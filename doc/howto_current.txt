plant : 'MarsonLuigi_API  (registered to wuawei)

see event loop chain start and cur status :
	*****   goonstep called , exec procedure:  startcheck 02/01/2023, 19:29:32 , step:  3 

see event loop progression and related input chain progression :
	Outerfunction. updateData_: in procedure:  startcheck
	 sets input chain as 
	 
see end of execute proc :
	****
 execute procedure: 
	
	
	
	
see update on state persistance: note date to see if caused by  anticipating >  state.anticipating.date or user browser
	writeScriptsToFile(): updated
	
	
see rest token requirement on   event ( connect )
	  connect(): token not available, so fired login rest await
	  
see relay set changes :
	onRelays current status
	
_______________________________
sequenza che precede server emit('pump)

	- causata da anticipating :
	
			in repdayly(plant,hin, hout, fn)  called at init in startfv(eM) , we lauch each hour for a day interval :
			execute procedure:   procName='startcheck '+ d.toLocaleString() 
			       with event sequence  ev2run = {connect:null,openapi:null,weather:null,startcheck:null} 
			 
			 
			the ececute precedure at last firing event startcheck   :
			- runs cb set with : these.on('startcheck',cb)
			- cb will : 
			aTT=anticipate(state)) calcola inuovi valori per le pompe usati da :
			attuators(state,pdc,g,n,s), per settare i pomp relais :
				call setPump(i,status) to set iesimo relay value/state registered as state.relays.x 
					
			  	nb  setPump is created 1 each relasEv :
			  	
			  	
			  	nb setPump is aslso used in startfv to deploy the initial state relays to pumps 
			  	
			  	
			setPump(pumpnumber,on)  calls :		  **AK78     
			
			 	- pumpsHandler[pumpnumber](0,on_)  to set   handler di relais (button io) che lancia il update dei rele visibili nel browser , 
			 						nb esso è settato in startfv_/abilita2/builddev():
			 							pumpsHandler[ind]=watchparam(pump);// handler for actuators, each handler emit the socket.emit('pump' to browser.
										if(relais&&relais[ind])relais[ind].watch(pumpsHandler[ind]);// attach same handler watchparam(pump) to all gpio pump  buttons.   << todo : da debuggare il passaggio parametri !!!
			 	
			 	- onRelais(relaisEv[pumpnumber],on_,'server',fn);   to command the dev ctl e updatare il loro state.relais (assieme anche a ... )
			 	
					 	 //  nb onRelais can be called  from :
				                  //     - this server using   setPump() che chiamera onRelais sia direttamente che via browser (feedback )
				                  //      or
				                  //     - browser(via .emit('pump',,'browser')) che ha origine da 
				                  //          - browser user change flag
				                  //          - come feedback del event 'pump' lanciato dal server dal gpio button handler  :
				                  //                pumpsHandler[pumpnumber]= watchparam(pump)) 
				                  //                this handler can be called by gpio button change or
				                  //                 by  setPump() 
				                  // 
				                  //          nb setPump() chiama onRelais sia direttamente che via browser ( come feedback )
				                  //              setPump è chiamato da startfv, attuators e altri metodi che si azionano all'uscita di vari execute
				
		 
	 - causata da user buttons relais :
	     
	 	relais=[new Gpio(18, 'in', 'both'),
					new Gpio(19, 'in', 'both'),
					new Gpio(20, 'in', 'both'),
					new Gpio(21, 'in', 'both')
					];
		 watchparam(pumpname)  crea  un hanler set foreach button con : relais[ind].watch(handler) 
	 	il handler e posto  anche in pumpsHandler[pumpnumber]  per essere usato da setPump , vedi sopra 
	 	
	 	il handler :  socket.emit('pump',pumpName, lightvalue); che va a settare il flag nel browser 
	 

	 		nb  relaisEv=['pdc','g','n','s'];
_______________________________________________________
sequence after .on('pump',,  , fired by browser (causato sia user flag button or .emit('pump' by server(see above)  )

	- socket.on('pump',onRelais);/

	- function onRelais  (pump,data) , data= valore da settare 
		nb called anche direttamente dal server in setPump , contestualmente ad emettere emit('pump',,  via handler pumpsHandler[pumpnumber](0,on_)   )
		
		se il valore da settare e diverso dal valore corrente del pump rele lo setta
		se il data non corrisponde allo state.relays[pump] lo si updata (serve quando si cambia valore via button nel server o i flag nel browser )
		return api.writeScriptsToFile(scripts,plantname,procedura). : si updata lo state nel file 
	  
	  
	- writeScriptsToFile
	
_______________________________________________________________________
sequenza di init al press del button: load a plant
	 <button type="button" onclick="startctl()">start controller</button> 
	   dopo aver indicato il plant che si desidera gestire

		nb 

		1:  loadScriptsFromFile(src,ctl)
		  carica il status dal file src in /.data se esiste 
		  se no considera lo state base e lo completa con:
		  	- plantname
		  	- setta il state.relays[pump]=false   nb o settarlo copiando il value presente ???
		  			 , pump in relaisEv

	

- start quando il browser si connette (si crea .socket e si lancia il init del socket (.on('connect',,) ) e clicca il button  onclick="startctl()
		si spara il socket event :
- socket.on('startuserplant', function (plantname,feat) 
	- si crea il ctl con eM = ccbb(user={name:plantname});
	
			ccbb() will 
			
				recupera ctl : inst=started[name].inst = (new eMClass()).cfg(name); 
					LLKK : NB inst.state.reBuildFromState=false
							>> qui il inst e' già operativo compreso di 
								(inst.socket) e
								inst.state.anticipating...   e 
								execute procedure regstrate nel closure .........
				o si crea :
				- crea il ctl : inst=started[name].inst = (new eMClass()).cfg(name);
					dove in .cfg(), chiamando customOn(this), : si personalizza gli handler degli eventi (non socket) chiamati da app2.js  
						NB reBuildFromState=true, so see .......
	
	- si registra o si aggiorna il ctl con   il socket corrente , cio permette di comunicare con la nuova sessione browser :
			eM.socket=socket;

	-  recoverstatus(plantname).then((em_) => startfv_(em_));  : con this= eM, updata il state recuperandolo dal file in /.data 		(BNM) 

 		> chiama  loadScriptsFromFile(src,ctl) ,che 
 					se c'e' in file=process.env.PersFold+src+'.json' un processdel plant  attivo:
 						lo  carica lo state nel ctl, 
 							>>>> nb quando disattivare un plant ??
 					se non c'e' init a new state sostanzialmente usando i pumps configutati per il plant : relaisEv
 						
 						
 			 e poi  (LKIO):
 			 writeScriptsToFile(scripts,plantname) in modo async (.then(),
 			 	writeScriptsToFile chiama anche socket.emit() per updatare :
 			 	 - file in /.data 
 			 	 - la parte di state che e' visualizzato nel browser via 
 			 	 			socket.emit('status',, e 
 			 	 			nel browser socket.on('status'...
 			 	 		es il .anticipate( )
 			 	 			TODO   aggiungere anche i browser triggers input !!!
 			 	 	(escluso i relays state che sone gestiti via event 'pump' , vedi anche DDRR )
 			 then 
 			risolve il promise returned by recoverstatus che lancia startfv_()
 	i thread procede (mentre i promise stanno risolvendosi : KIU) con:
 	if(eM.reBuildFromState){if(state.anticipate){ // se sto completando un controller con lo status recuperato 
 				>>>>>>>  naturalmente si spera che i promise che stanno lavorando in recoverstatus abbiano gia impostato lo status che qui si sta usando :
 					{hourinterval,starthour,stophour,triggers}=state.anticipate;  !!!!!!!!!!!!!!!!!!!!!!!!!!!!
 					** sembra che node in recoverstatus esegua loadscriptsfromfile , poi proceda qui, scriva state.anticipate  e poi finisca il recoverstatus con writeScriptsToFile() riscrivendo fn.state (LKIO)
 						quindi naturalmente si va avanti con il promise chain (BNM) eseguendo startfv()
 						dettaglio : qui si chiama 
 		repeatHandler(starthour,stophour,hourinterval,triggers);
 		
 		 	reregister procedure execute chiamando lo stesso  handler del  socket.on('repeatcheckxSun',
 				 repeatHandler(starthour,stophour,hourinterval,state.triggers)
 				 	chiama checkFactory(eM)repeatcheckxSun(starthour,stophour,hourinterval)
 				 			che,like onRelais, write a state property (.anticipate correct?) :
 				 			setanticipateflag({running:true,starthour,stophour,hourinterval,triggers});

							  fn.state.anticipate=set_;
							  return api.writeScriptsToFile(fn)

 	- thread ends
 	
 	nel frattempo nei promise chain di recoverstatus (KIU)
 		
		 	- startfv_(em_)   procede dopo il resolve del promise tornato da recoverstatus (risolto alla resolve del writeScriptsToFile ):
		 		- startfv(eM)
		 		
		 			  - if (!Proto) customOn(eM);
		 			  - eM.emit('reset', cfg);// reset fsm   todo 
		 			  
		 			  -  following  we allign state.relays[pump] , pump in relaisEv,   according with current recovered state running setPump()

							DDRR : allign relays secondo il current state.relays recoverato
							nb se i relay sono non coerenti con lo stato si allineano al ritorno del corrispondente pump event dal browser
							in alternativa si potrebbe forzare il current state allo stato dei rele , ma non dovrebbe succedere  
		  				relaisEv.forEach((pump,ind) => { setPump(ind,eM.state.relays[pump],eM)
		  				
		  					setPump will:  AASSWW
			  					-pumpsHandler[pumpnumber](0,on_)=watchparam(pump);// called also by anticipating algo in attuators to set the pump relay in browser that call back to event pump calling 
			  						onRelais(relaisEv[pumpnumber],on_,'browser....',fn);
			  					
			  					-onRelais(relaisEv[pumpnumber],on_,'server',fn); this is a copy of previous call , that we use if the browser is browser is off
			  					
				  						in onrelais se il valore da impostare e diverso la rele current value si updata la gpio con : 
				  					relais_[pump_].writeSync(lightvalue);
				  						quindi se lo stato   state.relays[pump] non corrisponde lo aggiorno chiamando il promise 
				  					
				  					return api.writeScriptsToFile(fn)
				  					che da lo stesso promise  come return di onRelais()
				  					
				  			non si aspetta il resolve di writeScriptsToFile(fn) e si ripete il ciclo relaisEv.forEach(
			  				
		  			- si allinea il flag 'procedura anticipate in corso'(ora il state: ACTIVE/INACTIVE ) , che lo copia dallo state.anticipate 
		  				da accendere come feedback del socket event repeatcheckxSun
		  				e il suo spegnimento come feedback di stopRepeat
		  				
		  			- old : 
		  			  repdayly(plant,10, 12, eM); :lancia ogni ora un eceute procedure procName='startcheck '+ d.toLocaleString();
		  			  > question : il primo execute e' eseguito subito sul thread corrente 
		  			  		>>  evitare che il processo di init non sia  terminato (manca abilita() ) prima di startare il primo repdayly  
		  			  		
		  			  - now :		
		  			  >>>>>   ora repdayly è sostituito dal socket event repeatcheckxSun lanciato da    ::::
		  			  
		  			  
		  			  	
		  			  	checkFactory(fn) genera :
		  			  		- 	{ repeatcheckxSun: funzione per settare la ripetione giornaliera di exec orarie che realizzano algo anticipate
		  			  						// exec proc name: 'startcheck_'+ d.toLocaleString();
		  			  						// >>> viene lanciato da: socket.on('repeatcheckxSun'
		  			  						//  after execute we updates state running writeScriptsToFile()'
		 						  stopRepeat:function (){// stop della programmazione giornaliera
		 						  			// >>> viene lanciato da: socket.on('stopRepeat'
		 						}
		 		- abilita(plant )
		 			lancia il socket event 'view' che abilita la sezione plant "VDM001"
		 			
 
	_______________________________________________________________________
sequenza di init prima del press del button
	  <button type="button" onclick="startctl()">start controller</button> 


si inizia con il init socket connection in cui si da il websocket che pemette la cominicazione con il s 

	io.sockets.on('connection', function (socket) {/
		- crea i socket event per cominicare con la essione aperta nel  browser:
			>   socket.on('startuserplant', function (data,feat) { // user press button to connect to some plant, so this event is fired , feat url enc

				vedi sopra
			>  // set local gpio relay to some button on web page, web page will emit a socket event 'light' that
				will in this server activate the gpio port

  					pushButton.watch(function (err, value) { //Watch for io hardware interrupts on pushButton  
                                            // to review , see also staff/webserver07112022.txt

			>   // implements also a button/algo handler array for actuators / pumps
					 relaisEv.forEach((pump,ind) => {// ['pdc',// socket event to sync raspberry buttons and web button
									  // 'g','n','s']
					  relais[ind].watch(pumpsHandler[ind]=watchparam(pump));// attach a handler watchparam(pump) to all gpio pump  buttons 
						// that handler works also x algo handler called in attuators/setpump   ex pumpsHandler[0](err,value) 0 means pdc pump
					  
					 }); 
			>   socket.on('light', function (data) { //
			
			>  socket.on('pump',onRelaisClos());// same handler for all pumps events
  
			
____________________________________________________
implementation staff 
> see on app2.js :
// new make this app fv fsm factory( factory of event mngobj) 
// it also can be implemented as a server with user login and session (put in a session store service) will be the same as the event obj state(local vars))
// so some socket events coming from browser (probably after a login to user and a logim to plant with related session/token ) that are addressed to specific plant mng will be routed to the implemented rest fsm server

___________________________
022023

attenzione che watchparam e' usato per settare il flag del browser dal button click e dagli algo con setPump. pero mentre in setPump comunque si setta i relays con onRelays e quindi il feedback del browser e' inutile  in button click no 
	quindo in questo ultimo caso il feedback e necessario >>>>>>>>>><   sistemare !!!!!
	
____________________________

nested ref 022023

in socket connection handler troviamo 
	- eM (ctl)
		settato da  socket.on('startuserplant'
	- e gestori dei repetion job manager repeat e repeat1 
		settati in socket.on('repeatcheckxSun' e socket.on('startprogrammer'   
			con checkFactory(eM) (factory di fv3) dove si porta il ref eM
		
		in essi (repetition job manager)si lancia, nel suo closure,i rep job 
			gfg_Run_(cicles,period,execParm_)
			 
			che ripete il callFn_(execParm); (sempre nel closure) 
			
			  che lancia  (eM=fn).execute(procName,a,b,  ev2run, asyncPoint, processAsync, dataArr,....
			  		nel cui cb si chiama api.writeScriptsToFile(fn)   per il state persistant
			  	che esegue gli event ev2run customizzati in  customOn(these)  lanciato in eM.prototype.cfg con customOn(this)
			  	in tutti gli events del ctl eM
			  			generati con (eM=these).on('genZoneRele', 
			  		- è disponibile e condividuano  this=eM con il suo state this.eM.state
			  	 		ad es  in these.on('genZoneRele',    un event che setta i results 
			  	        		usera 
			  	        		sub function interne  dove e' disponibile eM 
			  	 
			  	 			o sub esterne functions/obj dove passeta eM , 
			  	 				es : 
			  	 				attuators(these,
			  	 				e aTT=program(state,inp,probes)){/
			  	 	- e usano fun , es setanticipateflag(false,'program','lastProgramAlgo');		
			  	 		
	- le def dei sochet events  socket.on(.....  
	
	- e alcune utility f 
		es setanticipateflag(false,'program','lastProgramAlgo');
		che hanno sempre il ref eM
			  	
	che sono visibili da tutti i socket events socket.on() 
_________________________________________
alla fine di una exec :

   nell'handler dell'ultimo evento girato nella exec il risultato viene passato col cb:
   
   
   	 cb(0, res);
   
   
   
   esso viene usato da :
    ends(stepNum,lastRes)
    	che setta in state :
    	state.lastRunnedProcedure={result:lastRunnedProcedure,procName,GMTdate}; ex : state.lastRunnedProcedure={result:{execute:pippo},procName,date}
_______________

setting results in last event of execute   OOHH

 in  these.on('last even', 
  - if(aTT=algo())
  
  
  		algo (program or anticipate)   (state,inp,,,)
  
  			recover input from state and inp 
  			ret=[]/null   order according to    relaisEv=['heat','pdc','g','n','s','split'];
  			if(ret) 
  			
  				 if() 	state.lastProgramAlgo={updatedate:date.toLocaleString(),probes,pumps:ret,model:'programbase'};/false
  				 	state.lastAnticAlgo={updatedate:pdate.toLocaleString(),level:1,policy:0,algo,pumps:ret,model}/false
          			 if() ret=optimize(ret,date,h,m);//
  				if(ret){// program wants to set some relays, ret can have nul val that must be resolved  also looking at other proposal user+ anticipate 
  					return consolidate(state,'program',date);
  				else 	return null   // means no result from algo, no action at all 
  
  
   	attuators(these,aTT[0],aTT[1],aTT[2],aTT[3],aTT[4],aTT[5]);//[heat,pdc,g,n,s,split] val=true/false/null   set relais x level 1, then after 1 hour (1,1,1,0), if noeco (1,1,1,1)
                                                                  // ?? (pdc,g,n,s)  set relais x level 1, then after 1 hour (1,1,1,0), if noeco (1,1,1,1)
      	res.execute=aTT.toString();/
      	
    else   res.noexec='no....';
    
  - cb(0, res);
   	
_____________________________

server imlem level > see also implementation staff 

 immagino il server cme il bot che si connette in socket con il client (frame o android app) al event message estraggo lo user e recipero il instance/session che controlla lo user plant
   il session sarebbe lo state e lo spazio degli url/event viene concentrato in una istanza del fsm che esegue gli event loop/chain execute.
   
   see also :
   
   	function ccbb(client) {// when client/plant got a request (a button) for a plant on a webpage , we fire : socket.on('startuserplant' ,that to operate/ register the fv ctl inst
  	 so we instatiate or recover  the fsm: that is a eventmanager or connect to the server with a socket that has the same event managed (so the socket is the session/instance of the event manager for the 		plant)!
  	 
  il che vuol ire che con un server classico io recupero il sesstion state e poi apro un socket con un sever che gestisce gli eventi ( fsm instance) che e' in patica la connessione/associazione con il local fv3 factory che instanzia il ccbb
  
  il ccbb che fa il chaining routing del event ( custom) e' in pratica il dm che gestisce i threads/ convo quindi l'associazione tra gli eventi nel bot e' il intent resolver / thread mentre qui lo sono i vari execute event chains!. nel bot il evento message significa che è la continuazione di un chain/thread precedentemente individuato fino alla risoluzione del intent. dopo un intent ( execute) si passa a selezionare un altro master event o master intent fatto da vari thread / event chain !!!!!
  
  un event connected server e' come un server che gestisce uno spazio di routing/url ma piu articolato!
  
  
  
  
  __________________________________________
  
  i pratica : api 
  		> ricava dallo logonato user i state per navigare su ececute chain instance (ccbb) personalizzati e connessi via socket o events 
  		
  	si gestisce la pagina main ( presenta prodotto , configura , inorma  con una serie di url
  	si fa login con user quando si vuole gestire un gruppo di plant
  	si sceglie il plant e si apre una socket che gestisce uno gruppo di url tra user e fv3 che poi mappa le richieste sul socket instance messo su server o banalmente associato come modulo event driven
  	 		 in pratica gli socket event sono intent che si risolvono in parallelo e gli event del instace ccbb sono gli eventi/entity base che sono raggruppati in execute(intent resolver) 				piuttisto che in threads
  	 		 
  	 fsmmanager(opt, function (app, opt, no_ccbb) 
  	 	eMClass..cfg = function (plantname) { plant/user customizing}
  	 	
  	 		configura il fsm x gruppo di user/plants
  	 	
  	 	
  	quano lo user vule getire un plant chiama l'evento/spazio di url ;
  	socket.on('startuserplant', function (data,feat) { // user press button to connect to some plant, so this event is fired , feat url enc
  	
  				si chiama  eM = ccbb(user);// ** il fsm recupera/crea un siglethon x user/plant 

				 si relaya/associa connette il fsm/server con un socket:  
				 
				   eM.socket=socket;// 
				   
				 in pratica una parte del socket gestisce un livello tra user e fv3 che fa da gestore di eventi di front end e configurazioni varie.... 
				 mentre una parte si socket richiama direttamente il server/fsm  app2 per gestire gli chain di eventi della fsm (execute chain di event fsm) ( quelli di onCustom()
                                                      
  	 	
  	 			si ricava lo state come dati per gli execute :  recoverstatus.call(eM,user.name).then((em_) => startfv_(em_))
  	 			
  	 			si riprendono processi interrotti :  if(state.anticipate){
  	 			
  	 			....
  	 			
  	 			
  	 			
  	
  
  let inst;
  _____________________________________________________
  inserire in run() dopo la prima fase della costruzione dei device ctl :  relais_
  
  _______________________________________
  
  dyn devices mng  to customize plants
  
    		nb error in :     setPump(ind,eM.state.relays[pump],eM);// setPump(ind,eM.state.relays[pump]); // todo xxx : is error ?
  
  pumps sono individuati dal index o dal nome :
  nomi pumps : relaisEv ['heat','pdc','g','n','s','split'],   >>>> sono i relais monitorati nel browser !
  
  mapping pump index con devices (mqtt/gpio) :  gpionumb:[12,16,20,21,26,19,13,6]  e       mqttnumb:[11,null,null,null,null,null,null,null],
  devices configurati vanno in : relais_ che hanno i metodi per leggere e scrivere (readsync e writesync)
  

	nbnb : se dimension di relais e maggiore di dim relaisEv vuol dire che le funzioni applicative non agiscono  su quei device ! 
		se un device e' null es relais_[8]=null vuol dire che quando si legge e scrive si ottiene sempre 0 
		
applicativi che usano il name relaisEv che poi tradotto in index comandano relais_ :
 - incong()

 -  onRelais   (setta il rele ( index= pump_ e nome pump) e registra in state lo status per nome in state.relays[pump])
 				nb:
                                   //  onRelais can be called  from :
                                  //     - this server using   setPump() che chiamera onRelais sia direttamente che via browser (feedback )
                                  //      or
                                  //     - browser(via .emit('pump',,'browser')) che ha origine da 
                                  //          - browser user changing flag
                                  //          - come feedback del event 'pump' lanciato dal server dal gpio button handler  :
                                  //                pumpsHandler[pumpnumber]= watchparam(pump)) 
                                  //                this handler can be called by gpio button change or
                                  //                 by  setPump() 
                                  // 
                                  //          nb setPump() chiama onRelais sia direttamente che via browser ( come feedback )
                                  //              setPump è chiamato da startfv, attuators
 
 	- 		
	  nb setPump(): imposta i pumps indicndo l'index 
	  
	  	chamato da function attuators(fn,heat,pdc,g,n,s,split){/    : è funzione applicativa che setta alcuni pump indicando gli index: es setPump(0,,,,,

state : i pumps sono storati in state (con key il loro nome) in api.writeScriptsToFile(()   // upddate persistance and send status to browser
       esso stora : JSON.stringify(new_scripts= new_scripts=fn.state  sul file_=fn.state.app.plantname;
       
       fn.state contiene status della app customizzata e in particlare i pumps che in onRelais vengono storati con key=nome !
	
	
- nel rebuild della pagina exindexhtml.ejs (come model si prende il gia elaborata pagina spapage_copy.ejs (che non va perche i partial sono quelli di digital ocean ()) :

	- si lascia il vecchio cdn :  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
	 		piuttosto che quello proposta da do :
	 			<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.2/css/bootstrap.min.css">
	 			
	 - var str = '<ul class='xbreadcrumbs' style='position:absolute; bottom:0px'>';

	- in https://stackoverflow.com/questions/7677028/how-can-i-dynamically-create-an-unordered-list-in-javascript
		for(var i in $yourArray){
		   str += '<li><a href="#">String 1</a></li>';
		}

		str += '</ul>';

		$('body').append(str);
________________________________________________________________

ssh luigi@192.168.1.76   wifi
ssh luigi@192.168.1.79  

mosquitto_sub -t shellies/shelly1-34945475FE06/relay/0 -u sermovox -P sime01 -h bot.sermovox.com -p 1883
mosquitto_sub -t ctl_var_gas-pdc_4 -u sermovox -P sime01 -h bot.sermovox.com -p 1883
mosquitto_sub -t @MarsonLuigi_API@ctl_var_gas-pdc_4  -u sermovox -P sime01 -h bot.sermovox.com -p 1883
mosquitto_sub -t @Casina_API@ctl_var_gas-pdc_4  -u sermovox -P sime01 -h bot.sermovox.com -p 1883


setting var from external mqtt client : 
mosquitto_pub -h bot.sermovox.com -t shellies/shelly1-34945475FE06/relay/0/command -m "off" -p 1883  -u sermovox -P sime01
mosquitto_pub -h bot.sermovox.com -t shellies/shelly1-34945475FE06/relay/0/NReadUser/cmd   -m "off" -p 1883  -u sermovox -P sime01
mosquitto_pub -h bot.sermovox.com -t shellies/shelly1-34945475FE06/relay/0/command -m "on" -p 8883 --capath /etc/ssl/certs/ -u sermovox -P sime01
mosquitto_pub -h bot.sermovox.com -t Test -m "hello world" -p 8883 --capath /etc/ssl/certs/ -u sermovox -P sime01
mosquitto_pub -h bot.sermovox.com -t @MarsonLuigi_API@ctl_var_gas-pdc_4 -m "off" -p 1883  -u sermovox -P sime01
mosquitto_pub -h bot.sermovox.com -t @Casina_API@ctl_var_gas-pdc_4 -m '{\"payload\":1,\"sender\":{\"plant\":\"Casina_API\",\"user\":55}}' -p 1883  -u sermovox -P sime01  dont work , also without ''
mosquitto_pub -h bot.sermovox.com -t @Casina_API@ctl_var_gas-pdc_4 -m '{"payload":3,"sender":{"plant":"Casina_API","user":55}}' -p 1883  -u sermovox -P sime01     works
sent setManual/forceautoconsumo from openremote from remote object :
	 Received message  {"payload":1,"sender":{"plant":"Casina_API","user":55},"url":"setMan","checked":1}    on topic  @Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd
		TODO : sender.user   > sender.device
					sender.user must be the emitter : can be mainctl  or  OR  (openremote) !	
					 
	 

mosquitto_pub -h bot.sermovox.com -t @MarsonLuigi_API@ctl_var_gas-pdc_4 -m '{\"payload\":\">ctlpresent\",\"sender\":{\"plant\":\"MarsonLuigi_API\",\"user\":55}}' -p 1883  -u sermovox -P sime01


shelly cfg

 al reset è access poimt wifi e il suo address e   192.168.33.1  ??????
 poi setti il wifi mode client e dai un indirizzo statico e il nome del wifi acess poin del router per cui poi lo accedi con quello indirizzo statico es 192.168.1.150 (shelly in casina ? )
 ht : 192.168.1.151

poi setti in advnced dev setting mqtt con   server bot.sermovox.com:1883  user sermovox e pass sime01




________________________________________________
relevant logs start with : to print with log module .......
anticipate algo calc new relays values....     or 	anticipate() find cloudily low so start pdc....
Outerfunction. updateData_: in procedure:  startAntic

.................................


__________________________________________
01042023

program algo 
triggered by socket.on('startprogrammer',repeatHandler1);
	- si calcola sched={giorno,notte} in funzione dei triggers triggers2 input
		poi usando riggers2.custom si mappano i concetti giorno/notte ai plant devices :
			es le zone giorno/notte saranno legati a 2 devices su cui agire 
				> improvement :
					i concetti degli algo si dovrebbero applicare a generici devices , quindi :
						- caso program algo :usare programmatore uno e due e poi applicarli a devices di index 3 e 5 ! 
						- caso anticipate : ad es mappare temp ext a devices, e mapping in uscita verso pdc e altri utilizzatori (zone, stufette,sanitario, )
						
						>> question : il mapping va fatto usando un campo mapping da fare eval o usare elementi dentro mdels ?
							probabilmente entrambe in models concettualizzare i devices e poi in eval mappare i device concettualizzati a azioni proposte dagli algo !
						
	- si recupera  il .....  : repeat1=repeat1||checkFactory(eM);
		checkFactory è closure returning {repeatcheckxSun: function (hourin, hourout, period, execParm, cb2) {// register the procedure to repeat, period in minutes
						......
						
	
				>> verificare che e' usato anche dal algo anticipate !!!! > si


	
	- che lancia l'ago utilizzando il param builder prog_parmFact(sched)) che li calcola in funzione dei trigger scelti :
			nb il anticipate chiama invece : function antic_parmFact(noparms)   !!
			    il prog_parmFact(sched)  :
			    	setta : ev2run = {initProg:null,// will put probes result as input of genZoneRele ev
						  genZoneRele:"initProg"};// attivare valvole x risc generale e poi singole zone
						  
						  		nb gli event sono def in function customOn(eM)  !
						  
						  	genZoneRele async function ( inp_, cb) 
						  	esso come usuale per il last event calcola i nuovi valori degli attuatori usando program :
						  		aTT=program(state,inp,probes))
						  
						  		e poi si settano i new value mappando i aTT index sul plant pumps (identity here ) 
						  		
						  			>>> advice: in order to costom std program algo to plant devices in plant web page :
						  				> in program algo triggers insert a js to evaluate with some var in context to map the algo staff to plant devices 
						  		
						  			attuators(these,aTT[0],aTT[1],aTT[2],aTT[3],aTT[4],aTT[5])// set plant pumps relays
						  		usando these (eM/fn) e agendo sui fn.
						  
						dataArr={initProg:null,genZoneRele:{dataArr:sched}};
						evAsync={};// evAsync={aEv2runKey:itsasync,,,,,,}
						a=processAsync={},b=asyncPoint={};// todo 
				e torna  {procName, a,b,ev2run, asyncPoint, processAsync, dataArr,algo:'program'};
	
		repeat1.repeatcheckxSun(starthour,stophour,dminutes,prog_parmFact(sched) 
				esso lancia nel periodo di  attivita il ricorente exec con :
				 gfg_Run_(cicles, period, execParm);    >>> che e' un func (statico) del closure checkfactory
				   chiama gfg_Run_(cicles,period,execParm_)
				   	che chiama la callF()
				   		che chiama ripetitivamente  callFn_(execParm);  
				   		
				   		 che lancia 
				   		 	        fn.execute(procName,a,b,  ev2run, asyncPoint, processAsync, dataArr,
									  () =>{
									console.log(' after execute we updates state running writeScriptsToFile()')
									//api.writeScriptsToFile(fn.state,fn.state.app.plantname)
									api.writeScriptsToFile(fn)
									.catch(function(err) {// pdate the state file
									  console.error(err);
									  process.exit(1);
									 });
									});
		
	- poi : setanticipateflag({running:true,starthour,stophour,dminutes,triggers2},'program');
	

____________________________________
01042023

at start, after login, we built+ customize (customOn(this);)  fn/eM using app2 basic ctl obj in :
	run() 
		torna/setta la func : ccbbRef=function ccbb(plantname) 
		per creare o recuperare il plant ctl dopo socket.on('startuserplant',
		
 socket.on('startuserplant', function (plant_,feat) {// inst/fn/ctl/eM :  here we create the ctl of the plant that will be passed to all the service functions 
   - get model parm (principalmente fa il config dei devices )
	plantcnt=model.ejscontext(plant_);// ejs context=plantcnt={pumps:[{id,title},,,,]}
    	plantconfig=model.getconfig(plant_);// 
    	plantcfg=model.getcfg(plant_);// get plant cfg from available pool. : return plants[plant].cfg;
   - 
   	 eM = ccbbRef(plantcfg.name);// ** il fsm recupera/crea un siglethon x plant , state to be updated with recoverstatus()

   - recover/create the persistence status  
	     recoverstatus.call(eM,plantcfg,plantcnt,plantconfig).then((em_) => startfv_(em_)); // >>>>   recoverstatus() returns a promise resolved. we finished to write status back with promise .writeScriptsToFile
	     							avremo :
                                                                    // ctl event status: in eM.state 
                                                                    // socket in eM.socket
                                                                    // plant cfg in eM.status.plantcfg, 
                                                                    // dev i/o still to build 
                                                                    // will cb startfv_   // TTGG  // why do not use eM invece di passarlo come em_ ?
                                                                    //recoverstatus_.call(eM,user.name).then((em_) => startfv_(em_));// will cb startfv_
                                                                    
             mentre aspetto di recoverare status goon con :
             >>> o lo giro in coda a startfv_ ???????????
             
               if(eM.reBuildFromState){// we got status in persistance, so check if we restart some algo (anticipate/program)
               
               
               
   -   function startfv_(eM){// entry point when staus is recovered from file   // // why do not use eM invece di passarlo come em_ ?
  
		    let plant=eM.state.app.plantname;// or app.plantcfg.name

		    let plantconfig=eM.state.app.plantconfig;
		    let{gpionumb,mqttnumb,relaisEv,devid_shellyname}=plantconfig;
    

			 - abilita(eM.state).then((devices)=>{ / abilita sezione gestione eventi ( relais_)  plant nella pagina  SSSTTT
			 	sostanzialmente runna 
			 	- async function buildPlantDev(){// build here the plant ctl devices (ctl/eM/fn).iodev.relais_ dev/pumps (+ /button switch) and their handlers 
			 		isAvail=mqtt.init(devid_shellyname))){// devid_shellyname={11:'shelly1-34945475FE06'}
                                            // AAFF :after start mqtt connection  wait connection and subsribe all gpio , 
                                            // so  as soon cb is called we have status[gp]=[] (the subscription is ok )
                                            
                                            torna promise return getio.getctls(gpionumb,mqttnumb);
                                            
                             .then((devices)=>{ / abilita sezione gestione eventi ( relais_)  plant nella pagina
                             - al resolve si prosegue con :
                             
			 
			 - abilita2(devices);					HGGB
			 	>>>  carica i devices come status di fn:

						devices.ctls.forEach((mdev,index)=>{
						  if(mdev){eM.iodev.relais_[index]=mdev.ctl;
						    state.pumpMap[index]=devices.devmap[index].portnumb;// the dev id in models.js
						    
						pumpsHandler[ind]=watchparam(pump);// handler for actuators, each handler emit the socket.emit('pump' to browser.
						
						context={ejscont,scope};
    						socket.emit('view', context); // nb .on('pump',,) can be not jet assigned 
			 
			 -  startfv(eM);})// ** start/update/recover plant singlethon ctl eM state and .....
			 
			 	function startfv(eM) {// ** start/update singlethon 
					  // console.log(' startfv : the ctl instance is :\n',JSON.stringify(eM,null,2));
					  let plant=eM.state.app.plantname;
					  console.log(' startfv plant: ',plant,' , following  we allign relay according with current recovered state running setPump()');

					  if (!Proto) customOn(eM);		>>>>>>>>>>>>>>>>>>>>>>><   again ????
 					eM.emit('reset', cfg);// reset fsm   todo 
 					// allign relays current status to state.relays :
					  relaisEv.forEach((pump,ind) => {// ['pdc','g','n','s']
					    setPump(ind,eM.state.relays[pump],eM);//
_____________________________________________
fare merge tra consolidate() e optimize() MMJJ :

  function consolidate(state,lastalgo,date){// [false, false, false, false,false,false]= [heat,pdc,g,n,s,split], lastalgo = anticipate,program,user
// puo essere chiamato sia da anticipate che da program. ma ultimamente program chiama optimize() !!!  >>> todo  sistemare un unico optimize !?!
// heat : se impostato da program  antic puo solo fare or 
.........
_________________________________________________

chiarimenti sullo state dei 'dev/relay/pumps

i  device ctl sono mappati via indice in eM/fn.iodev.relais_
i nomi assegnati (calcolato from  models.js) sono eM.state.app.plantconfig.relaisEv;(mappa indice/nome)
lo stato dei device sono storati nell'oggetto : eM.state.ralays secondo key/nome relaysEv

 eM/fn.iodev.relais_ e eM/fn.iodev.probes_ hanno i dev/prob che sono ottenuti dagli id/port in model.js  secondo i :
    "devMap" : [11, 16, 20, 21, 26, 19, 13, 6],
    "probMap" : [],
    
    >>> cancellare pumpMap  dal persistant file ! in rapberry   , + anche  quache altro refuso ?

 state.plantcnt.pumps  contiene i dati x creare espandere la view dei pump list nel browser 
 
  
___________________________________
set date:

const dOraLegale=parseInt(process.env.dOraLegale)||0;
            var date = new Date(); // Create a Date object to find out what time it is   gtm ?
            date.setHours(date.getHours()+dOraLegale);//dOraLegale);
            
 or:
     let  pdate=new Date();pdate.setHours(pdate.getHours()+dOraLegale);
	localdate= pdate.toLocaleString(),algo='program';
            
_____________________________________
integrating program and anticipate algo , summary in :
function attuators(fn,map,aTT){// aTT: the program() algo resuts (after consolidating with anticipate algo and manual set in optimize())
                                //  in attuators(these,map,aTT), we set (calling setPump(i,relaisEv[i],fn)) real devices (i) mapping virtual (if its map>=0) into real dev (of index i=map) 
                                //                              nb only if the new set/value  of  real device is changed from its status  state.relays[pump=])
                                // setPump will then call (eventually ) browser then call:
                                //                          >>  onRelais   (setta i singoli real device/rele ( index= pump_ e nome pump) e registra in state lo status per nome in state.relays[pump])
                                //                                 only if the new set/value  of real hw device is changed ! 
                                // when all setpump promises resolves we cb for event termination setting the execute program algo results : aTT.toString() , see Outerfunction. updateData_ .....
                                //                          >> the execute result was then stored in "relHistory" state as string!
                                //                          nb program() algo specific result (before consolidating ) was  stored in lastProgramAlgo obj  as pumps array ! as lastProgramAlgo array 
                                //					because they need to consolidate all related algo results  when  next algo result is coming


_____________________________________

nuovo algo : the base pdc algo : in funzione di temp ext e orario setta pdc e split e ht via dei optimIndex=0,1,2   0: usa solo split e pdc  1: usa split pdc e g/n/s   2: usa solo ht e g/n/s 
 schema di optimize :
 - ora base assegna 0,1,2   , antic modifica il base, program assegna i rele guardando base e singole zone :
 split on se antic split
 
 premessa : ogni plant ha i suoi custom rele mappati dai virtual dev secondo map
 per agire sui virtual dev si inseriscono i algo triggers sulla pagina del plant con relative map che connettono i custom rele
 ogni algo triggers ha anche dei virtual( non esistono pero reali) status var che registrano eventi intermedi che, se trovati,  vengono usati da tutti algo semplificando i calcoli usando i valori intermedi(context) che possono anche essere settati a mano !(magari usando node red che imposta il var usando un connettore mqtt !!!!.
 	in pratica rele che sono sotto gruppo state.var che hanno dei setpumps che agganciano dei onRelais che settano solo lo state , tali var possono essere usati anche come probe, leggendo i dati  dello state senza avere un real probe attaccato !!! 
 		quindi i state,var saranno generati con una prsonalizzazione di getio.getctls(gpionumb,mqttnumb);   che non avranno la parte di dev ctl essendo inutile, il device e' proprio la var stessa !! ( see SSSTTT)
 		> tutti gli algo avranno a disposizione direttamente il valore come se usassero un lastVarAlgo piuttosto che leggere un dato udando un probe virtuale !!!!!
 		
 		cioe il anticipate cambia solo i l base var status. poi quando si gira il program non si guarda solo il base var al posto del setting dei rele
 		in parole povere il optimize qando chiamato da un program calcola i rele anche pe la parte che ora e' in anticipate guardando solo il base var !!!!
 		
 		
 		oppure aggancio il var state a uno state su mqtt che registro come registrare un rele e un probe allo stesso tempo . quindi il var state  legge scrive su tale device mqtt assieme/interagendo anche via node red 
 		quindi con un ago base o con nodered impostro la modalita base , poi anticipate algo resetta il base e chiama il program algo per calcolare i real devices. poi program algo girera autonomamente lavorando sul base var ! 
 		
 		quindi si potrebbe per semplificare raggruppare i probe facendogli fare anche funzione di var e lasciandogli uno spazio di state var sotto i state rele 
__________________________________________________

premessa al start del plant si caricano i device (pumps/'out' o prob/'in-var') in state.iodev :

		builddev(devices,eM.iodev.relais_,state.devMap,0);// transform devices={devmap,ctls} >>  state.devMap eM.iodev.relais_  : the action relays listed in browser
		builddev(probes,eM.iodev.probs_,state.probMap,1);

nb relaisEv sono i nomi dei custom/real pump rele (inorout='out') dei relais_ che uso su un customized plant(real device plant).
  gli algo lavorano su virtual pump/rele e poi vengono mappati in real : 
  	- es: il virtual index 3 e mappato sul real index 2, il nome reale e' relaisEv[2] come appare nella lista dei rele del browser
  	
  	
  	
  gli algo lavorano anche su prob/var device e anche loro vengono mappati :
  	quando  si triggera un program algo :
  		socket.on('startprogrammer',repeatHandler1);// start anticipating 
  		
  		  - si recuperano (come per tutti gli algo) i map per i rele e i prob/var  devices:
  		 	sched.probMapping=toeval(eM.state,triggers2.probMapping);// mapping algo vars to plant devices !, input used when call last event genZoneRele of related exec created with prog_parmFact(sched)
                                                            // // preferred use :  ('==&&state.mapping=[0,1,3,2,4];')   will fill the state.mapping var ! and returs the array 
  			sched.mapping=toeval(eM.state,triggers2.mapping);
		  - che vengono passati ai builder degli execute proc :
		  	prog_parmFact(sched)
		  	
	 	  - quando in un event degli execute event list devo usare un probe allora 
		  	o genero al volo il dev se e' un modbus (real index <1000) , see   parseFloat(await shellcmd('modbusRead',	(KKPPMM)
		  	o lo recupero un dev index se è un mqtt probe (real index>1000) (nbnb index=0,1,2 not its id=110):
		  			cerco il id nel cfg  mqttprob:{110:{topic:'gas-pdc ....
		  					nb  non nei cfg dei rele/pump ; mqttnumb:[11,null,null,null,null,null,null,null]     !!!!!!!!!!!
		  					>>> quindi il id e' solo un tag di controllo, i dev in-var si usano con i real index che e' l'indice di mqttprob!!
		  	
 			se invece uso un var posso fare lo stesso ma qualora volessi gestire il value (read write) del var state dovrei
 			 fare come per i pumps/relais :
 			  > creare lista sotto i relais in browser 
 			    con nomi description in un array like relaisEv_prob
 			    creare una immagine degli mqtt persistant var in state (like did for pump/relais state.relays) usando i nomi di relaisEv_prob come key :   state.in-var: {}
 			    	cosi come fatto per i pump/relay device :
 			    		state.relays={
					    "heat": false,
					    "pdc": true,
					    "g": true,
					    "n": false,
					    "s": false,
					    "split": true
					  },
 			    e un meccanismo di ( eventi lettura/scrittura impostati da setpump() che poi vengono corretti nel browser e girati come eventi on... che poi write sul device ( persistance) e registrano nell'immagine state. ) 
 			    
 			    
 	>>>>>>>><   idea
 		- invece di rifare per i var lo stesso meccanismo di settaggio dei pumps/relays con update anche via browser lasciamolo solo via execute event ctl readSync/writeSync 
 			che opera sui in-var reali caricati da mqttprob e facciamo update solo da node red ( a questo punto facciamo anche update dei real pump via node red (agganciando un var ai real pump device) ??
 		- oppure 	carichiamo i var dev che si vogliono editare in browser come forreso pump/rele, ovviamente modificando i metodi nel caso di inorout='dev' . 
 			quindi 'dev' sono configurati in mqttnumb (come i pump/rele ) e non in mqttprob che rimane solo per i prob !
 			il problema e' che va unificato i config dei 'out' secondo lo standard 'var' (obj e non integer)
 			
 			quindi un event potra scrivere su un var index 1007 che sara il index 1007 -1000 = 7 del mqttprob ( meglio che sara il var 110 che e' il key del real var device of index 0/7)
 			
 ___________________________________________
 
 catena di generazione dei device (mqtt ) in state.iodev :
 
 > model.js 
 cfgMarsonLuigi={ name:'MarsonLuigi_API',// duplicated FFGG
        apiPass:'xxxx',// to do
        // index : the index of a device 
      gpionumb:[12,16,20,21,26,19,13,6],// (dev id or port) raspberry device info. number is the raspberry gpio , null means no connection to dev available
      //mqttnumb:[11,null,null,null,null,null,null,null],// mqtt device info/id/port. number is the device id to subscribe
      mqttnumb:[{portid:11,clas:'out',protocol:'shelly',subtopic:'shelly1-34945475FE06'},null,null,null,null,null,null,null],// mqtt device info/id/port. number is the device id to subscribe

      mqttprob:[{portid:110,subtopic:'ht-cucina',varx:null,isprobe:true,clas:'probe',protocol:'shelly'},//a probe,  the shelly ht probes to register (read only) 
                                                                                // nbnb clas e isprobe sono correlati !! > semplificare !
                                                                                // clas='var'/'probe'or 'in'

      {portid:54,subtopic:'var_gas-pdc_',varx:3,isprobe:false,clas:'var',protocol:'mqttstate'}],// a var

                // a var  add also write capabiliy , so can be used as gen state var to modify with mqtt app/node red . as mqtt num will ha a frame below relay state in browser !
        
      relaisEv:['heat','pdc','g','n','s','split'],// dev name // >>>>>>>>> todo   add here and in fv3 a new item : heatht !!!!!!!!!!!!!!
                                                // //  relays : https://www.norobot.it/nascondere-e-mostrare-elementi-in-una-pagina-web/#btn001
      // titles:["HEAT Low Temp","HEAT High Temp"," PdC (vs GAS)","g"," Zona Notte"," Seminterrato"," Splits"],
      titles:["HEAT Low Temp"," PdC (vs GAS)","g"," Zona Notte"," Seminterrato"," Splits"],// description of device name
      devid_shellyname:{11:'shelly1-34945475FE06'// mqtt device id-s/n relais and probes !!!!   , details
                                                // in future we must add cfg data in order to check that the device can be compatible with the type requested (in/out)
                                                // and other cfg data in order to set a customized topic to send/publish and receive/subscribe messages 
                                                //              >>> (now we use a def cfg (out:shelly 1 and in:shelly ht) in mqtt ) 
                                                // 11:{sn:'shelly1-34945475FE06',types:['in,'out'],subscrptiondata:{in:{},out:{},publishcfg:{}}
                        }
      };
 
 
 
 > fv3
 
 
   socket.on('startuserplant', function (plant_,feat) { // user press button to connect to some plant, so this event is fired , feat url enc

	   plantcnt=model.ejscontext(plant_),// ejs context=plantcnt={pumps:[{id,title},,,,]}
	    plantconfig=model.getconfig(plant_),// 
	    plantcfg=model.getcfg(plant_);// get plant cfg from available pool. : return plants[plant].cfg;
	    eM = ccbbRef(plantcfg.name);// ** il fsm recupera/crea un siglethon x plant , state to be updated with recoverstatus()
	 
	 
  		recoverstatus.call(eM,plantcfg,plantcnt,plantconfig).then((em_) => startfv_(em_)); // >>
 
 - function startfv_(eM){// entry point when staus is recovered from file   // // why do not use eM invece di passarlo come em_ ?
  
    let plant=eM.state.app.plantname;// or app.plantcfg.name
    let plantconfig=eM.state.app.plantconfig;
 	
     let{gpionumb,mqttnumb,mqttprob,relaisEv,devid_shellyname}=plantconfig;
    	 abilita(eM.state).then((devices)=>{   abilita2(devices);  startfv(eM);})// 
 
  - abilita(state){
 
    buildPlantDev(
 	myctls_= getio.getctls(gpionumb,mqttnumb); 												 (A)
                                          // {ctls:[ctl1,,,,,],devmap:[{devNumb,devType,portnumb},,,,]}
                                          // get pump/relais r/w devices from preferred  mqtt or gpio arrays
	myprobs_= getio.getctls(null,mqttprob,true);//   {ctls,devmap} , true = a probe/var device						(B)
                                            // get probs  read only devices from  mqtt, true means is a probe type (type='in')
                                            // + get var, intermediate status / context to be used by other algo , connectable to red note

 
 -  getio=require('./nat/io/getio.js').init(Gpio);/
 
 > getio.js
 - getctls:function(gpionumb,mqttnumb,isProbe=false){// isProb : look cfg in mqttprob , not in mqttnumb ! so in this case mqttnumb=cfg.mqttprob not mqttnumb=cfg.mqttnumb
 		resolves in :
		 		// BGT
				  {ctls:resu,// ctls=[ctl1,,,,,] ctlx:PRX, see PIRLA in mqtt 
				  devmap:resolved});// devmap=[{devNumb,devType,portnumb},,,,],release the ctl array , max time to resolve the ctl has got, some item can be null
				}
 
 	
 	function fillctls() {
 		for(i=0;i<numOfDev;i++){
 	 	PRX=doSomethingAsync(mqttnumb[i].portid,i,true);//probj={ind:i,prom:pr};// mqttnumb[i] is {portid:110,topic:'gas-pdc',varx:3,isprobe:false,clas:'var'/'out'} 	a promise
 	 						// PRX resolves in : {ctl:new fc(gp,ind,inorout,cfg),devNumb:ind,type:'mqtt'}
 
 	- function doSomethingAsync(gpio=portid,ind=0,1,2...,ismqtt=false) {// a wrapper to getio()   
		  let clas;
		  if(isProbe)clas='in-var';// temp use std shelly ht mqtt protocol  in-var:probe or var device (look cfg in mqttprob!)
		   else clas='out';// relay device or var dev (without update in browser) (look cfg in mqttnumb!), temp use shelly 1 protocol 
		return getio(gpio,clas,ind,ismqtt);// = PRX !
	 
 
		 	async function getio(num=portid, iotype(=clas), ind, ismqtt = false) {
		 	 retu=mqtt.fact(num,ind,iotype);// iotype=  'out'  or 'in-var'(look cfg in mqttprob!). retu={ctl:new fc(gp,ind,inorout,cfg),devNumb:ind,type:'mqtt'}  (= PRX)
		 
 
 mqtt.js
 
 - fact:function(gp=portid,ind=0,1,2,inorout=iotype=clas='out'/in-var'){// gp=portid,ind=0,1,2 index of 
 									//		mqttnumb(if inorout='out') or 
 									//		mqttprob (if inorout='in-var') depending on inorout !!
 									
 									// // >>  return promise resolving in  PRX=	{ctl:new fc(gp,ind,inorout,cfg)= 	
 																		{gpio=11,
 																		devNumb=0,// array index 0,1,2
 																		type=inout,
 																		cfg,
 																		cl=1(clas='out')/2(a var)/3(clas='in'OR'prob'),
 																		isOn,
 																		readsync,
 																		writesync},
 															devNumb:ind,
 															type:'mqtt'} 
 									
 	 cfgf=mqttnumb;if(inorout!='out')cfgf=mqttprob;// (***)
        let cfg=cfgf[gp];// dev cfg from model, can be :
        							(A) anumber: mqttnumb , being inorout='out'  because of isProbe 		>> now qttnumb can also contains same cfg of mqttprob
        						      or (B)a map:mqttprob
        						      
        						      >>>>>>>>>>><
        						      now A e B = {portid:110,clas:'var'/'out',  
										      	   // if 'out'  +
											 	protocol:'shelly',subtopic:'shelly1-34945475FE06',
										      	   // if !'out'  +
											 	topic:'gas-pdc',varx:3,isprobe:false}
        						      
  
 	 res({ctl:new fc(gp=portid,ind=0,1,2,...,inorout,cfg),// depend on inorout the model cfg is different (see  mqttnumb,mqttprob in plantconfig)
                    devNumb:ind,type:'mqtt'}); 
                    
 -  fc= function (gp,ind,inorout,cfg){// mqtt gpio constructor new fc will return the io ctl
                                        // inorout=iotype=clas='out'/'in-var' , nb  clas in doSomethingAsync is not this.clas
 
                                // type = old :  inorout is the dev type or capability requested ,must match the config data got in init()
                                //        new :  can be 'out' for gpio like relais (cfg in mqttnumb) or 'in-var' for mqtt probes/var (cfg in mqttprob)
                                //  update : if clas/inorout='out', now we can also  have rele/pump dev ,and also var device with similar  config data  as mqttprob[i]
                                
    this.gpio=gp;// gp: the mqttnumb or mqttprob  .portid as number of the device  io ctl
    this.devNumb=ind; // the associated array  item index  as displayed in browser  and for mqttnumb case the index  in relaisEv/relais_  OR   .... /probes_
   this.type=inorout;// >>> 'out' for rele configured in mqttnumb, or in-var for probes/vars configured in mqttprob. tells where is the cfg and if is relais or probs/vars
    this.cfg=cfg;//  >>>> mqttnumb/mqttprob item  depending on inorout
 
	     this.gpio=gp;// the gpio or mqttprob id as number of the device  io ctl
	    this.devNumb=ind; // the associated rele order as displayed and in relaisEv/relais_  OR   .... /probes_
	    this.type=inorout;// 'out' for rele or in-var for probes/vars . tells where is the cfg and if is relais or probs/vars
	    this.cfg=cfg;//  mqttnumb/mqttprob item = 
	    
	    if(this.type=='out'){
		if(cfg.clas='out')this.cl=1;// rele  in mqttnumb (valued updatable in browser !)
		else this.cl=2;// a var in mqttnumb[i] of name relaisEv[i]
	    }else if(cfg.clas=='in'||cfg.clas=='probe')this.cl=3;// probe
	    else this.cl=4;// var in mqttprob (no visibility in browser)
 
 	fc.prototype.readSync = function (){
 	
 	    let gp=this.gpio

    		let resolRead=getgpio(gp,this.clas);
    		
    		.......
    		
    		
    		
    	fc.prototype.writeSync = function (val){// val 0/1, can return false if in error 
                                        // will send a topic KKUU as registered in init() conf data for the device 
                                        // todo : in dev config data we can mark a dev if is available for out (a shelly 1 relay) or 'in' a HT device
    		let gp=this.gpio;
    		
    		 if(this.clas==1)  {  
    		 		  if(val==0)message=messageOff;else message=messageOn;
    		 		  client.publish(pub_topic, message, pub_options, function (err) {....
    		}else if(this.clas==3){
					message=val;
					let {topic,varx,isprobe,clas}=this.cfg;
					let topic_='ctl_'+topic+varx;// warning we add ctl_   !!!!

        				client.publish(topic_, message, pub_options, function (err) {
				    		
    		
 - async function getgpio(gp,clas){// gp :portid
 
 		 async function rread(){
 		 	re= status[gp][status[gp].length-1];
 		 	        if(clas==1){if (re=='on')return 1;else return 0;}// relays value: 0/1
				else if(clas==2)return re;
				else if(clas==3) {// var
				    if(re=='>ctlpresent')return rread();// discard this or other  ctl presence
				    else return re;   }
 
 			nb status[] :		
 			in .........
 				plantconfig=model.getconfig(plant_),  > 
 					recoverstatus(plantcfg,plantcnt,plantconfig){ > 
 								plantconfig=eM.state.app.plantconfig;
 			
 					mqttnumb=plantconfig.mqttnumb,
      					mqttprob=plantconfig.mqttprob;// prob + var state cfg array
      					
      					for(i= ...  in mqttnumb,mqttprob :
      						  	let dev=mqttnumb/mqttprob.portid;
						       futurecb[dev]=null;// it will be filled by the request of a dev ctl
						       status[dev]=null;// not subscribed jet !
						       statusList[dev]=[];// init list arrays
      					
 				function onconnection () {// gestisce i subscribe dal model.js  e USA la mappa inversa GENERATA precedentemente da .....   che in ricezione messaggi uso per trovare i devid e l'instance mqtt del plant 
 				
 				  
    					 mqttnumb.forEach((val) => {// subscribe all relay key/dev, registered in gpio by init(), in order to call readSync()
    					 
    					 	  let { portid, varx, isprobe, clas, protocol, subtopic } = val;
    						 if (clas == 'out') {// rele
							if (protocol == 'shelly') {
							    let topic = shelly_stopic + subtopic + shelly_topicp;// shellies/<model>-<deviceid>/relay		ex : topic=shellies/shelly1-34945475FE06/relay/0 
							    client.subscribe(topic, shelly_options, function (err) {// in bash do :
    						 		 status[key]=[]
    						 		 ......
    						} else if (!isprobe && varx != null && clas == 'var') {


								if (protocol == 'mqttstate') {
								 let  topic = 'ctl_' + topic + varx;// warning we add ctl_   !!!!!				ex:	topic=ctl_var_gas-pdc_4
                    									client.publish(topic_, ">ctlpresent", opt);// send msg with testtopic topic for debug
										

				      							 client.subscribe(topic_, shelly_options, function (err) 
			    						 		     					status[portid]=[]
			    						 		 					......
			    			if(topic){mqttnumbTop[portid]=topic;invTopic[topic]=portid;}// complete cfg to better management !		 					
			    			
    						 		 	  
 				
 					  mqttprob.forEach((val) => {// subscribe all relay key/dev, registered in gpio by init(), in order to call readSync()
 					 
 					 
 					 	            let { portid, topic, varx, isprobe, clas, protocol } = val,
								topic;

							    if (!isprobe && varx != null && clas == 'var') {// a var
								if (protocol == 'mqttstate') {// state persistant in mqtt server, interfaciable with node red 

								    topic = 'ctl_' + subtopic + varx;// warning we add ctl_   !!!!!				ex:	topic=ctl_var_gas-pdc_4
								    client.publish(topic, ">ctlpresent", opt);// send msg with testtopic topic for debug
								    
								    client.subscribe(topic, shelly_options, function (err) {// 
								    			status[portid] = [];
								    			.....
						 	 } else if (isprobe && clas == 'probe') { 
						 	 
						 	 	 if (protocol == 'shelly') {
                   							 client.subscribe('ctl_probe_' +subtopic,  shelly_options, function (err) {/		ex:	topic=ctl_probe_ht-cucina
                   							 
                   							 	 status[portid] = [];/
						 	 
						  if(topic){mqttnumbTop[portid]=topic;invTopic[topic]=portid;}// complete cfg to better management !
__________________________________

run mosquitto , on any dir :
mosquitto_sub -t shellies/shelly1-34945475FE06/relay/0 -u sermovox -P sime01 -h bot.sermovox.com -p 1883
mosquitto_sub -t Test -u sermovox -P sime01 -h bot.sermovox.com -p 1883


mosquitto_pub -h bot.sermovox.com -t test -m "hello again77" -p 8883 --capath /etc/ssl/certs/ -u sermovox -P sime01
mosquitto_pub  -h bot.sermovox.com -t test -m "hello again33" -p 1883  -u sermovox -P sime01

mosquitto_pub -h bot.sermovox.com -t shellies/shelly1-34945475FE06/relay/0/command -m "on" -p 1883  -u sermovox -P sime01
mosquitto_pub -h bot.sermovox.com -t shellies/shelly1-34945475FE06/relay/0/command -m "off" -p 8883 --capath /etc/ssl/certs/ -u sermovox -P sime01


run node-red :
	preferiti : caldaia/mqtt/top (  see MQTT With Node-Red)  e fv/best
sudo nano /etc/systemd/system/node-red.service			x cfg staff
sudo systemctl start node-red

____________________________________________________________

todo manage status x var differentemente . quando faccio start non ripristino il valore in status ma lo adeguo  quanto settato via node red .
 	inoltre/oppure quando lo status cambia via node red dovrei simulare un manual set via browser per aggiornare lo status secondo quanto sovraimposto via node red 
 	
 // allign relays current status to state.relays :
  relaisEv.forEach((pump,ind) => {//
  
  
  quindi alla partenza recupero il state o lo setto come initial state con : recoverstatus.call(eM,plantcfg,plantcnt,plantconfig,feature)
  poi usando il ctl con lo state settato da recoverstatus (con un init state o lo state recoverato dal persistant file .data/... che dovredde essre .init=true cioe pronto per girare) :
  - startfv_(em_) che :								LUUIO
	  - abilita : return devices_={myctls,myprobs} 

	  				 il device in eM/fn.iodev.relais_ e eM/fn.iodev.probes_
	  				 
	  				 
	  - abilita2(devices_):	************
	  	  	   	devices=devices_.myctls,// 	{ctls:[ctl1=new fc(gp,ind,inorout,cfg)= 	
 																		{gpio=11,
 																		devNumb=0,// array index 0,1,2
 																		type=inout,
 																		cfg,
 																		cl=1(clas='out')/2(a var)/3(clas='in'OR'prob'),
 																		isOn,
 																		readsync,
 																		writesync}
 									,,,],
 								devmap:[{devNumb,devType,portnumb},,,,]}  										
 																		
	      			probes=devices_.myprobs;// 
	      			
	      		usando builddev()// transform devices={devmap,ctls} >>  state.devMap eM.iodev.relais_  
	      		 si costruiscono (usando i ctls buildati in abilita())  :
	      		eM.iodev.relais_ e 
	      		eM.iodev.probs_
	      		che verranno usati da setPump e specificatamente da onRelais per fare io sui device e anche da altre funzioni per vedere come gestire gli i/o: ......
	      		
	      		SDDWW 
	      		
	      		
	      		
	      		
	      		
	      	-  startfv(eM)  : si impone di resettare i valori dei device (writabili: no probs !) secondo lo state recuperato 
	      		// allign relays current status to state.relays :
	      		  let relaisEv=eM.state.app.plantconfig.relaisEv;// plantconfig
			  relaisEv.forEach((pump,ind) => {// ex: ['pdc','g','n','s']// socket event to sync raspberry buttons and web button
			    setPump(ind,eM.state.relays[pump],eM);
	      		
	      		nb quando si vuole leggere i valori dei device si usa syncread . infatti :
	      			- quando in event usati da exsecute si vuole leggere un probe di eM.iodev.probs_ ( not var). es in these.on("initProg" ,,,,   :
	      			   si mappano i virtual device delle procedure execute in real device del plant caricato con probMapping
	      			   quindi :
	      			   - se il mapping è < 1000 si interroga al volo il modbus senza usare un device probe 
	      			   - altrimenti curval=await these.iodev.probes_[map[1]].readSync();// 0/1
	      			   
	      			-  per quanto riguarda i device visibili nel browser e che vengono storati nello state ( state.relays) essi sono determinati da i device di eM.iodev.relais_  che sono indicizzati in relaisEv
	      				sia che siano pump che var 
	      				>> in questo caso quando i var vengono cambiati fuori da setpump ( quindi ad es esternamente da node-red) lo stato non si aggiorna e si ha un disallineamento che viene sistemato la prossima chiamata di onRelays
	      				infatti (see **AK78) setpump che innesca 
	      					- sia il event verso browser pumpsHandler[pumpnumber](0,on_) , che aggiorna il display dei rele persistenti in state.relays e 
	      							in ogni caso ritorna con un event che chiama onRelais() (per gestire i update da browser)
	      					- che onRelais(relaisEv[pumpnumber],on_,'server',fn) che setta il device con writesync e anche aggiorna lo state.relays !!!
	      				
	      				>>>> TODO :
	      					1: in realta i button handler dovrebbero chiamare setPump() che eseguono entrambi e non il solo il suo pumpsHandler[pumpnumber]() ( da sistemare anche il passaggio parametri !!!!
	      					
	      					2: opzionale se il var relè ha un meccanismo ch permette di ricevere un listener quando viene cambiato (see mqtt subscription e onmessage) allora , controllato che il cambiamento non sia stato provocato
	      						da un locale writesync che se no si loopa , si lancia un setPump normale per aggiornare sia il display del browser che lo state relativo con onRelais ma senza chiamare writesync che se no si loopa 
	      					3 : se invece si rinuncia a aggiornare lo status da update esterni , banalmente qundo voglio usare in qualche event del execute faccio 
	      						un readsync come fosse un probe ( che non è nei state.relays displayati in browser) 
	      						e poi se voglio anche aggiornare state.ralays e relativo browser lancio un setPump con il solito avvertimento
	      							di non richiamare writesync che riscriverebbe il valore appena letto con readsync
	      							
	      					4: modifico il program execute che ha il compito di settare i rele in funzione dei sensori , preso atto del gas/pdc preference var settato da anticipate
	      						in altre parole ci deve essere un loop su base event o ripetitivo che setta i rele dopo aver consolidato i valori proposti da anticipate (storati in un var relè ) e program
	      						questo ruolo puo essere spalmato su program , su entrambi o essere a parte . piu semlice e' inserirlo in program che quindi deve essere sempe attivo !!
	      						forse e meglio rendere in program attivo di default . il lancio di program da browser semplicemente modificail programma di temperature !
	      						  
	      		
	      		
	      		
	 -   socket.emit('view', context);   response to browser 
	  
  
  	 
  - 
  
  
__________________________________________________________

{myctls:ctl1,myprobs:ctl2}= abilita() : regole nel formare la lista dei device myctls_ e myprobs_ ( in getctls(x,y) l'iesimo item di ctls e devmap è scelto tra il iesimo  device  x e y con precedenza di y se  not null

WWEERR

myctls_= getio.getctls(gpionumb,mqttnumb);
                                          // {ctls:[ctl1,,,,,],devmap:[{devNumb,devType,portnumb},,,,]}
                                          // get pump/relais r/w devices from preferred  mqtt or gpio arrays
myprobs_= getio.getctls(null,mqttprob,true);//   {ctls,devmap} , true = a probe/var device
                                       
____________________________________________________________

todo 02052023
1: usare i topics registrati in mqttnumbTop ,,,
2: correggere clas > cl in readsync          } else if (this.clas == 2) {// a var in mqttnumb[i] 
3: tornare un new da mqtt.init()

________________________________
read queue logic 

dopo subscribed riempio una queue perche qualche device puo voler leggere valori vecchi ,
		comunque al giungere di un msg la queue length aumenta fino a un max , poi si riduce la length a 2 (non posso lascirla a length max ? forse e troppo oneroso come calc ? )
		 es se un device var pub un evento di presence e poi si mette in ascolto scartando dal queue i suoi presence ?!?
	ma in genere quando vogliio leggere se c'e queue leggo l'ultimo valore  ma non riduco la queue (perche ?)
						se non c'è registro un listener e attendo che giunga un msg che passo ai listerers e poi inserisco in queue settando length=1 
	question : ma qualche readsync() una volta raccolto il dato , e' in grado di ridurre a 1 la length ? , puo o deve ?
	intanto , per i soli rele, ora prima di srivere con writesync()  si annulla il queue length !  , guisto ????????????
	
________________________________________________


todo  la parte cge gira sotto  mqttClass.prototype.start = function    ....

 e' sbagliato chiamare onconnection e sul cb fare i subscribe dei dev del plant perche il plant si  connette dopo l'avvio di mqtt. quindi bastera chiamare client,subscribe () ....  !!!


 new subscription policy , SubAfterPlantReq=true, :
 
 - mqttInst.fact(gp,ind,inorout='out') resoving in ctlpack= {ctl:new fc(gp,ind,inorout,cfg,that),devNumb:ind,type:'mqtt'};/
	 after a dev pack ctlpack was created by in mqttInst.fact we call the subscription func : 
	 	probSubscr(val,that,ctlpack,subscred) and numbSubscr(val,that,ctlpack,subscred)
	 depending from the info dev source mqttnumb and mqttprob decided by inorout!='out' :
	  inorout!='out'  is set in getio/doSomethingAsync :
	 	inorout=clas='in-var'/'out'
	  looking at isProbe
	  
___________________________________________
	  
	  console.log('  getgpio wants read buffer for dev: ',gp,', , its  dim is: ',mqttInst.status[gp].length);// todo 05052023  called 2 times ???
	  next check at gpio() : console.log(' fillctls() , now available dev ctl (devtype: ',it.type,')  dev number : ',it.devNumb);//,' promise resolved in def time in :',JSON
________________________________

nb the promises pr  in  function getio/fillctls()  resolves (for mqtt dev ) in :
						/* 05052023 got  : it={ctl:{cfg:mqttnumb/mqttprob[dev],
									   cl:1, // 1:rele ,2: var in mqttpnumb, 3: probe in mqttprob 4: var in mqttprob   .......    
									   		used WITH protocol in readsync() and writesync() 
									   			ex, in readsync() at :  
										   			resolRead=getgpio(this.cl)/ rread() ......
										   			for ex forcl=2/4 discard the itself presence published :
										   					if (re == '>ctlpresent') return rread(false);// discard this or other  ctl presence
									    devnumb:0,
									    gpio:11, // is really  devid/portid
									    isOn:false,
									    mqttInst,
									    type:'out'  //  can be out   or in-var  (?)  , check it
									    		
									    		
									    		 // iotype = 'out'   'in-var' dice dove trovare la cfg di model (mqttnumb o mqttprob)
									    		 sequence :
									    		 in   function doSomethingAsync(gpio,ind,ismqtt=false) {// a wrapper to getio()
 										1			 if(isProbe){clas='in-var';}else {clas='out';// relay device or var dev (without update in browser) (look cfg in mqttnumb!), temp use shelly 1 
r													return getio(gpio,clas,ind,ismqtt,mqttInst);
									    		 
									    		 in : getio(num, iotype, ind, ismqtt = false,mqttInst)// iotype=clas !
									    		 			
									    	2	 		retu=mqttInst.fact(num,ind,iotype);
									    		 		
									    		 in :  mqttClass.prototype.fact = function(gp,ind,inorout='out')// inorout=iotype !!
									    		 
									    	3	 		let ctlpack= {ctl:new fc(gp,ind,inorout,cfg,that),devNumb:ind,type:'mqtt',,,};//
									    		 
									    		 in:  fc= function (gp,ind,inorout,cfg,mqttInst)   // the ctl constructor 
									    	4	 		this.type=inorout;	
									    		 		
									    		 	quindi la folle catena è :
									    		 		1 clas='out'/'in-var'  >  2 iotype	> 3 iorout	> 4  ctl.type		
									    
									    
									    //  +  ctl proto func readsync and writesync should be present ! :
									    readsync(),
									    writesync()
									    
									    // add topic ???


									    },
								      devNumb:0,
								      type:'mqtt'  // 		<<<<<<<  DIFFERENT than previous ctl.type !!!!!!!!!!! because .used in ....  for .....
								      				see        // xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 
       														 let ctlpack= {ctl:new fc(gp,ind,inorout,cfg,that),devNumb:ind,type:'mqtt'};
       														 // depend on inorout the model cfg is different (see  mqttnumb,mqttprob in plantconfig)
                    
								      
								      topic,
								      cl_class // from :  subscred(resu) after subscribe cb in probSubscr/numbSubscr
								      
								    }
						    
						*/
that it should be the resolve of mqtt.fact() : ctlpack= {ctl:new fc(gp,ind,inorout,cfg,that),devNumb:ind,type:'mqtt',topic,,};  SDDWW  >>>>>>>> todo : add also a interrupt cb to dev button press ?  

nb in mqtt  probSubscr and numbSubscr  :
	 invTopic[
  maps  topic  >   {portid,mqttInst:that,topic,cl_class,protocol};  SDDWW  >>>>>> todo add also clpack so in message receiving we can do a dev button press interrupt if the message is not coming from this mqtt client !!!!!!
  cl class is the class discovered in used in subscribing 
_______________________________________
warning : gpio dev has not many property in ctl devio.relais_[index] so many console.log can give errors !
_______________________________________________
console.log('  getgpio wants read buffer for dev: ',gp,', , its  dim is: ',mqttInst.status[gp].length);// todo 05052023  called 2 times ???
______________________________________________________

06052023 : restructuring anticipate and program merge .

now anticipate()/program() : 
 * set aTT: 
	- var/ intermediate result gaspcdPrefer(virtual index 6) var and the 
	- preferred real action (in state.anticipate.suggest) on  mapped rele  :
	index of virtual rele	significato	mapped on real index 	real name suggested			mandatory 		nb in map is <0 or value=Att[i] is null , ignore it 
	
	0			termostato bt		map[0]		relaisEv[map[i]]		si
	1			attivazione pdc		map[1]			"			si
 	2			preferred zone		map[2]			"			no	
 	3			second zone								no
 	5			split valve								si
 	
 * add its suggestion to state.lastProgramAlgo/ state.lastAnticAlgo	CFDD
 
 * call consolidate or optimize to get the return 
 * return the suggestion : aTT
 *ask attuators(these,map,aTT) to apply the suggestion calling setPump (the visible relays (the mqttnumb rele/vars) procedure) : update rele info in browser ask onRelais() to write visible relays , update state.
 
 
 todo: 
 -  1 merge optimize with consolidate  dopo verifica che ci sono benefits used in consolidate che non sono ancora stati applicati in optimize ,
    then 2 start a def system execute to run a main loop execute that just run a event/injected func   that call updated optimize (that sees CFDD) then attuators
 	in questo modo togliamo l'onere di chiamare attuators da anticipate e program 
 - in attesa di 1 togliere da anticipate la chiamata ad attuators se si vede che e attivo program algo perche tanto sara lui a far girare atuators dopo optimize !!!
 		
 	 
 
 _______________________________________________
 
 review di execute , dovè ?
 intanto riprendiamo la logica di withtime :
 
 //    typescripy :import { EventEmitter } from 'events';const eventEmitter = new EventEmitter();

// js   run : node --experimental-fetch withtime.js 

let { EventEmitter }=require('events');
// import fetch from 'node-fetch';// esm module



// Example 2->Adapted and thanks to Sameer Buna

class WithTime extends EventEmitter {
    execute(asyncFunc, ...args) {
      this.emit('begin');
      console.time('execute');
     // this.on('data', (data)=> console.log('got data ', data));// AA
      asyncFunc(...args, (err, data) => {
        if (err) {
          return this.emit('error', err);
        }
        this.emit('data', data);
        console.timeEnd('execute');
        this.emit('end');
      });
    }
  }


  // try  to set proto func
  WithTime.prototype.cfg=function(){this.on('data', (data)=> console.log('got data with prototyping ', data));return this;}// AA


  const withTime = (new WithTime())
  .cfg();// AA

withTime.on('begin', () => console.log('About to execute'));
withTime.on('end', () => console.log('Done with execute'));

const readFile = (url, cb) => {
  fetch(url)
    .then((resp) => resp.json()) // Transform the data into json
    .then(function(data) {
      cb(null, data);
    });
}

withTime.execute(readFile, 'https://jsonplaceholder.typicode.com/posts/1');

>>> logica :
withtime costruisce un event stile procedure basandosi su un event manager (event emitter)
- combina event emitter chain 
	> begin  >  asyncfunc(injected)  > data  >  end
 - dove gli handler degli event  begin e end sono customizzati
 	> begin lancia dei log 
 	> asincfunction  applica a param passati la asyncfunc injected 
 	> data processa il return di asyncfunc  
 		data handler è settato definendo un prototype func che lavora con this , oggetto istanziato dal class constructor 
 __________________________________________
 openapi fusionsolar huawei : see openapi1.txt
 see https://forum.huawei.com/enterprise/en/communicate-with-fusionsolar-through-an-openapi-account/thread/591478-100027

plant :
{
    "data": [
        {
            "aidType": 2147483647,
            "buildState": null,
            "capacity": 0.005,
            "combineType": null,
            "linkmanPho": "",
            "stationAddr": "Via Damiano Chiesa, 33170 Pordenone PN, Italia",
            "stationCode": "NE=36026831",
            "stationLinkman": "",
            "stationName": "MarsonLuigi Via D. Chiesa"
        },
        {
            "aidType": 1,
            "buildState": null,
            "capacity": 0.007,
            "combineType": null,
            "linkmanPho": "",
            "stationAddr": "Via Bunis, 27 33084 Cordenons PN, Italia",
            "stationCode": "NE=35350463",
            "stationLinkman": "",
            "stationName": "MarsonLuigi"
        }
    ],
    "failCode": 0,
    "message": null,
    "params": {
        "currentTime": 1683701642796
    },
    "success": true
}

example site : https://forum.huawei.com/enterprise/en/communicate-with-fusionsolar-through-an-openapi-account/thread/591478-100027?page=2#comments-area

postam don work , just set the poste then get curl command using <> code 

ex get token in file :

curl --location 'https://eu5.fusionsolar.huawei.com/thirdData/login' --header 'Content-Type: application/json' --data-raw '{
"userName":"MarsonLuigi_API","systemCode":"Huawei@123"}' --cookie-jar cookie_file
{"data":null,"success":true,"failCode":0,"params":{},"message":null}

ex get the devices for station NE=36026831, cioe via damiano chiesa (inverter: id=1000000036026833 s/n=HV2160184230) :

curl --location 'https://eu5.fusionsolar.huawei.com/thirdData/getDevList' \
> --header 'XSRF-TOKEN: x-9jmremrzga9hlffydhfsg7bx7v089elic53y0ajzmpqlrz1cka48nv9hbyel7t7yc7ddo6rw3s45jwlgdec4qlpcqoc7vyg5rz05k7hc4aga3zbx6pbtg8jxcbft88de' \
> --header 'Content-Type: application/json' \
> --data '{"stationCodes":"NE=36026831"
> }'
{"data":[{"devName":"INV-HV2160184230","devTypeId":38,"esnCode":"HV2160184230","id":1000000036026833,"invType":"SUN2000-5KTL-L1","latitude":45.965359,"longitude":12.678223,"optimizerNumber":0,"softwareVersion":"V200R001C00SPC130","stationCode":"NE=36026831"},{"devName":"Battery-1","devTypeId":39,"esnCode":null,"id":1000000036026834,"invType":null,"latitude":45.965359,"longitude":12.678223,"optimizerNumber":null,"softwareVersion":null,"stationCode":"NE=36026831"},{"devName":"Meter-1","devTypeId":47,"esnCode":null,"id":1000000036026835,"invType":null,"latitude":45.965359,"longitude":12.678223,"optimizerNumber":null,"softwareVersion":null,"stationCode":"NE=36026831"}],"failCode":0,"message":null,"params":{"currentTime":1686069692769,"stationCodes":"NE=36026831"},"success":true}

_______________________________________





logic of  execute(procName, evcontingencyparam, evAsyn, ev2run, processAsync,asyncPoint, dataArr_,cb)

	ev2run : event name list
		sono la catena di eventi da lanciare (sono definiti in fv3 !) su input dataArr
		es :  ev2run = {initProg:null,genZoneRele:"initProg"};
                                      :the event genZoneRele  will receive input from event initProg output


    	- asyncPoint=// asyncPoint={1:'login',,,,,}at step 1 run :   processAsync['login']={login:function(){},,,,,}.login with input  input_ = dataArr[asynckey];

	   nb  stepx : // current step index : can be reset in event handler setting this.state.stepInd!! (default is ++)
			ev2run events will be fired sequentially (step=0,1,,,) in ...
		    	with .emit(event,inputdata=dataCon[event],,)
	- dataArr= {initProg:{dataArr:sched}, genZoneRele:{dataArr:sched},login:'sometext'}
			> std input x genZoneRele is sched , but initprog add its result : dataArr.genZoneRele={dataArr:sched,initProg:{}} 
	
	-     evAsyn={evname:asynctorun,,,} : asynctorun  is the async to run before fire its associated  event, input x asynctorun is : dataArr[evname].processAsync
                                      the asynctorun cb(data)  will set dataCon[asynckey]=date if data not null     ....... still valid ???


>>  goonstep  : // called by Outerfunction:  will wait cb then call this goonstep() togoon a step.   nb :  in pratica e' un iteratore !!!

  - allo stepNum (index of the ex2run and ... ) se ho registrato un async in processAsync e se ho previsto (in asyncPoint) che allo stepNum devo lanciare un async
  	lancio il async asyncNam
  		che ha come input
  		 e output 
  	
	let step=prolist[stepNum],// event ev2run[stepNum] at current step
        asyncNam = asyncPoint[stepNum]; // ex  asyncPoint={1:'login',  quindi asyncNam='login'

        if ((asyncNam )) {
          if (processAsync[asyncNam]) {// run here the (login) async before fire the event    >>>>>>>>>> ???????????????????
          				// ++++   no qui verifica se login e' in processAsync !!!!!!!!!!!
            noasync=false;
            runAsync(asyncNam)
                              .then(() => runEvent(step));
		.....
		
     - run runEvent(step);
        runEvent(step);// can return after a client defined event chain
         // Outerfunction will wait cb then call this goonstep() togoon a step
      };// ends goonstep_
 
 
 
>>  async function runAsync(asynckey) // run async associated to event with input=dataArr[asynckey].processAsync
 
	run 	asyncFunc = evAsyn[asynckey] : // +++   ma qui considera evAsync[login] come async func !!!!!	 ex in step 1  asynckey='login' , asyncFunc = evAsyn.login
		dataCon[asynckey] =asyncFunc( input_,
		  // was ...args chained from excute args
		  procName, evcontingencyparam,
		   evAsyn,   // 
		    ev2run, evAsync,
		     processAsync, // ++ so processAsync are just made avalable in event async func !!!!!!!!!!!!!!!!!!!!
		      dataArr,
		   	// no mere used :  cb=() // get data feedback and fill input for associated event : 
			//	....  if (data) dataCon[asynckey] = data;		  ....... still valid ???
		  	//)
						>>> so in fv3 posso dare il async come ad es :   evAsync={login:fx,,,}
									fx=async function( input_, // calcolato come :  =dataArr.login.processAsync,	>>>>>>>>>>><  ????  non coerente con POLK
											// + same param as execute call
											procName, evcontingencyparam, evAsyn, ev2run, processAsync,asyncPoint, dataArr_,cb))
											{
											
											.....
											// we can call other general Async like withtime.js
											dataCon['login'] =await processAsync.agenAsinc(
													any obj in dataArr/dataCon can be used as input
													
													);
											......
												console.log(dataArr.genZoneRele.initProg,dataArr.login,dataArr.whayeveryouwant);
											.....
											
											// no more returning calling cb : cb(err, data) ,//  so output data is put in :dataCon['login'] = data;// nb dataCon is dataArr updated !   POLK 
											return data
											},
		
			nb in fv3 we put processAsync.agenAsinc=async function (x){
									return itsoutput
									}  
									
 
 
      
>> function runEvent(myev) 
	lancia il event chiamando : var emmitMyev = OuterFunction(par1, myev).call(that,null) 
	      console.log(' runEvent(): promise was started ( probably terminated)  , event ', myev, ', ev2run is:', ev2run,' con input: dataCon : ', dataCon, ', dataInv(quali eventi sono alimentati): ', dataInv);
	      
	     
>> function OuterFunction(par, ev) : setta il context del returned innerfunction : cb del inner  , updateData_(err, data), che:
								-  setta il output del event sul uno dei event da processare successivamente 
								- chiama  goonstep(data); per processare il next step 
							
>>   function InnerFunction(newin)  : setta input e lancia il event ev che chiamera il cb updateData_   
	function InnerFunction(newin) {// >>>>  <InnerFunction rename in :runevent, 
                                      // newin can force the new input instead of std input ev2run[ev]
        let inp = newin || 
          dataCon[ev];// no :ev2run[ev];
        console.log('pilo, innerfunction(), event: ', ev,' , inp: ', inp,' dataCon: ',dataCon);
        this.emit(ev, inp, updateData_);	
        
        
question : can async be used inside customized event handler (ex: initProg)  ??		

async structuration 

in execute e un main non async che realizza un for/loop costruito con goonstep 
 usando call to innerfunc che chiamo .emit(event,cb) che sono sync e che con il cb loppano/iterano su goonstep e poi vanno a far morire il thread al ritorno dalla call .emit()
 e usano il primo livello di async func (posso usare il comodo await) come promise.then() quindi facendo uscire il thread 					 	     
 quindi se voglio usare nei customized handler degli async (non sere recuperarli dai param di execute essendo disponibili in fv3 (?)))
    non posso far tornare l'andler che altimenti esco da .emit() senza prima eseguire il suo cb . ma andrebbe bene lo stesso tanto dopo l'emit esco dal loop !
    quindi si potrebbe nel handler .on(fn,cb)  fare in fn() :
    ...
      promisex.then(cb)
      
      oppure dichiararlo addirittura come async !!! tanto cosi che esco subito dal .emit()  !!!
      		>>>> infatti è cosi fatto in these.on('openapi',...  !!!!!!!
______________________________________________

  todo   quando si ferma debug point il socket viene perso
  	sistemare l'errato input del plant 
_______________________________

    >>>> tieni presente che i commenti di sopra non sono aggiornati . la modifica principale e' che ora :
     
      - resolve of mqtt.fact() : ctlpack= {ctl:new fc(gp,ind,inorout,cfg,that),devNumb:ind,type:'mqtt',topic,,};  SDDWW  >>>>>>>> todo : add also a interrupt cb to dev button press ? 
      - resolve of getio = mqtt.fact
      - resolve of pr=doSomethingAsync is mqtt.fact 
      - resolve of pr è it=mqtt.fact 
      	>    05052023 got  : it={ctl:{	cfg:mqttnumb/mqttprob[dev],
                           		cl:1,
                            		devnumb:0,
                            		gpio:11,
                            		isOn:false,
                            		mqttInst,
                            		//  +  ctl proto func readsync and writesync should be present ! :
                            		readsync(),
                            		writesync()

                            		// + from  from :  subscred(resu) after subscribe cb in probSubscr/numbSubscr
                            		topic,
                            		cl_class
                            	},
                      		devNumb:0,
                      		type:'out'
                    }
    
    	- resolve of getio.getctls is resolve({ctls:resu,devmap:resolved})   see WWEERR
    	
    	- quindi   abilita()  return devices_={myctls,myprobs}   sarà : 
    		myctls_= getio.getctls(gpionumb,mqttnumb);
                                          // {ctls:[ctl1,,,,,],devmap:[{devNumb,devType,portnumb},,,,]}
                                          // get pump/relais r/w devices from preferred  mqtt or gpio arrays
		myprobs_= getio.getctls(null,mqttprob,true);//   {ctls,devmap} , true = a probe/var device

  	- in abilita2() settiamo finalmente usando builddev():
  	eM.iodev.relais_=[ctl1,ctl2,,,,]
__________________________________

  button press interupt management VVCC
  
  in abilita, see HGGB e (see **AK78 e LUUIO) :
  -  buildPlantDev(){// build here the plant ctl devices (ctl/eM/fn).iodev.relais_ dev/pumps (+ /button switch) and their handlers  
  
  		>>> attenzione gli handler erano def come handler dei button di raspberry che lavorano con un solo plant 
  		ora i button vanno mappati sul ctl del plant , ogni plant ha ctl eM e dentro esso i suoi handler che interfacciano il browser via socket emit .
  		 quindi il handler va messo come eM.
  
     si costruiscono i ctl che vengono poi inseriti da abilita2 in state.devio  che sono usati da on e altri per lavorare con i dev .
     in particolare stePump e' l'handler che updata sia il browser che il state e i devices via onRelais()
  	
  	>> quindi nella creazione dei dev in abilita devo portare un cb che aggancia setPump come interrupt di message var settati dal esterno (come se fosse chiamato un setPump)
  	
  ora altermine della recuero/creazione/update di stato dal persistant del plant ctl (eM/fn) esso reagira agli input ( button press o device interrupt  + event handler del websocket firate dal browser) 
   quindi applico i interrupt da device come ho applicato il handler dei button !!!!
   
   nota che il plant ctl eM e' creato in un closure che e' il cb di una connessione socket. in un handler di evento socket lo faccio gestire chiamando funzioni di eM
    es in socket.on('pump'  handler chiamo un metodo onRelais(pump,val,coming,eM) che lavora con i dati func del ctl eM
    
    modifiche da fare :
    see SDDWW per le modifiche da fare sul interrupt  
    
    done : sunto 
    
    in  client.on('message',    handler :
    
    	- dal topic si recuperano i oggetti registrati :
    	  if (adev=regTopic(topic) ) {//just returns invTopic[topic], useless !

            let dev=adev.portid,mqttInst=adev.mqttInst,
            ctlpack=adev.ctlpack;// ctl=ctlpack.ctl
         - se e' dev tipo var allora chiamo il interrupt registrato sul ctl.int, al ritorno butto via il thread
            
               
___________________________________________________________________________

testare e verificare come al primo richiesta di un plant da un browser venga creato e messo in pool (started[name]) il eM plant controller che viene completato con la configurazione dei device eM.devio.
quandoo il browser si scollega il eM continua a lavorare e quando un nuovo browser richiede il plant si va a recuperare il eM da pool  poi ricostruito il .state e il .devio :
	>>>  see in abilita(): 
		// GGTTFF
		eM.pumpsHandler={}; // not the super . the app can have many browser connected each one with its handler to manage the update of the browser
		   //  only one plant will have the button handler set  as its pumpHandler !!! so set a flag the first plant get the button association end the other nothing !
		eM.iodev={};

	question : e' necessario riapplicare tali 2 ricostruzioni se il recupero avviene da pool? come e' possibile che nel pool tali 2 ricostruzioni siano diverse da una nuova ricostruzione (abilita e abilita2)  

_______________________________________________

ricorda :
function stList(){//(dev,token){// return a promise that is resolved when a listener , added to a dev listener list, is called with the next  msg
    // todo : add a reject to fire after a max time is reached
____________________________________________

        /* now when a  var subscribe, are sent 2 message :
        1: '>ctlpresent'
        2: no more :the def var , it will be set at first write !

        se vogliamo inviare (con .subscribe() ) il presence sullo stesso template, dobbiamo lavorare su message handler( client.on('message', ...) e readsync() x evitare 
            che venga letto quando si vuole leggere un valore con readsync.  2 strategie:
        a) inserirla nel queue (client.on('message',,)) quando arriva il >ctlpresent ,  e quindi impedire di leggerlo dal readsync, lanciando un listener stList() anche piu volte (se il >ctlpresent viene mandato 2 volte dal brocker),
        b) non inserire >ctlpresent nel queue  da parte del  (client.on('message',,)) .
        b) e' da implementare ancora  


        */
_________________________________

    mqttinst.statuslist
    
      ricordarsi che siccome con setPump firo sia onPump che il browser che chiama onPump avro 2 richieste di lettura e quindi di listener in readsync    !!!
      
      inoltre se ricevo 2 >ctlpresent in un dev var  al secondo ricezione farogirare i pool corrente dei listener e il primo aggiunge un altro listener alla coda per un futuro msg
      	 quindi alla fine del girare il pool avro un listener in piu' che va mantenuto . quindi il pool finale saranno i listener aggiunti da pool corrente !!!!
      	 
      inoltre da aggiungere un timelimit al listener per agire. per ora settare 0 cosi readsync() ritorna la lettura (''    , would be better reject !) anche se non ho dati in coda
      	 
______________________________________

usual reading  in some fv3 event:
   curval=await these.iodev.probes_[map[0]].readSync();// 0/1 or also '' that could mean N/A   .... todo manage that case !
   
   nb in readsync according with dev info in mqttnumb/mqttprob (protocol,,,,) we adapt the device response to get values we expect. can be 0/1  or 'on'/'off' or 0/1/''  or 'on'/'off'/''=(N/A)
   its good abit have also N/A expecially in var device (protocol=....)
____________________________________________
ricordaesi che incoming message process alimenta i pending listeners e la coda con i messaggi mqtt generalmente raw (mqtt msg) o estratti da un imbustamento stabilito per il tipo di dev ( dipende da .cl in genere )
 quando si processa 'linput (readsync e relative func) allora si analizza il msg , vedendo se e' un valore 'on'/'off' o un signal ('>ctlpresence') e secondo il dev protocol si decide cosa restituire a readsync()

 inoltre si ricorda che per ora il browser usa i dev da displaiare come on/off o 0/1 quindi in setPump() i readSync sono null/''/'N/A' o 0 o intt != da 0 (cioe 1/'on')) se N/A si procedera in ogni caso alla riscrittura del valore proposto da setPump()
 
 todo  in rread gestire il fatto che in ogni caso registro in ingresso anche valori autoprovevienti  quindi :
 	- se msg è un  signal (>ctlpresence)  loopare rread per processare il next msg,
 	- se e valore anche autoprodotto leggerlo , 
 	- se timeout return null/''  
 	
 	
________________________________________________________
                   return function (lastmsg, test = 0) {// the listener . is sync function , so return to the caller (IIOOPP) after eventually added a new listener 
                                            // and eventually delete itself ref 
                                            // 05052023   dev is the devid , test to have the function id to recognize it when delete the listener reference in array
___________________________________________________________

in readSync/getgpio/rread/stList  waiting x a ext message  the entry point is the listener that will act on all func  getgpio/rread/stList relating on a request id ts 
	- ora il listener puo tornare un promise che sara soddisfatto se rread risolve o setta un ulteriore listener .
	- a questo punto il caller , processing a msg coming from mqtt :
	
		                if(!debug_int){
                    let count = 0;
                    mqttInst.statusList[dev].forEach((el) => { count++; // IIOOPP
                    
 potra aspettae che tutti i rread delle richieste dei listener stabiliscano i ulteriori listener per aspettare un next ulteriore msg e si settano i nuovi listener 
 _________________________________________________
 
 the listener are set by readsync when the dev queue is void or the last msg is a signal , the a new msg is got and the listeren runned, inside stList and the promise returned will resolve entro timeout di 0.1 s 
   - entro tale tempo rread continua e capisce se risolvo readsync o se devo richiamare un ulterire  stList() che avviene risolvendo il promise el(msg) che procede nel ridefinire il    mqttInst.statusList[dev] per il prossimo msg  :
   
   - nel frattempo il thred continua il process di ricezione :
   
   
   	e ulteriori sviluppi 
   	
   	>>> tuttavia si ha la convinzione che entro il tempo in cui processo un nuovo msg i listener siano  stati ridefiniti in BB 
   	
   	per avere la certezza entrando con new msg :
   	
   		  client.on('message', function (topic, message,packet) {// message=obj=buffer
		let msg,// the payload
		message_;// the js object
		
	dovrei checcare che il last 
        
   			>> iterListen.push(el(msg));//  el(), sync,  is the listener embedded on resolving func in stList() ! 
   			
_________________________________________ 
overview of listener fundamentals  in between the incoming msg process and the readsync process :

	in rread  stList()  return to rread a promise that resolve when the listener process the next msg.in message income.
	 rread after receiving the resolve of stlist, will 
	 - resolve the readsync or 
	 - require another listener ( because the message don allow to have a value to read)
 		to process a next msg and coerentemente risolve la promise retProm ritornata da listener quando chiamato in message income 
 		affinche esso predisponga il listener array da chiamare al ricevimento del next message 
 		2 way :
 		- (first time ) add listener to list array at the end (this wont be deleted ! ) and resolve with 
 		- resolve the promise returned after the listener is called thiw the msg ,
 		    in income msg we will analyze all promise returned to see which listener to mantain to process the next msg 
 		    
 todo sistemare la resolve del promise tornata dal listener :  PPLLKK 
 
 ________________________________________________
 sistemare :  Inserted current message ( 0 ) , in current msg queue for device: 55  is:  [ 1, '0' ]
 
_________________________________________
 	
finaly considerazioni su mqtt externa set of var dev :
- creare un subscrition su NRsubscription=+'/NReadUser/cmd' 
- cosi l'attuale topic subscriptio e usato come il 'on' del shelly solo in uscita 
- alla ricezione del newsubscription non settare il var ma settare il flag manual : state.lastUserAlgo={scad,pumps}  , anche lui in state,  con la sua durata ricevuta su msg oltre a payload pump

		il state.lastUserAlgo   nb user=state.lastUserAlgo.pumps e' il manual set recuperato dal browser o il set da interrupt se il dev e' un mqtt var  
					nb i dev puo essere rele o var con la differenza che ......... (vedi meglio in message income : .on('message',....))
						e' vero ? quindi i rele dev non hanno interrupt ???
						chiarire .......
	
	
		es in consolidate si usa in code:  JUII
		      res.forEach((val,ind)=>{
        		if(user){............
        		
        >> todo 1 aggiungere la parte  manual di consolidate nell'ultimo optimize !!
        	2 ogni volta che si setta un dev(escluso pump type ) con un algo xxx
        		- se una proposta si mette in lastxxxAlgo  (se un dev non viene proposto si lascia null)
        			quindi anche il intermedi var dev vengono proposti non settati 
        		- se un set (di solito in optimize) si verifica sempre JUII
        		escluso il super set del pump browser che ha una applicazione immediata (ma non durevole come se avesse un time out praticamente null )
	
		3 porre il presence su topic =+'/presence  dove in msg dare anche il nome del ctl fv3
			 cosi in pratica il device chiamato con writeSync() lancia un pub PP appena si setta un state.ralays[i], esso annulla il current queue cosicche un readsync successivo dovra attendere un messaggio che probabilmente sara il pub PP 
			 	immaginando che nel broker non ci sia una coda di pub vecchi al momento di emissione di PP che giungono quindi prima di PP nel message income.
			 	in ogni caso ogni volta che c'è il dubbioche un device  legga dati sporchi si trattera readsync come se fosse sempre ballerino 
			 	e si decidera il vero da farsi ( nel caso di un intermediate var) basandosi sul state.relays[var]
			 		e quando si puo scrivere (writesync()) si scrive sempre anche se il readsync() mostra che il dev ha già il valore da impostare 
			 		(si scrive lo stesso proprio perche la lettura con readsync   potrebbe essere ballerina !! )
			 
			 
			 inoltre, escludera anche che :
			 	nel subscription normale che traccera su NodeRed la statistica dello state del ctl fv3 , il reiterarsi del listener in receiving state :
			 		un listener sara sempre risolto positivamente dal nex coming msg 

		4 quindi liberati del probema presence 3 :
			- ora il interrupt dovra essere inserito dopo aver checcato i topic:
			
				si cercano i topic con base il topic di registrazione del del (che diventa un master topic )
				 poi si distingue se e' un topic di var value che verra processato as usual 
				 o se e un topic base +'/NReadUser/cmd' e in questo caso si processa la parte interrupt 
____________________________________________________________
review of OOHH , ricorda OOHH : 

				setting results in last event of execute   OOHH

				 in  these.on('last even', 
				  - if(aTT=algo())
				  
				  
				  		algo (program or anticipate)   (state,inp,,,)
				  
				  			recover input from state and inp 
				  			ret=[]/null   order according to    relaisEv=['heat','pdc','g','n','s','split'];
				  			if(ret) 
				  			
				  				 if() 	state.lastProgramAlgo={updatedate:date.toLocaleString(),probes,pumps:ret,model:'programbase'};/false
				  				 	state.lastAnticAlgo={updatedate:pdate.toLocaleString(),level:1,policy:0,algo,pumps:ret,model}/false
					  			 if() ret=optimize(ret,date,h,m);//
				  				if(ret){// program wants to set some relays, ret can have nul val that must be resolved  also looking at other proposal user+ anticipate 
				  					return consolidate(state,'program',date);
				  				else 	return null   // means no result from algo, no action at all 
				  
				  
				   	attuators(these,aTT[0],aTT[1],aTT[2],aTT[3],aTT[4],aTT[5]);//[heat,pdc,g,n,s,split] val=true/false/null   set relais x level 1, then after 1 hour (1,1,1,0), if noeco (1,1,1,1)
								                                  // ?? (pdc,g,n,s)  set relais x level 1, then after 1 hour (1,1,1,0), if noeco (1,1,1,1)
				      	res.execute=aTT.toString();/
				      	
				    else   res.noexec='no....';
				    
				  - cb(0, res);
				  
				  
				  
 reviewed : 
 
 				setting results in last event of execute   OOHH

				 in  these.on('last event of the execute algo', 		es ....
				  - if(aTT=algofunc(state,inp,,,))			aTT is he algo dev proposal x virtual mqttnumber device ( virtual devices are  virtual index mapped on virtual device : 
				  																sottointeso virtual name : relaisEv=['heat','pdc','g','null','null','split'];)
				  							in past set heat, pdc g and split , leave n and s null(not impacted) now just set var dev gaspdcPref , 
				  							them program algo use it to merge all running algo  into a final setting 
				  
				  
				  ** ora per il algo program :
				  
				  	- algofunc=program    (state,inp,,,)  promise will : 
				  
				  			recover input from state and inp 
				  			ret=[]/null   with index/order according to  a predefinite dev , the virtual dev 
				  			if(ret) 
				  			
				  				per ogni zona calcola se e' resa necessaria l'attivazione di virtual devices :  if(toact(zonelist[i],probes[zonelist[i]],inp[zonelist[i]]))
									e riempie toactivate[]				  			
				  				se trovo almeno 1 toactivate setto una proposta ret sui index virtuali  :
				  					 ret = [true, null, toactivate.indexOf('giorno')>=0,toactivate.indexOf('notte')>=0, false,null];/
				  				e setto il result nello state in particolare la proposta sui virtual pumps (parte dei mqttnumb):
				  			
				  				 	state.lastProgramAlgo={updatedate:date.toLocaleString(),time,probes,pumps:ret,model:'programbase'};/false
				  				 
				  				 ora recuperando le proposte del algo anticipate
				  				 	state.lastAnticAlgo={updatedate:pdate.toLocaleString(),level:1,policy:0,algo,pumps:ret,model}/false
				  				 lancio il optimize che fa merge di tutte gli algo attivi tra quelli definiti/previsti 
					  			 	optimRet=optimize(ret,state.lastAnticAlgo,state.lastProgramAlgo);
					  			 	
				  				return optimRet   > ritorna il valore che va in aTT
				  				
				  		 after resolved aTT , call a real mqttnumb dev setter: 
				  		
				   	- attuators(these,map,aTT[0],aTT[1],aTT[2],aTT[3],aTT[4],aTT[5]);//[heat,pdc,g,n,s,split] aTT[i]=true/false/null   set relais x level 1, then after 1 hour (1,1,1,0), if noeco (1,1,1,1)
								                                  // ?? (pdc,g,n,s)  set relais x level 1, then after 1 hour (1,1,1,0), if noeco (1,1,1,1)

				      			attuators will map index of virtual dev used by algo to real virtual dev (mqttnumb part, the visible rele/pump in brower , mqttprob are only used in execute events !)
				      			then , resolved (without use the resolved value ) call: 
				    
				    
				  - cb(0, res); //  res={execute: aTT.tostring() = the program algo suggestion }   if positive result
				  			or ..........
				  				


				  ** ora invece per il algo anticipate  :
				  
				  	- algofunc=anticipate    (state,inp,,,)  promise will : 
				  
				  			recover input from state and inp 
				  			ret=[]/null   with index/order according to  a predefinite dev , the virtual dev 
				  			
				  				dopo aver valutato i result dei precedenti eventi :
				  					 if (triggers)    { if (cloudly <= (100- triggers.FVPower)) {
				  					 >> def la proposta sui index virtuali : 
				  					 ret = [true, true, true,null, null,true,true];//l'ultimo e stato aggiunto gaspdcPref : [heat,pdc,g,n,s,split,gaspdcPref] 
				  					 
				  					 >>>>>> nbnb ora con il optimize di program algo  il intermedio var gaspdcPref dira' proprio di considerare i dev non null che sono stati settati da anticipate !!
				  					 se ndered desidera overwrite il gaspdcPref  lancia un msg con topic topic base +'/NReadUser/cmd'  che intercettato da interrupt 
				  					 settera il manual attribute proposal del device gaspdcPref che verra intercettato da optimize come risultato del algo manual
				  				
				  				setto una proposta ret sui index virtuali  :
				  					 ret = [true, null, toactivate.indexOf('giorno')>=0,toactivate.indexOf('notte')>=0, false,null];/
				  				e setto il result nello state in particolare la proposta sui virtual pumps (parte dei mqttnumb):
				  			
				  				 	state.lastAnticAlgo={updatedate:pdate.toLocaleString(),time:pdate.getTime(),level:1,policy:0,algo,pumps:ret,model};

				  				 
				  				 ora ritorno ret o se l'algo program è attivo recupero le proposte del algo program e ritorno il merge delle 2 :
				  				 	if(state.lastProgramAlgo&&ret) return consolidate(state,'anticipate');  che in effetti e' inutile ora 
									else return ret;
				  				
				  		 after resolved aTT , SOLO SE PROGRAM ALGO is INACTIVE call a real mqttnumb dev setter: 
				  		
				   	- attuators(these,map,aTT[0],aTT[1],aTT[2],aTT[3],aTT[4],aTT[5]);//[heat,pdc,g,n,s,split] aTT[i]=true/false/null   set relais x level 1, then after 1 hour (1,1,1,0), if noeco (1,1,1,1)
								                                  // ?? (pdc,g,n,s)  set relais x level 1, then after 1 hour (1,1,1,0), if noeco (1,1,1,1)

				      			attuators will map index of virtual dev used by algo to real virtual dev (mqttnumb part, the visible rele/pump in brower , mqttprob are only used in execute events !)
				      			
				      	- POI CHIUDE SIMILMENTE A  PROGRAM ALGO :
				      			then , resolved (without use the resolved value ) call: 
				    
				    
				  - cb(0, res); //  res={execute: aTT.tostring() = the program algo suggestion }   if positive result
				  			or ..........
				  				


________________________________________________________

topic usati  in  probSubscr(cfg,that,ctlpack,subscred);e numbSubscr()

   - cl_class='rele';// rele
   if (protocol == 'shelly') 
   
   		un topic x subscrbe e uno alternativo per pub :
   		qui è l'opposto che in var, essendo fv3 a comandare  :
   			- al writesync scrivo su un topic non subscribed , come se fossero scartati in ingresso
   			- il readsync e' su iniziativa fv3 e legge dal buffer . non ho interrupt
                
                > topic =  shelly_stopic + subtopic + shelly_topicp; // x publish used in readsync shellies/<model>-<deviceid>/relay/0  must be unique in all plants
                  topicPub=shelly_stopic + subtopic + shelly_topicpp;// x publish used in writesync shellies/<model>-<deviceid>/relay/0/command
                  
                  								 shelly_stopic = 'shellies/',shelly_topicp = '/relay/0';
                  								 shelly_topicpp = '/relay/0/command';command
                  								  subtopic from def in model.js :  { portid, subtopic, varx, isprobe, clas, protocol } = val
                  								  
        


   - cl_class='var';
     if (protocol == 'mqttstate') {
     
     		situazione opposta a rele:
     			- il writesync scrive sul topic base, secondo un format predefinito ({payload,source,,}),  e all'ingresso il messaggio viene scartato se proviene da fv3 altrimenti si inserisce in coda il payload
     					( si perde per ora in souce)
     				anche se non e' formattato si mette in coda , 
     				(i msg in coda  potranno essere testato se e' un presence avendo un format specifico , es >ctl..... )
     				
     			- ora in message income :
     				tenendo presente che readsync/rread, sia leggendo dallacoda che aspettando con un listener, nel caso  trovi un format specifico sa che ci deve essere un trattamento specifico (todo)
     					e considerando il read impossibile chiede un altro listener waiting the next msg nella spperanza di trovare un msg/payload senza format specifico , quindi da considerare ok per il readsync
     					
     				>>> quindi un writesync fa trovare al next readsync proprio il valore scritto a meno di ritardi o code in brocker mosquitto 
     					(da cui il fatto che il readsync non puo essere considerato affidabile, ci si fida dello state.ralays)	
     					
     				>> quindi in caso di var dev avviene l'opposto che in rele dev : scrive sul cmd topic e legge sul read sul topic base ( base url)
     					qui si scrive sul base topic mentre i cmd ( da node-red) si leggono sul cmd topic topicNodeRed 
     					
     				una volta che in message income posto che il msg non provenga da fv3 (nel caso il msg sia formattato) si alimenti la coda (+ eventuali listener) con il msg se non formattato o con il msg.payload :
     					
     				- se formattato si estrae il topic resolver adev=invTopic[msg_topic]={} dove si cerca il topic base (base url) con cui si registra invTopic
     						nb il topic base ha formato libero per i rele e probe dev , mentre per i var dev e' sempre senza '/',  mentre il cmd topic registato in invTopic come topicNodeRed, si	
     							quindi :
     							msg_topic e' il msg topic escluso i dev dev per cui :
     							topic arrestato al primo '/'
     				
     					ora adev contiene le cose che permettono di interfacciare il dev :
     						dev = adev.portid, 	// the queue associated dev to readsync
     						mqttInst = adev.mqttInst, // mqtt instance 
                    				ctlpack = adev.ctlpack,// ctlpack={ctl:new fc(gp,ind,inorout,cfg,that),devNumb:ind,type:'mqtt'}=info on dev ctl
                    			+ il cmd topic:
                    				topicNodeRed=adev.topicNodeRed;
                    				
                    		- per i var dev sara proprio la presenza del cmd dev a agganciare il interrupt che richiereda a optimize di considerare nel prossimo check :
                    			- la proposta 'manuale' per il update del var dev ! ( come avviene da browser)
                    			
                    			
__________________________________________________

richieste comando da parte di node-red sranno gestite su un canale socket in modo analogo a quanto avviene col browser !!!!
_______________________________________-
     					
     					 
     				
 			   	
 		>  topic= that.topPlantPrefix+'ctl_' + subtopic + varx;// warning we add ctl_   !!!!!   ex: @MarsonLuigi_API@ + ctl_ + var_gas-pdc_ + 3
 		
 									topPlantPrefix='@'+this.plantName+'@';// prefix for dev topics for dev type 
 									 subtopic from def in model.js :  { portid, subtopic, varx, isprobe, clas, protocol } = val
 		
 		
   - cl_class='probe';
     if (protocol == 'shelly') {
     
     
     		>      topic='ctl_probe_' +subtopic;//  subtopic from def in model.js :  { portid, subtopic, varx, isprobe, clas, protocol } = val
     		
     		
     		
    registered in mqttInst :
                
                   that.mqttTop[portid]=topic;
                   that.mqttTopPub[portid]=topicPub;
                   
    e in inverts topic > ....   :
               
               	 invTopic[topic]={portid,mqttInst:that,topic,cl_class,protocol,ctlpack};};   ctlpack=   
               	 
               	 
               	 
    * quindi in message income per var dev we intercept topic like : @MarsonLuigi_API@ctl_var_gas-pdc_3 
    									used to:
    									-  in writesync publish fv3 to node-red and x read itself
    									-  in readsync read itself , but as delay in broker can make instable the readsync we must look at state.relays and write in any  case when update  
               	 				and all extension like   @MarsonLuigi_API@ctl_var_gas-pdc_3/NReadUser/cmd 
               	 							used to 
               	 							- in readsync read topic subscrbed to node-red : the cmd that send nodered to fv3 
               	 								will do, as manual set in browser, propose a update temporaneo di un var dev :
               	 									 eM.state.lastUserAlgo={updatedate:pdate.toLocaleString(),time:pdate.getTime(),policy:0,algo: "usermanual0",
												  		defTO : 24*3600000,// one day, or shoud be the cur day end ?
												  		pumps};
												  
               	 								see socket.on('manualAlgoProposal',(pump_,val,coming) => 
               	 										{// this will be like the final part of a manual algo: propose a single pump value () to be evaluater with all other active algo by optimize ....
 _______________________________________________
 
 update 2505
 
 abbiamo cambiato lo 'interrupt' da browser , il set manual, da 
 	- il triggerare l'event 'pump' che via onRelays chiama setPump() , cioe il immediato cambio di valore del rele(device) , e del corrispondente state.relays[],
 		( in effetti il socket event 'pump', che il browser usa per forzare il valore dei rele visualizzati nel browser,
 		   ha senso in assenza degli algo mediati dalla regola optimize usata per agire sui setPump()  
  		)                                
 	- al triggerare l'event 'manualAlgoProposal' che procede  al settaggio del result obj (lastUserAlgo) del algo 'manual' che appunto concorre al settaggio dei device ma attraverso la regola optimize che coordna tutti gli algo attivi !
        
        
 todo :  ora modificare l'interrupt a ralays[index].int che si fa in message income, in modo tale che emuli quello che si fa nel eventmanualAlgoProposal 
 		nb perche non si triggera un =  event su un connection socket in parallelo al socket col browser ???
 			il che anche con gli altri event che il browser usa x interfacciarsi col il fv3 !!!!
 			
 			> forse perche nel caso dei state.relays che rappresentano i rele nel browser che aggiornano i state.relays e poi si chiama il write dello state     .......
 				  mentre ...........
 				  
 			in effetti il mqtt e' un meccanismo simile al event mngment , solo che event management agganciano i handler dei subscription   
 		       
 ________________________________________________________
attenzione che quansolancio il plant in 
	socket.on('startuserplant'
	
	 si recupera lo stato con :
	     recoverstatus.call(eM,plantcfg,plantcnt,plantconfig,feature).then((em_) => startfv_(em_)); 
	     
	     che legge e scrive di nuvo lo stato.
	     quando scrive non avendo ancora emesso 'view' ovviamente va in errore non trovando la lista dei rele buildata !!
__________________________________
open ws from a ode client : https://socket.io/docs/v4/client-initialization/

il concetto è che che voglio fare il client identify come con il browser devo richiedere, nel client node, il build del socket su un url/namespace che nel corrispondente server gestito da express su cui ho aggiunto una session e passport, e dopo che ,nel node client, mi sono  ho autenticato (non dal browser) copiando quello che fa il browser quando sul server installo il passport    !
 il che e' difficile trovare tutto cio in un modulo node-red !
 
 >> per ora una al posto di autorized ws connection a topic/event su mqtt  senza auth .
 

_______________________________________________________
nb instead of duplicating topic x device interrupt and nr mqtt socket will be better create a base topic and recognize from basetopic  (the utl of topic ) that meet some basetopic extension 
	basetopicExt={aUriTopic:handler,,,,dev1topic:devQueue&InterruptHhandlers)}
 registered in invTopic[basetopic]  !!!!
see nRsocket x mqtt 
_________________________________________________

sistemare erraro plant in ingresso
_____________________________________

store result in state 
1) in app2 alla fine di ogni execute , in function ends(stepNum,lastRunnedProcedure):

	- si updata that.state.lastRunnedProcedure con il suo algo/execute result :
		 result:lastRunnedProcedure    ,nb  lastRunnedProcedure.result.execute sono i virtual  set pump proposti nell'ultimo event handler eseguito in execute procedure
		  è il result del ultimo event handler/step  tornato via cb a updateData_(err, result=data)
		nb le date correnti (lastRunnedProcedure.GMTdate ) sono generate localmente : GMTdate
	-  se i lastRunnedProcedure.execute (setpump) non e' null:
		> si  controlla che that.state.relHistory abbia dimensione limitata e si aggiunge un item ,
		
2) nell'ultimo step di execute nel event handler si chiama un function (ex program()) che setta il last algo/execute detailed result ( ex state.lastProgramAlgo),
	in esso si setta anche i setpump proposti , vedi 1) 


store active algo param  : in anticipateFlag(set_,fn,algo,activeAlgoRes=program/anticipate)
				it store immediately using :
					return api.writeScriptsToFile(fn)	
	
___________________________________
todo 
whan calling a event handler :
these.on('genZoneRele', async function ( inp_, cb) 
 in inp_ we find dataArr, the execute input param , and some param set by previous step .
  better add also gen nfo about running execute like procname , so can be available in execute event handler 
_______________________________________________________

now optimize and consolidate merged into consolidate !
_______________________________________________

is nRsocket.js used in fv3 ?  so add to stage. no used only to study.
____________________________________

check eM , fn > socket.eM
____________________________

virtual to real device map 

 anticipate and program , if have any proposal will set lastAnticAlgo and lastProgramAlgo then EVENTUALLY call consolidate/optimize  working on virtual device
 	then calling attuators(fn,map,aTT) we map real device into real device as descripted on  relaisEv  and we set:
 	- the state.relays and corresponding devices (using writesync ) so also shown in browsers
 	

 	
 	now what hapens to intermediate virtual to real devices ??
 	probably we must run consolidate on real device and not on virtual device ? no
 	
 	
 	.....
 	so in anticipate we set intermediate virtual pump 
 	
 	
 	solution :
 		call consolidate only once
 			add in consolidate the config read from models.js , specifically the mapping of virtual intermediate to virtual pumps
 			
 		call attuators only once after consolidator  so better move consoldate into attuators
 		
 		
_____________________________________________________
  duplication in state : plantconfig and plantcfg
____________________________________________________

ancora su : io.sockets.on('connection', function (socket) {// WebSocket Connection :server is listening a client browser so now we built the socket connection, transmit to server if there are status updates 

	........
	
	  socket.on('startuserplant', function (plant_,feat) { // user press button to connect to some plant, so this event is fired , feat url enc
                                                      // inst/fn/ctl/eM :  here we create the ctl of the plant that will be passed to all the service functions 
                       .....

	quando arriva un nuovo socket viene eseguito il handler cb :  function (socket) ...
	
	il quale registra su socket vari  handler come startuserplant ,cio' è come se fosse tornato dalla closure handler.
		quindi tutte le var della chiamata handler , closure di startuserplant rimangono disponibili in startuserplan compreso
________________________________________

 add a appDevSpaceGroup property to state.app to declare the virtual dev space on witch every algo will apply ( each algo knows the role of each device and operate on them ) 
 _____________________________________________________
 
 to do   correct :
 	  {begin:null,// error todo  :  connect:null,
 _________________________________
 to do   in consolidate we work on appDevSpaceGroup=default , in future can be also algo working on different appDevSpaceGroup and will generate a different vitual merge 
 	then in attuators we merge all groups using specific map to real devices shown in browser
 		see : let aTT=consolidate(state,'program');// this is virtual dev. now all algo works on a single def appDevSpaceGroup and produce the def virtual dev set
                                      // in future can be many groups with some algo working on its group , so aTT will be a array , on wich apply a array of map 
 __________________________________________
 	
 anticipate setta il gaspdcPref , poin in program si propone il set dei rele sia per valori true che false di gaspdcPref, 
 	es essendo i probe a 20 e il desidered a 19 propongo sostanzialmente false e pero indico che nel caso di gaspdcPref posso procedere con true perche non ho superato il overpdc di 1.5 gradi 
 	e lo segnalo con una var in lastProgramAlgo . quindi in consolidate riverso il anticInterm2VirtMap.gaspdcPref (che in effetti potrebbe essere inserito nella parte bassa della proposta anticipate
 	oppure il program che dovrebbe partire essendo probe = 18.5  ma sapendo da field di lastProgramAlgo  che ci sara power tra 2 ore ( eanche che non ho piu battery)  attendo il fv 
 	
______________________________________________________________________________

storare il anticipate in lastProgramAlgo cosi calcolo le ore di lavoro di anticipate che sono il risparmo di cicli di memoria e se il min battery al mattino è 0 e anche un risparmio di energia 
__________________________________________________________
il fv3 engine sara visto come un device plc mqtt based  per un generco havac building monitor . i device saranno comandabili da fve e anche come mqtt da havac. il node red sara un circa browser open source ctl del fv3  
___________________________________________________________________________

in ioreadwritestatus si scrive lo status e si invia lo staus al browser che utilizza alcuni campi per descrivere temperature e altre var che potrebbero essere aggiunte ai devices come var per essere inviate anche a node-red !!
  in particolare le temperature che sono var di state.program set when program algo is active. 
  so if we e want to send temperature to node red we could write a mqtt var device (where we update state.program)  that can be read by node-red
  or we just do as in browser , and extract the temperature streaming from the state send in the event socket.on('status',
  _________________________________________
  aggiungere in program resul also consolidate, add also in anticipate the power read 
 _________
 
 revisionare il plant init   socket.on('startuserplant', function (plant_,feat) { // user press button to connect to some plant, so this event is fired , feat url enc
 
 	- eM = ccbbRef(plantcfg.name);// recover from bank started[name].inst or create a basic app2 instance
 	
 	- eM.socket=socket;   >>>>> interessante qui il socket , param della closure che gestisce il dialogo con uno user, e' appiccicato al eM per renderlo disponibile in altre helper richiamate con eM come param
 		es in ioreadwritestatus :
 			  console.log('sendstatus() pretty is: ',prettyjson);
   			 fn.socket.emit('status',fn.state,prettyjson);// send the status to the browser too, also if the related plant section is not jet visible !
   			 
   			 >>>> in closure che gestiche il cliente/plant per node-red aggiungeremo anche il
   			 fn.sochetNR=node-read socket !!!!
  
 	
      	- recoverstatus.call(eM,plantcfg,plantcnt,plantconfig,feature).then((em_) => startfv_(em_)); 
      	// we got status in persistance, so start the active algo that was running :
      	..........
      	
      	
      		so in startfv_ we do : 
      		function startfv_(eM){// 
      		
		      		const keepDeviceDef=true;// is true, try false
				 if(keepDeviceDef||!eM.init){// eM is not initiated (non recovered from started[name] )
				 
				 	abilita(eM.state).then((devices)=>{ 

					  abilita2(devices); eM.init=true;// flag che avverte nodered instance se posso usare il app2 (state recovered e device attached )

					  startfv(eM);})// ** start/update/recover plant singlethon ctl eM state and .....
					// .catch();
				  }else{
					  startfv(eM);// ** call setPump to allineate pump state to state.relays
					 }


				>>  da cui si vede che la prima volta creo la basic app2 instance ma poi metto a bank la app2 (eM) dopo aver recuperato lo state dal persistance e aggiunto i device con abilita e abilita2 

 	-      if(state.anticipate){...     repeatHandler(starthour,stophour,dminutes,triggers);/// activate repetitive algo anticipate 
 	- 	if(state.program){...     repeatHandler1(starthour,stophour,dminutes,triggers2);/
 	
 	- eM.reBuildFromState=false;// reset now the ctl has the procurure loaded on closure checkFactory()
 ________________________________________
 
 la logica di una app socket.io e' uguale al fsm che gestisce un input via browser 
 discussione teorica :
 
 il fsm e' un oggetto con uno stato interno che gestisce le transazioni i cui input sono gestiti da listener
   .on/get(listname,handler/listener)
   
   nel caso di piu utenti lo stato dello user viene appiccicato al listener come session  su cui lavorano i listener
   
   fsm={
   	state,// interno non dipende dallo user 
   	userstate, // vietato se ho multiuser
   	list1234:function(){},
   	helperfuncs,
   	init
   	}
   poi con il main creo il connector
   e registro sul conector i listener del fsm :
   connector.listen(listname,fsm.listx)
   pero siccome utto loggetto deve lavorare sul user state e' come se lo instanziassi aggiungendo uno userstate che il connector di solito appiccica al request.session in modo da evitare l'instanziazione 
   
   noi invece in socket.io il connector chiama un listener particolare alla connessione a cui fornisce un oggetto il socket a cui io appiccico i listener di fsm ) 
   
   connector.on('onconnect',function (socket){// closure
   	state=new state
   	fsminst=new fsm(state)
   	socket.on(listenername,fsminst.list123)
   }
    
   il che si semplifica se il fsm diventa un oggetto della clusure 
   
   
   rivedi il tutto verificando che il tutto sia ok con i suggerimenti : socket.io : seerver-application-structure   and somwere to see how to manage user state ( attach to socket !!!) 
    
   
   
   }
          
__________________________________________________________________

ripresa di come inviare streaming date a node-red :
 -1 via mqtt per i device rele come comandi 
 	( i dati vengono inviati direttamente da shelly)
 	todo : testare su dev 11 ? 
 	
 2 via mqtt per i dev var come write con topic principare ,  mentra come cmd da node-red sia invia su topic comand del device 
 
 3 per lo state via socket.io su event state . e' modo molto simile al mqtt emit su basic topic !
 	todo: testare con emitter 'status'  see  fn.socket.emit('status',fn.state,prettyjson);
________________________________________________________

warning . when read a dev var class 2 or 4 , in last implementation we read null because the device reading the mqtt subscription will discard its proper formatted message write or anyway message that is signalling
	so if no one write to dev main topic the queue will be void and the readsync will return null
	seems to remember that anyway the listener in case of void queue is disabilitated on current implementation so as usually there are nodered presence only but it will write in a coman topic only !!
		in mqtt.js see:
			console.log(' readsync() :  rread()  is reading for dev: ',gp,', current queue : ',mqttInst.status[gp],' ,request ts # ',ts);// todo 05052023  called 2 times ???
			if (checkQueueFirst)console.log(' ......   rread()  will now try to get the top of current queue ',mqttInst.status[gp]);
			.......
			
>>> thats why in readyng the current set value in var device we have null :

 stlist() : listener x dev :  55 , registered to wait for next message, in request ts # 1687555929521 , in listener position #  0  is timeout.  so cb with void message
 ** readsync() for portid  55 , is ending . reading val:  null , now current dev queue is :  []  req id  1687555929521  listener chained  0
 onRelais, coming from:  server , current rele position x dev name  gaspdcPref , is  null  asking to set :  0
_________________________________________________

remember how was built the state of fm/eM/app2 inst :

	bacic was defined in appe Status_ constructor 
	
	then was completed in : socket.on('startuserplant' 
		 after we got plant info from models.js and put plant cfg in state.
		 we call  recoverstatus.call(eM,plantcfg,plantcnt,plantconfig,feature).
	 
	 		here if we cant recover state from persistence we complete the state with plant cfg :
	 		
	 			              ctl.state.app.plantcfg=plantcfg;// add to new std state the plant cfg
					      ctl.state.app.plantname=plantcfg.name;// rindondante , giusto per compatibilita vecchia versione !!!!
					      ctl.state.app.plantcnt=plantcnt;// ex ejs context to generate pump list in browser
					      ctl.state.app.plantconfig=plantconfig;

  ___________________________________________________
              
  exiting from execute algo 
  		 execute(procName, evcontingencyparam, evAsyn, ev2run, processAsync,asyncPoint, dataArr_,cb){
  when ends() : function ends(stepNum,lastRunnedProcedure)
  	is called from a step stepNum, 
  	
  	then:
  
  	 fill:
  	 - that.state.relHistory
  	 - state.lastRunnedProcedure
  	 
  	 - but not lastxxxAlgo if the execute wont get the std last event so returns with a result (ex: HYYG): right ????
  	 
  	 >>> nb if we cant get the token or we got too many times we ends with stepNum=1001
  	 
  	 > then return to    function callFn()   with cb()
  	 	to  update the status 
  	 
  
  
  
  	 
  HYYG to do :  in antic algo execute we 
  	- extract token (if  not alredy known) in step connect then 
  	
  		- if token dont got we exit execute (calling en) because next step is 1001 (> 1000)
  		- if token was got we pass to :ds() 
  	
  	- step openapi to get api results  but if it fails ( returned null ) step will loop to step connect (known token but expired )
  		exiting the loop and goon with normal next step 
  		
  	>>>>> to avoid loop running forever limit loop to just max 2 turn of looping !!!!
  __________________________________________
  
  dev mapping 26062023  summary 
  
  - dopo device built (see getio.getctls() in abilita buildPlantDev()
  
  	buildPlantDev  si risolve dopo la costruzione dei dev info {myctls,myprobs} ,
  					dove myctls e myprobs contengono rispettivamente info sui device esposti nel browser e i device esposti negli algo , con formato :
  						 {ctls:[ctl1,,,],devmap:[{devNumb,devType,portnumb},12,,,]}, ctlx sono i controller che poi in abilita2 verranno assegnati a state.
  - in abilita2 partendo dai  {myctls,myprobs} si fillano ggli array dei dev controller , rispettivamente iodev.relais_ e iodev.probs_
  
  	- devMap e probMap elencano i device id a cui si attaccano i :
  			- real device del web browser (output rele e var) scelti tra le config (see model.js) gpionumb e mqttnumb ( priorità per i not null mqttnumb[i] al posto dei gpionumb[i]  ! )
  			- prob device  (probe e var) scelti tra la config mqttprob
  
  	ex : 
	  	    "devMap" : [
				{
				    "portid" : 11,
				    "clas" : "out",
				    "protocol" : "shelly",
				    "subtopic" : "shelly1-34945475FE06"
				},
				16,	// null if no device can be set
				20,
				21,
				26,
				19,
				{
				    "portid" : 55,
				    "subtopic" : "var_gas-pdc_",
				    "varx" : 4,
				    "isprobe" : false,
				    "clas" : "var",
				    "protocol" : "mqttstate"
				},
				6
			    ],
			 "probMap" : [
				{
				    "portid" : 110,
				    "subtopic" : "ht-cucina",
				    "varx" : null,
				    "isprobe" : true,
				    "clas" : "probe",
				    "protocol" : "shelly"
				},
  
   dve 16 sta per gpio 16  mentre gli oggetti sono 
  
    ___________________________________________________________
    
    
   revisionato  il plant init   socket.on('startuserplant', function (plant_,feat) { // user press button to connect to some plant, so this event is fired , feat url enc
 
 	- eM = ccbbRef(plantcfg.name);// recover from bank started[name].inst or create a basic app2 instance
 	
 	
 				ccbb() will 
			
				recupera ctl : inst=started[name].inst = (new eMClass()).cfg(name); 
					LLKK : NB inst.state.reBuildFromState=false
							>> qui il inst e' già operativo compreso di 
								(inst.socket) e
								inst.state.anticipating...   e 
								execute procedure regstrate nel closure .........
				o si crea :
				- crea il ctl : inst=started[name].inst = (new eMClass()).cfg(name);
					dove in .cfg(), chiamando customOn(this), : si personalizza gli handler degli eventi (non socket) chiamati da app2.js  
						NB reBuildFromState=true, so see .......
						
						
	  // poi  si registra o si aggiorna il ctl con   il socket corrente , cio permette di comunicare con la nuova sessione browser :
 	-  eM.socket=socket;   >>>>> interessante qui il socket , param della closure che gestisce il dialogo con uno user, e' appiccicato al eM per renderlo disponibile in altre helper richiamate con eM come param
 		es in ioreadwritestatus :
 			  console.log('sendstatus() pretty is: ',prettyjson);
   			 fn.socket.emit('status',fn.state,prettyjson);// send the status to the browser too, also if the related plant section is not jet visible !
   			 
   			 >>>> in closure che gestiche il cliente/plant per node-red aggiungeremo anche il
   			 fn.sochetNR=node-read socket !!!!
  
 	
      	- recoverstatus.call(eM,plantcfg,plantcnt,plantconfig,feature).then((em_) => startfv_(em_,oncomplete)); 
      			// we got status in persistance, so start the active algo that was running :
      	
	      	 		> recoverstatus:
	      	 		chiama  loadScriptsFromFile(src,ctl) ,che 
	 					se c'e' in file=process.env.PersFold+src+'.json' un processdel plant  attivo:
	 						lo  carica lo state nel ctl, 
	 							>>>> nb quando disattivare un plant ??
	 					se non c'e' init a new state sostanzialmente usando i pumps configutati per il plant : relaisEv
	 						
	 						
	 			 e poi  (LKIO):
	 			 writeScriptsToFile(scripts,plantname) in modo async (.then(),
	 			 	writeScriptsToFile chiama anche socket.emit() per updatare :
	 			 	 - file in /.data 
	 			 	 - la parte di state che e' visualizzato nel browser via 
	 			 	 			socket.emit('status',, e 
	 			 	 			nel browser socket.on('status'...
	 			 	 		es il .anticipate( )
	 			 	 			TODO   aggiungere anche i browser triggers input !!!
	 			 	 	(escluso i relays state che sone gestiti via event 'pump' , vedi anche DDRR )
      		..........
      	
      	
      		- so in startfv_ we do : 
      		function startfv_(eM,cb){// 
      		
		      		const keepDeviceDef=true;// is true, try false
				 if(keepDeviceDef||!eM.init){// eM is not initiated (non recovered from started[name] )
				 
				 	abilita(eM.state)
				 	
				 				che :
				 				return buildPlantDev();
				 					che :  async function buildPlantDev(){

											eM.pumpsHandler={}; // not the super . the app can have many browser connected each one with its handler to manage the update of the browser
											eM.iodev={};
											
											mqttInst=mqtt.init(plantconfig);// the plant mqtt instance on which works and are created  all plant mqtt dev ctl ( ctl=new fc()) 
											
												nb   init:function(plantconfig){  return new mqttClass(plantconfig);}
											

											myctls_= getio.getctls(mqttInst,gpionumb,mqttnumb);// get devices choosing from describing gpio and mqtt info array : these are the visible rele/var in browser
                                          								// myctls_={ctls:[ctl1,,,,,],devmap:[{devNumb,devType,portnumb},,,,]}
													  // get pump/relais r/w devices from preferred  mqtt or gpio arrays
													  
													  
													  in getio.getctls() :
													  
													  	return new Promise((resolve) => {  see mqttdev.txt ......
													  		resolve({ctls:resu,devmap:resolved})
													  		
													  				/*   ***********see in mqtt the func  fillProm(pr) : 
													  				
													  				ctls=[ctl1,,,,,] ctlx:PRX, see PIRLA in mqtt 
													  				
													  				
															  		   if mqtt use mqttInst factory, mqttInst.fact(), to get PRX:
															  					ctl1={ctl:new fc(gp,ind,inorout,cfg,mqttInst)= 	
			 																		{gpio=11,
			 																		devNumb=0,// array index 0,1,2
			 																		type=inout,
			 																		cfg,
			 																		cl=1(clas='out')/2(a var)/3(clas='in'OR'prob'),
			 																		isOn,
			 																		mqttInst,
			 																		readsync,
			 																		writesync : function (val){
			 																				 that=this;
			 																				if(client && client.connected && this.mqttInst.status[gp])
			 																				 topic=this.mqttInst.mqttTopPub[dev] or this.Inst.mqttTopPub[dev];
			 																				if(this.cl==1)  {  
																			    		 		  if(val==0)message=messageOff;else message=messageOn;
																			    		 		  client.publish(topic, message, pub_options, function (err) {
																			    		 		   ....
																			    		 		     console.log("Published on device ",dev," , a (no var) msg
																			    		 		      ",message,",successfully to " + topic);
																			    		 		  
																			    		 		  } 
			 																		
			 																		
			 																			}
			 																		},
			 																	devNumb:ind,
			 																	type:'mqtt'} 
													  				
																			updated example    14102023 :
																				   {
																				  ctl: {
																				    gpio: 54,
																				    devNumb: 2,
																				    type: "in-var",
																				    cfg: {
																				      portid: 54,
																				      subtopic: "var_gas-pdc_",
																				      varx: 3,
																				      isprobe: false,
																				      clas: "var",
																				      protocol: "mqttstate",
																				    },
																				    mqttInst: {},
																				    int: null,
																				    cl: 4,
																				    isOn: false,
																				  },
																				  devNumb: 2,
																				  type: "mqtt",
																				  topic: "@Casina_API@ctl_var_gas-pdc_3",
																				  cl_class: "var",
																				  protocol: "mqttstate",
																				}
													  				
													  				
													  				  devmap={ devNumb: 4, devType: 'gpio', portnumb: 26 },   			in gpio case 
													  				  	= {devNumb: 5,devType: 'mqtt',portnumb: {portid: 66,			in mqtt case 
																							clas: 'var',
																							varx: 4,
																							isprobe: false,
																							protocol: 'mqttstate',
																							subtopic: 'var_split_'
																						      }
 																		 },
 																		 
 																		 
 																		 updated example di devmap : { devNumb, devType, portnumb },   
																			abilita() buildplantDev() getctls() resolved devices in cfg x lists: gpionumb,mqttnumb. 
																			      the resolved devs map is :  [
																			  devmap= {
																			    devNumb: 0,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 11,
																			      clas: 'out',
																			      protocol: 'shelly',
																			      subtopic: '_shelly1-34945475FE06'
																			    }
																			  },
																			  { devNumb: 1, devType: 'gpio', portnumb: 16 },
																			  { devNumb: 2, devType: 'gpio', portnumb: 20 },
																			  { devNumb: 3, devType: 'gpio', portnumb: 21 },
																			  { devNumb: 4, devType: 'gpio', portnumb: 26 },
																			  {
																			    devNumb: 5,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 66,
																			      clas: 'var',
																			      varx: 4,
																			      isprobe: false,
																			      protocol: 'mqttstate',
																			      subtopic: 'var_split_'
																			    }
																			  },
																			  {
																			    devNumb: 6,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 55,
																			      subtopic: 'var_gas-pdc_',
																			      varx: 4,
																			      isprobe: false,
																			      clas: 'var',
																			      protocol: 'mqttstate'
																			    }
																			  },
																			  { devNumb: 7, devType: 'gpio', portnumb: 6 },
																			  {
																			    devNumb: 8,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 0,
																			      subtopic: 'mqtt_websock_',
																			      varx: 0,
																			      isprobe: false,
																			      clas: 'int',
																			      protocol: 'mqttxwebsock'
																			    }
																			  }
																			]
																			 abilita2(),got dev ctls x models.js lists: gpionumb,mqttnumb. relais map is:  [
																			  {
																			    devNumb: 0,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 11,
																			      clas: 'out',
																			      protocol: 'shelly',
																			      subtopic: '_shelly1-34945475FE06'
																			    }
																			  },
																			  { devNumb: 1, devType: 'gpio', portnumb: 16 },
																			  { devNumb: 2, devType: 'gpio', portnumb: 20 },
																			  { devNumb: 3, devType: 'gpio', portnumb: 21 },
																			  { devNumb: 4, devType: 'gpio', portnumb: 26 },
																			  {
																			    devNumb: 5,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 66,
																			      clas: 'var',
																			      varx: 4,
																			      isprobe: false,
																			      protocol: 'mqttstate',
																			      subtopic: 'var_split_'
																			    }
																			  },
																			  {
																			    devNumb: 6,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 55,
																			      subtopic: 'var_gas-pdc_',
																			      varx: 4,
																			      isprobe: false,
																			      clas: 'var',
																			      protocol: 'mqttstate'
																			    }
																			  },
																			  { devNumb: 7, devType: 'gpio', portnumb: 6 },
																			  {
																			    devNumb: 8,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 0,
																			      subtopic: 'mqtt_websock_',
																			      varx: 0,
																			      isprobe: false,
																			      clas: 'int',
																			      protocol: 'mqttxwebsock'
																			    }
																			  }
																			]
																			 abilita2(),got dev ctls x models.js lists:,mqttprob. probs map is:  [
																			  {
																			    devNumb: 0,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 11,
																			      clas: 'out',
																			      protocol: 'shelly',
																			      subtopic: '_shelly1-34945475FE06'
																			    }
																			  },
																			  { devNumb: 1, devType: 'gpio', portnumb: 16 },
																			  { devNumb: 2, devType: 'gpio', portnumb: 20 },
																			  { devNumb: 3, devType: 'gpio', portnumb: 21 },
																			  { devNumb: 4, devType: 'gpio', portnumb: 26 },
																			  {
																			    devNumb: 5,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 66,
																			      clas: 'var',
																			      varx: 4,
																			      isprobe: false,
																			      protocol: 'mqttstate',
																			      subtopic: 'var_split_'
																			    }
																			  },
																			  {
																			    devNumb: 6,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 55,
																			      subtopic: 'var_gas-pdc_',
																			      varx: 4,
																			      isprobe: false,
																			      clas: 'var',
																			      protocol: 'mqttstate'
																			    }
																			  },
																			  { devNumb: 7, devType: 'gpio', portnumb: 6 },
																			  {
																			    devNumb: 8,
																			    devType: 'mqtt',
																			    portnumb: {
																			      portid: 0,
																			      subtopic: 'mqtt_websock_',
																			      varx: 0,
																			      isprobe: false,
																			      clas: 'int',
																			      protocol: 'mqttxwebsock'
																			    }
																			  }
																			]
 																		 
   																	nb portnumb can be: null (if ctl is null)  / portid-portnumber number / descr obj in models.js (if mqtt)		  				
													  				
													  				
													  				*/
													  				
													  				
													  		
													  			ctlx/PRX is got using :
													  			getio(num, iotype, ind, ismqtt = false,mqttInst) 
													  				that returns (PRX) {ctl={readsync,writesync,,,},devNumb:ind,type:'gpio'} that can be:  
										  			
													  				- mqttInst.fact(num,ind,iotype);// factoty of dev ctl , a promise resolving to :
													  				
													  				  {ctl:new fc(gp,ind,inorout,cfg),devNumb:ind,type:'mqtt'}  //   = PRX , see in mqtt code !!!!!!!!!!!!!!!
													  					
																		//  a relais if iotype='out' a pump or var
																		//    or if (iotype='in-var', a probe or var
																		//  mqtt dev 
																		// iotype: is the capability requested and must match the dev registration data done in init()
																		
																		or if(Gpio)return:
																	-  {ctl:new Gpio(num, iotype),devNumb:ind,type:'gpio'}; // as Promise.resolve
																	
																	
																	nb in fact() we run numbSubscr(val,that,ctlpack,subscred) and  probSubscr(cfg,that,ctlpack,subscred)
																	
																				that sets some dev  property in mqttInst itself , like :
																				- that.mqttTopPub[portid]=topicPub, ..... 
																				- that.status[portid] = [] subscribe queue read by readSync 
													  
													  
													  
											myprobs_= getio.getctls(mqttInst,null,mqttprob,true);//   {ctls,devmap} , true = a probe/var device. invisible in browser
 
											return   new Promise(function(resolve, reject) {
				 								myctls_.then((ctl1)=>{myprobs_.then((ctl2)=>{// all resolved
                                								resolve({myctls:ctl1,myprobs:ctl2});// DDQQAA
				 	
				 	
				 	
				 	
				 	
				 	.then((devices)=>{ //  devices={myctls,myprobs} ,usati poi per def :il device in eM/fn.iodev.relais_ e eM/fn.iodev.probes_
	  				 
	  				 
				 	

						abilita2(devices); eM.init=true;// flag che avverte nodered instance se posso usare il app2 (state recovered e device attached )
						
						
							*/
									che : 
						
							  	  	   	devices={myctls: 	{ctls:[ctl1=new fc(gp,ind,inorout,cfg)= 	
 																		{gpio=11,
 																		devNumb=0,// array index 0,1,2
 																		type=inout,
 																		cfg,
 																		cl=1(clas='out')/2(a var)/3(clas='in'OR'prob'),
 																		isOn,
 																		readsync,
 																		writesync}
				 										,,,],
				 									devmap:[{devNumb,devType,portnumb},,,,]
				 									} ,										
 											myprobs:	{}
 											}			
 														
 										devices=devices_.myctls;		
	      									probes=devices_.myprobs;
	      			
								      		usando builddev()// transform devices={devmap,ctls} >>  state.devMap eM.iodev.relais_  
								      		 si costruiscono (usando i ctls buildati in abilita())  :
								      		eM.iodev.relais_ e 
								      		eM.iodev.probs_
								      		che verranno usati da setPump e specificatamente da onRelais per fare io sui device e anche da altre funzioni per vedere come gestire gli i/o: ......
								      		
								      		SDDWW 
													
						
							*/

						

					  	startfv(eM);})// ** start/update/recover plant singlethon ctl eM state and .....

				  		}else{
					  	startfv(eM);// ** call setPump to allineate pump state to state.relays
					 	}
			cb();
			}// ends startfv_
				  
				>>  da cui si vede che la prima volta creo la basic app2 instance ma poi metto a bank la app2 (eM) dopo aver recuperato lo state dal persistance e aggiunto i device con abilita e abilita2 
				
  const oncomplete_= function oncomplete(){

     displayView(eM.state.app.plantconfig.relaisEv,state);// return emitting event 'view'  to browser
                                  // was in abilita2() 


     if(eM.reBuildFromState){// we got status in persistance, so start the active algo that was running 
     
 	-  if(state.anticipate){...     repeatHandler(starthour,stophour,dminutes,triggers);/// activate repetitive algo anticipate 
 	-  if(state.program){...     repeatHandler1(starthour,stophour,dminutes,triggers2);/
     	eM.reBuildFromState=false;// reset now the ctl has the procurure loaded on closure checkFactory()
     }
    }	
________________________________________

session.socketId 
 question : quando nasce un nuovo connection col suo socket eM viene recuperato ed assegnato al nuovo connection closure. question : il vecchio closure continua a far girare il repetitive active algo ???	
 
 __________________________________________________
 
 usare il  if(!clientDiscon)// when client disconnect it useless run function that will emit browser .emit , because no connection is available
 non solo in setPump but before all .emit call . the browser is unavailable so dont send any emit to a unconnected socket !!!!	
 
 ________________________________________________
 
 onRelais is called by : startfv,attuators e abilita2.
 usa :
 
    let session=fn.getcontext.getSession(),
   clientDiscon=fn.getcontext.getCliDiscon();
   dove getcontext is set when in closure :    socket.on('startuserplant',closure)
   	 in   ccbb()     we  recover/create the eM and set the reference eM to bank of instances started[name].inst
   	 
   	 
   	 
   	>>>>>   nb 
   	1: insted of decide if goon with browser req using var recovered from eM.getcontext e eM.state.discFromBrow/blocking  we can put the logic in a cb of eM.getcontext
   	2: perhaps is useless to use 2 vat to store closure staf : eM.state.xxx   and eM.getcontext.xxx    use a single container ,
   	 for ex getcontext so
   	 	a)  put discFromBrow/blocking directly in eM.getcontext instead of eM.state
   	 	b)  let discFromBrow/blocking in closure and set the cb in eM.getcontext.processBrow=function(){}
   	 	>>>> forse e ancora  meglio solo avvertire il browser di non inviare il doppio req a onRelais !!!!!!!!!!!    >>>>>> todo todo .......................
______________________________________________

ancora sul cambio di socket :
quando un socket dsconnect ( NO : a parte setPump())  altre funzioni continuano a emettere socket.emit('someevent',func)  che chiaramente andranno a perdere se il socket è disconnected.
	es: qundo il anticipate setta qualche pump viene chiamato da anticipate il setPump (fuori closure ) che chiama 
	- sia il browser via  la var del closure pumpsHandler . essa in abilita2 (nel closure)) si fa riferire alla var di eM eM.pumpsHandler(fuori closure)  e assgnato alla func watchparam (nel closure ma sarebbe meglio metterla fuori closure) 
	- che direttamente il onRelais che e' fuori dal closure !! e lavora solo su eM
	se togliessi il ref che da x chiama un event pump  (nel closure alora il closure pu essere garbaged collect )
		quindi , todo, quando il closure disconnect il socket va tolto il rif di pumphandler a eM.pumphandler 
		infatti al nex browser connection si crea un nuovo closure per il socket e in ccbb() si ripesca il eM (fuori closure) e si riassegna 


ora quaando un nuovo connection apre un nuovo socket su una nuova closure noi alla richiesta di  socket.on('startuserplant',...) :
	- si riassegnano in eM le cose relative al nuovo socket / closure :
	-   eM.getcontext
	-  em.socket 
	-   in recoverstatus : 
			- eM.sate viene recuperato dal file 
			- state vene completato da var dipendenti da plant : 
				ctl=eM
			 	ctl.state.app.plantcfg=plantcfg;// add to new std state the plant cfg
			      ctl.state.app.plantname=plantcfg.name;// rindondante , giusto per compatibilita vecchia versione !!!!
			      ctl.state.app.plantcnt=plantcnt;// ex ejs context to generate pump list in browser
			      ctl.state.app.plantconfig=plantconfig;
			      
			- si azzera relais state :   ctl.state.relays[pump]=false;/
	- ora a seconda che l'instanza sia gia stata generata da browser precedente:
	
		eM.init) true 
		-   startfv(eM);
		
		
		
		eM.init) true 
		- abilita     // build here the plant ctl devices (ctl/eM/fn).iodev.relais_ dev/pumps (+ /button switch) and their handlers 
		- abilita2   // redefine eM.iodev.relais_ and eM.iodev.probs_ e state.devMap e  state.probMap
			     //  reset pumpsHandler[ind], to call browser socket  emitters x 'pumps'
		-   startfv(eM);	
		
		
		>>>> si vede che qualche reset è inutile ( es lo state reload and the plant config staff )	
			ma la cosa principale e' che vengo attaccti al nuovo closure/socket  i device ctl che permetteranno agli handler dei socket listener di lavorare sui device	
				es 
					i listener degli event pump
					i eM.pumpsHandler=watchparam  chiamati da setPump ( chiamato sia da closure (stato iniziale  ) che fuori (algo))   essendo
						 watchparam  function del closure chiamerà gli emitter del socket/closure !!
						> in pratica eM.pumpshandler ha un ref del closure (watchparam)  che lavora sul socket .emit('pump'...
							e i handler dei socket event 'pump' verranno agganciati a onRelais che e' fuori closure passando il ref eM (bank degli eM fuori closure )
							 che potra agire sui device
							 
					SUMMARY  - quando il socket disconnect si potra togliere tutti i rif esterni al closure percge nessun handler di eventi nel closure
							potra chiamare eM e nessun socket event emitter potra essere chiamato da funzioni fouri del closure 
							
							soluzione definire tutti le var  esterni alla closure che puntano a funzioni della closure  su un unico obj da resettare quando ho il disconnection !!!
							
									lista external var/func che puntano a oggetti nel closure:
									es
									- funzioni di socket io che chiamano gli handler registrati con socket.on ()  .
										 tali  rif si spera siano resettati da socket.io
									- setPump usa eM che ha var (eM.pumpshandler) che punta a una funzione di closure: watchparam  ; 
										quindi bastera inserire in on('disconnect',,,   eM.pumpshandler=null e 
											naturalmente testare se esso e' null non eseguirlo 
									
							
						- sebra inutile invce ridefinire i device in eM che possono stare in eM perche non cambiano al variare del socket connection !!!!
  

meglio sarebbe distinguere le funzioni lanciate quando il closure non viene disconnected e qulle lanciate dai  repetitive algo e verificare che il closure puo essere garbage collected !! 
  }
  __________________________________________
  
  todo : 
  
  nb ora il context in eM.getcontext va bene ,ma comunque e' meglio chiamare il event 'pump' da setPump in modo che non risponda chiamando onRelais !!!!!!!!!!!!!!!!1
  ______________________________
  
  working mosquitto x openremote:
  - mosquitto_pub  -h 192.168.1.213 -t master/client123/writeattributevalue/writestring/3fkopVxPrC3Cz7u5GqztUR -u master:mqtt_user2 -P ZSxwu2AwfGYb0EJ4D9mJK7TkSmfLZbkK -i client123 -m '{"ciao13": 1234}' -p 1883
  - mosquitto_sub -t master/client123/attribute/subscribeAttribute/3fkopVxPrC3Cz7u5GqztUR  -u master:mqtt_user2 -P ZSxwu2AwfGYb0EJ4D9mJK7TkSmfLZbkK -h 192.168.1.213 -p 1883 -i client123

	- x ext brocker link to a text attribute :
	mosquitto_pub -h bot.sermovox.com -t shellySN -m '{"prova":"9"}' -p 1883  -u sermovox -P sime01

_______________________________________________________________

nodered pubs and subscr
 - var dev type , protocol == 'mqttstate' :
	- when subsc var to topic : topic=that.topPlantPrefix+'ctl_' + subtopic + varx		AAOO
			topicPub= null   ????? is not set, so we writeSync on same topic used to read 
			topicNodeRed=topic+nodeRedp;// subscribed topic to receive from node-red 
							// questo topic simula, qui sulla app, il subsciption del topic ..../command sui schelly 
							// quando si ricevera un msg con questo topic si fara quello che shelly fa quando riceve un msg sul subscribed connand ::
							//   trasferire il command come val e quindi publicare nel topic il new val update !!!
							//	quando il dev riceve l message sul subscribed topic ci si accorgerà che e' diverso dal state.relais 
							//	( che acquisisce subito lo state proposto da writeSync)  
							// solo che (TTVV) : 
							// 	mentre con i device shelly (rele / out) si lancia (still todo)  un interrupt dopo un check tra :
							//		- il received msg on topic,  
							//		con 
							//		- il expexted state state.relais 
							// qui  si lancia direttamente un interrupt AAQQWW !!!!
							//		probabilmente l'interrupt agirà solo se lo state.relais non è congruente con la richiesta del node-red !!
							
							
							// logica dei var dev :
							// - quando un algo si cambia state del dev su state.relais e 
							//	scrive/pub nella stesso topic un val formatted  : {payload:load,sender:{plant:Plant,user:portid}}, cosi da riconoscere il sender
							//	azzerando il queue  del topic
							//   immediatamente doppo in receiving message, on topic (!isCmdTopic) , we recognize the msg coming from itself , so no interrupt
							// - quando invece è il node-red a scriver sul topic topicNodeRed  (isCmdTopic) allora emettero un interrupt !!!!!
							//			nb can a msg on topicNodeRed be come from itself ???? probably not , >> correct 
							// in sostanza in questa implementazione il topic AAOO serve solo a registrare i set di this ctl ma non ha effetto pratico 
							//	solo message su  topicNodeRed (isCmdTopic)  hano effetto via interrupt ! 
							
							// se usiamo or al posto di node-red  topicNodeRed e da usare come un shelly cmd topic e va usato per traccare i cmd
							// se voglio posso anche da or cambiare stato pubs su questo topic 
							//  mentre al solito il topic puo essere usato per traccare il var !!! : 
							
							
							
			
       			topicNodeRedPubish=topic+nodeRedpp;// topic used to publish to a node-red subscription 
       							// probably can be used to inform node-red that this ctl pubs alredy  on dev topic  AAOO 
	
		nb il subscribe serve ad alimentare il readsync che in var type serve solo a verificare che non ci siano cambi di stato provocati da publisher esterni
			infatti al writesync  si alimenta il subscribe topic ma il .sender è fromthisctl

	- subscribe the node red pub: client.subscribe(topicNodeRed,  useless handler )  ???
	- register topic : that.mqttTop[portid]=topic
	- register staff to manage incoming topic :  invTopic[topic]={portid,mqttInst:that,topic,topicNodeRed,cl_class,protocol,ctlpack};}
  	- as is var register same staff for topicNodeRed :  invTopic[topicNodeRed]=invTopic[topic];// duplicate entry for cmd topic
  	- register write pub topic : mqttTopPub[portid]=topicPub // null??
  		nb when writesync we pub to it and update the persistant state (relais ) without check the subscr topic ( infact we dont public on it : incoming message cant come from itself !
  			if someone change the state it will pubs to topic but we really dont use to check (with readSync) topic message changes ( from the state.relais set with last writeSync) 
  				(infact readsync is called only to check the dev state when we writesync !!!) 
  			
  			
  	>>  at the income message we :
  			
  			- recover staff : adev = regTopic(topic), ctlpack = adev.ctlpack={ctl:new fc(gp,ind,inorout,cfg,that),devNumb:ind,type:'mqtt'};
  			- is var , so :
  			- fromthisctl = true, isCmdTopic=false;
  			- topicNodeRed=adev.topicNodeRed
  			- check if the topic is node red topic :
  				isCmdTopic=topicNodeRed==topic;
  			- message_ = rec(message);// can return a obj if good formatted , else null .
  			- if formatted ( not signal) :
  			 
  			- check if the message come from itself (a formatted payload contais the sender  ).  
  				fromthisctl = message_.sender && message_.sender.plant == mqttInst.plantName && message_.sender.user == dev;
  			
  			- if !isCmdTopic : fill the dev queue with the subcribed msg 
  				>>> nb SSWW we dont expect anyone to pubs on topic unless fromthisctl
  					 if it were (external  pubs on topic ) we would launch a interrupt 
  			
  			
  			- else   is a command : AAQQWW
  			
  				- if (!fromthisctl) // 
  				 	console.log('  message  with cmd topic x device ', dev, ', of type var , so  interrupt to update the value. 
  				 		after update this dev will writesync the value x confirmation');
  				 	ctlpack.ctl.int(msg, mqttInst.status[dev], ctlpack.ctl.lastwrite); // interrupt , like was a browser click to change state !!
  				 - else // error: can from thisctl pubs on topicNodeRed  ?????????
                    			console.log('  message x device ', dev, ', of type var has been emitted by this ctl, so no interrupt');
  

                    
  -   rele dev type           (clas == 'out') , cl_class='rele';// rele
  			nbnb rele out var used a command topic to write new dev state :  topicPub (no node-red staff !)
  			quindi  quando scrivo cambio dev state sul topicPub cambio subito lo relais state
  				senza attendere un message di conferma su topic , lo si da per scontato 
  				tuttavia qualcuno potrebbe cambiare dev state (manuale o sempre via topicPub )
  				il che poi trovera un riscontro nel topic payload che mostrera con un certo ritardo uno state diverso 
  				>>> quindi si potra dopo aver scritto un valore(pub in ), atteso 10 s, nel caso il valore cambi rispetto relais,
  					  si potra lanciare un interrupt come per il type var simulando un manual (o interrompendo un algo ?)
  			a differenza del caso var	
  
  
                if (protocol == 'shelly') {
                    topic =  shelly_stopic + subtopic + shelly_topicp;// shellies/<model>-<deviceid>/relay  must be unique in all plants
                    topicPub=shelly_stopic + subtopic + shelly_topicpp;/	writing to schelly 
                    
                 subscribing :
                 
                  client.subscribe(topic,....
                  
                  }else if (protocol == 'ro')   ......
                  
                  
        >>  at the income message we do as for var type but :
        
        	- isCmdTopic=false;
        	- fromthisctl = true      ????? 
 
        	- if !isCmdTopic fill the dev queue with the subcribed msg 
        	
        	
  - conclusioni : 
        	>> per il rele dev type the logic is :
        	 shelly receive cmd on topicPub and after a delay pub the updated val in topic.
        		when we changed the val using topicPub we immediately change the state.relays state dando per scontato che arrivera poi in topic
        			una volta che il device prende atto del comando emettera nel topic un message con payload il val cambiato
        			 quindi il writesync non fa un update del topic con un pub !
        			quindi i valori payload del topic messo in queue servovo a checckare la congruenza e usualmente è fatta prima di updatare il state.relais
        		nel caso in cui il val venga cambiato hardware o altra app che fa un pub allora e' meglio che  noi dopo un certo ritardo confrontando il val storato in state.relais
        			e constatato che non è allineato allora lanciamo un interrupt
        			
        	>>>>>>> cio è diverso per un var perche'... see AAQQWW
        	
        	
 ************    di seguito alcuni commenti da mqtt.js che sintetizzano i concetti sopra studiati :
    
    - in message receiving :
          fromthisctl = true,// serve a capire nei msg contenenti il sender (var dev scrivono msg formatted ) se esso proviene da un pub di questo ctl, non sempre usato: di solito i var dev usano il meccanismo node-red quando un ext ctl vuole cambiare stato pubs un message con topic command topicNodeRed (il dev è un virt var dev, isCmdTopic=true )
          isCmdTopic=false;// simulera il subscription  di un virtual shelly node-red . il nodered comanda questo virt device fisico che simula un cambio stato genera un call a questo listener che diventa il  listener del suo subscription. constatato che è meritevole di interruput ( probabile state change) lo lo chiama 

    
    - near xxxSubscr():
    
            function numbSubscr(val,that,ctlpack,subscred){// al subscribe del topic associato al dev , that=mqttInst
                                                        // difference from pubSubscr() : 
                                                        // fv3 will keep dev state into state.relais. 
                                                        // so when fv3 algo change the state writesync pub to a cmd topic to change thephisical dev value according to state.relais and 
                                                        // we dont need to check the dev output state pubs into topic if the update is done fromthisctl (writesync())
                                                        //  so in var dev  we dont even fill dev queue with fromthisctl message coming to topic
                                                        // var dev adds  a virtual cmd topic topicNodeRed that ( pubs by ext ctl)  will interrupt running a manual algo to change the state.relais state 
                                                        // only if the dev change its state alne or ext dev ctl will cll its cmd topic we find a queue value different from internal state.relais
                                                        // and we must (todo) interrupt with a specific manual algo to take care of the ext changes
                                                        
                                                        // pubSubscr() dont have state.relais , so the dev state must be read from queue (pay attention to delay from writesync)
                                                        // to avoid delay problem we 
    
        topicNodeRed=topic+nodeRedp;// news : anche i shelly possono essere comandati con meccanismo virtual da un ext ctl come node red o openremote usando questo topic
 
    
        // QUESTION : probe var dev (cioe var che non hanno state.relais e che impostano i subscription con probeSubscr() ) , def in probSubscr() (a differenza dei numb var dev ) non ha meccanismo/topic topicNodeRed ! significa che gli ext ctl banalmente scrivono  anche loro sul topic base in cui si legge lo stato. infatti non c'e' un state.relais che raccoglie il dev status , quindi non si puo chiamare un interrupt che simula un state.relais manual set  !!!!
        // quindi i probe var dev , def in probSubscr() quando i algo chiamno writeSync pubblicano  su topic che filla il dev queue cosi come pubblicano su topic anche i ext ctl !!!
        //	quindi per type 3 e 4 che non hanno il topicPub (ed e giusto che sia cosi di solito) fillano la queue anche se provengono dal device stesso sender=device
        //	quando necessito di conoscere il dev state, non essendo info su state.relais devono fare un readSync che tornano l'ultimo valoe del queue !
        // 	( a differenza dei numb var dev che , con writeSync, pubs  sul topic ma i msg  con topic non alimentano the dev queue se sono prodotti dal ctl stesso
        // 		addirittura nemmeno i ext ctl non scrivono su topic in quanto si basano sul meccanismo node-red (topicNodeRed)!  )
        // 		in altre parole lo stato determinato dagli writesync viene gestito da relais senza checcare il queue riempito (forse)  da msg su topic
        
        todo verificare per questi  var dove pubblica il writeSync : ................. sembra che scrivano solo su topic mancando il caricamento di topicPub !!!!
        //		mentre lo update dello status di ext ctl viene gestito da topicNodeRed che impone un int per cambiare uno state di var tipo numb ( def in numbSubscr())
           



        //		***************  dev state type  MNG SUMMARY **************   :
        
        				SEE THE UPDATED FILE !!!!!!!
        
        
        // verifica di dove pubblicano i var dev:
        // - i type 1 ,rele (numbSubscr()) hanno topicPub=.../command si comportano per il resto come i type 2. in pratica il ctl scrive su topicPub e riceve conferma su topic .
        //		??:  gli ext ctl non scrivono su topicPub se vogliono cambiare lo state.relais con un interrupt handler=eM.iodev.relais_[ind].int (lancia setPump())scrivendo su pub topicNodeRed 
        //			
        //		UUGG invece se il ctl externo vuole direttamente cambiare il dev value puo scrivere sul topicPub che è il comandtopic del dev fisico
        //				(mentre il cmdtopic del dev type 2 è )
        //			cosi che poi viene emesso (da shelly rele) in topic il che  conferma del cambio stato 
        //			ma a questo punto manca il check che verifica lo scostamento dallo state.relais e si dovrebbe (todo ) lanciare un int opportuno  dopo un delay di 5 sec che reimposta il consolidate che setta il state.relais 
        //				consolidate() è la regola che assegna il state.relais del rele considerando sia le proposte dei fv3 (program algo ) che del ext ctl,
        //				senza lasciare che essi si sovrappongono disordinatamente nel settare il state.relais.devx .
        //				
        // - i type 2 var (numbSubscr()) hanno topicPub=null quindi, in conseguenza di un writesync(), pubblicano su topic (quindi ricevibili dagli ext ctl che sub il topic ) e al ricevimento (su topic e non sul cmdtopic ) essendo sender=dev  ,
        //			  fromthisctl = true e quindi non vengono caricati in dev queue in quanto lo state si basa piuttosto sul state.relais e non il dev queue !
        //		to CHECK: oltre che non caricare i topic fromthisctl sul dev queue, tuttavia sembrava che nemmeno pubblicassimo ,i var type 2, sul topic , invece si !!! 
        //			(per risparmiare una inutile operazione in quanto uso lo state.relais per leggere lo stato)
        //		gli ext ctl scrivendo un pub potrebbero fillare il topic del dev x come si fà per i type 4 che usano il queue del topic come state (daleggere con readsync() ma non in type 2 che usa state.relais come state 
        //			quindi per il type 2 dobbiamo lanciare in interrupt che setta una oggetto temporaneo eM.state.lastUserAlgo ( che rappresenta l'istanza di chi lo ha settato: il  ctl esterno NRed/HA o il anticipatealgo ) 
        //			che poi viene usato dal master program algo per settare tutti gli state.relais , comopreso lo stesso state.relais.x 
        //				simulando un algo ( manual algo ) setta il manual algo result che assieme al normale (interno) anticipate algo, concorrerà in consolidate() (lanciato dal master program algo), a definire il next  state.relais  
        //		
        //					sarà quindi un pub  sul topicNodeRed lanciato dal ctl esterno HA (homeassistant) come automation triggerato  dal cambio del select sul ext ctl entity
        //								(il select di home assistant rappresenta la proposta del ext ctl che trasmessa via cmdtopic lancera in message receive  il interrupt che lancia un  manual algo ()
        //									che setta eM.state.lastUserAlgo ( che rappresenterà l'istanza del ctl esterno nel consolidate() che settera il state.relais.devx )
        //								 )
        //							(in home assistant ho un menu/select manual force set che da istruzioni al fv3 di cambiare le regole di consolidate che poi in effetti setta tutti i numbSubscr dev compreso il dev stesso
        //								. nb non si cambia solo il state.relais del dev perchepoi verrebbe a essere corretto dal consolidate dopo qualche minuto ? 
        //									(nb  state.relais e' usato dai type 2 come state  al posto di dev queue ! )
        //								  nb lo state del var device (che  comanda di norma anche un rele ) potrebbe essere copiato su un rele dev  da consolidate !
        //								  nb il settaggio complessivo del state.relais (responsabilità di consolidate() ) viene registrato in ext ctl direttamente come property del select 
        //									quando (comandato da chi lancia il writeSync (meglio da un consolidate che media le varie proposte proventienti dagli algo e ext interrupt(manual algo))
        //									il writeSync srive sul dev topic (che processato (in fv3 msg receive) non  alimenta il dev queue per i type 2  , 
        //									mentre nel msg receive del ext ctl che è il json_attributes_template del select imposta la property del select
        //										nb la property del select puo essere copiata su un entity il cui stato rappresenta direttamente il settaggio del var dev (type 2) che è responsabilità del fv3 !
        //								 ) 
        //							)
        //						che, essendo un cmdtopic in fv3 message receive, a lanciare un interrupt in base al .url che puo fare : 
        //						- old not used now : fa manual update di state.relais () con setPump() ( not std)
        //						- lancia un algo o direttamente aggiorna il suo lastresult eM.state.lastUserAlgo ( letto poi dal program algo in consolidate )
        //						- anche i cmdtopic non vengono caricati in queue
        
        //		QUESTION : ma che senso ha un handler=eM.iodev.relais_[ind].int che lancia setPump() ???? dovrebbe lanciare un manual algo come fa il browser con evento manualAlgoProposal. 
        //			infatti in consolidate i manulalgo setting sovrascrivono le indicazioni del algo anticipate
        
        // - i type 4 var (probSubscr()) hanno topicPub=null quindi,al lancio di writeSync (nb non fillano, come gli type2, lo state.relais che non ha item specifico per i probSubscr dev):
        //			 pubblicano su topic e al ricevimento (su topic e non sul cmdtopic ) essendo controllabile sender=dev  ,  fromthisctl = false e COMUNQUE vengono caricati in dev queue 
        //				( usato per mantenere lo stato(reperibile leggendo con readSync) )
        //		gli ext ctl normali scrivono lo stesso sul topic e quindi fillano (direttamente senza lanciare un interrupt) il queue che funge da stato, 
        //			nb :  ma potrebbero lanciare in futuro un cmd topic (=topic +  /NReadUser/cmd )  che comunque filla il dev queue ma anche potrebbero lanciare prima un loro interrupt ( cosi puo lanciare un algo prima di fillare il queue)
        
        //		added 27082023 :
        //			si potrebbe anche settare il topicPub cosiccche potrebbero comandare anche un rele shelly senza usare uno state come fa il type1
        //			essi possono essere writeSync da un qualsiasi dev di tipo 1 e 2 definendo l'uso del dev in getio() see ZZTTYY
        
        
        //	quando ho bisogno di leggere lo status  non ho state.relais e devo chiamare readSync che legge l'ultimo valore in dev queue indipendentemente che sia stato scritto da this ctl o ext ctl
        //	
        
          // question what is difference among type 1 and 2 ? . add also a topicPub property ?????
          		- a type 2 (var dev ) essenzialmente ha un format nel publicare e ricevere i msg, entrambi hanno la capability di node-red cmdtopic ( interrupt), entrambi hanno state.relais_
          		-  type1 obbligatoriamente ha pubtopic diverso da topic e avendo un device fisico che ricopia poi il pubtopic in topic 
                        //      so type 1 devono avere pubtopic diverso da topic ed è meglio che non facciano un readSync per ricvare lo state che puo avere ritardo 
                        //		ma se lo state e' modificato da altri dall'esterno allora o gli altri usano i nodered topic ( e quindi si lanciano interrupt) o se no devo readSync ogni tanto per vederese qualcuno ha modificato il topic
                        // 	mentre i type 2 possono pub anche su topic ma essendo formattati si puo capire dachi vengono, comunque e' meglio che gli ext ctl usino il nodered topic !! 
          		- mentre i type 4 non hanno lo state.relais_ quindi devono essere letti con readSync()  per ricavare lo state
          		- tutti type 1,2,4 hanno la possibilità di avere un pubtopc != topic
          		
          		// todo : aggiungere un protocollo generico per i shelly like con possibilita di indicare un pubtopic per i type 1 (rele)
          		
          		
          		
         added 24102023:
  * i type 2 e 4 implementano internamente un device fisico che invece ha una sua parte nel type 1, 
      quindi realizzano all'interno del pubtopic il comportamento del device fisico che esegue il comando e poi riflette l'azione fornendo dati nel topic ( comunque disponibile all'interno e all'esterno (nodered/ha))  :
     - si riceve il pubtopic msg (dopo aver updatato lo state.relais interno), si esegue il comando e poi si manda sul topic la risposta corrispondente al nuovo stato del dev che usualmente in payload e' il nuovo valore assegnato
    la differenza tra type 2 e type 4 è che il type 2 mantiene in state.relais lo state interno e quindi non c'e' la necessita di leggere il queue di topic (che diventa lo state del dev type 4 ) x averlo  
    	mentre i ctl esterni (node red e ha) dovranno comunque usare il topic x avere info sullo stato del dev
  * il comtopic (nodered/ha cmd) processa l'evento esterno via interrupt che termina con un nuovo STATE fatto da :
  		- state.relais / lastxxxalgo/ lancio di ulteriori pub su dev.
  	esso permette permette di gestire l'evento/cmd esterno e informare poi gli altri algo  		
          		
          		
 ____________________________________
 
 browser after debug  pause can be  reload after delete cookies , works all event but not receiving only event :'pump'  ???????????????
 
 _____________________________________________________________________


sent setManual/forceautoconsumo from openremote from remote object :
	 Received message  {"payload":1,"sender":{"plant":"Casina_API","user":55},"url":"setMan","checked":1}    on topic  @Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd
		TODO : sender.user   > sender.device
					sender.user must be the emitter : can be mainctl  or  OR  (openremote) !	
 quindi nel caso di un topic ../NReadUser/cmd  in case of type 2 var we fire url interrupt that will act on state.relais   and in any case will fill the dev queue ( different from when a algo with writeSyn just ?
 
 _____________________________________________
 osservazione sullo .state.relais 
 - esso tiene lo state dei numbSubscr() , lo state dei pubSubscr() lo si ottiene con readSync ma come evento esterno! > se cambio (publico) un update di questi per poi usarlo in procedure interne devo creare uno stato interno che lo tenga, altrimenti 
 	i ritardi the un pub e un readSync mi falsano i valori appena impostati e scrtti/pub con writeSync 
 ______________________________-
 
 modifiche format x var :
 {"payload":1,"sender":{"plant":"Casina_API","user":55},"url":"setMan","checked":1}   >> {"payload":1,"sender":{"plant":"Casina_API","dev":55,"user":'thisctl/nrctl'},"url":"setMan","checked":1} 
 
_________________________________________

idea : in openremote, a differenza di nodered, anche i socket emit  vengono emessi con mqtt pub che richiamano i handler di socketio. 

 es x il start anticipate algo:       socket.emit("repeatcheckxSun", start, stop, interval, triggers); 
  creeremo un topic 'socket' con format :  {"payload":{start,stop,interval,triggers:{},"sender":{"plant":"Casina_API","user":'thisctl/nrctl'},"url":"repeatcheckxSun","event":'repeatcheckxSun'}   
  	. per i piu complessi ci sara la necessita di generare il algo come in:
  		- prog_parmFact(sched) : return {procName, a,b,ev2run, asyncPoint, processAsync, dataArr:dataArr_,algo:'program'}; partendo dal event chain ev2run = {initProg:null,genZoneRele:"initProg"};
  		- gi event come genZoneRele sono handler def con code in fv3 o importato da codice esterno caricato da un aatruto attributo ?
  	- ma come passare un code (es program() ) ?, o meglio fare un webagent che carica il code ?
  	tema come generare il template da attributi con le rules ? con i openremote webhook ?
format : .......

____________________________

home assistant vs openremote 

indagare se è piu semplice generare il template {"payload":{start,stop,interval,triggers:{},"sender":{"plant":"Casina_API","user":'thisctl/noderedctl'},"url":"repeatcheckxSun","event":'repeatcheckxSun'}   

diff tra  usare/configurare  gli automation algo : 
- prog_parmFact(sched) di fv3 con il 
 - automation di https://www.home-assistant.io/getting-started/concepts-terminology/ 
________________________________


differenze between 
  state.app.plantconfig.virt2realMap : //  iesimo virtual dev is mapped to index= map[i] of name: relaisEv[i], con state:relays[relaisEv[i]])  
  e 
  eM.state,triggers2.mapping : // mapping algo vars to plant devices !, input used when call last event genZoneRele of related exec created with prog_parmFact(sched)
___________________________________________

 termostati per ogni zona ha  formato : {"8:30":20,"17:00":22}   la zona notte/giorno ,,,,  e' mappata sul dev virtuale in program()
 
 _____________________________
  see https://indomus.it/formazione/le-automazioni-di-home-assistant-cosa-sono-e-come-si-usano/
  	https://indomus.it/formazione/home-assistant-guida-rapida-ai-concetti-principali/
 
 automazioni home assistant diferenze con fv3 :
 
 event : interpretato come qualcosa che cambia lo stato
  in fv3.js event si puo considderare tutto cio che cambia i device in web interface (numbSubscr() , ma non  pubSubscr() )
  invece i listener che cambiamo i device state ( es i prob) non hanno impatto sui numbscript numbSubscr()
  	mentre se ho un un topic ../NReadUser/cmd  in case of type 2 var we fire url interrupt that will act on state.relais  (and in any case will fill the dev queue) 
  	mentre se ho un var normale ,come il preferred...  solitamente vengono usati dal algo anticipate per settare lo state del var che verra esaminato dal program algo 
  	mentre se setto con writeSync il pub topic  associato al rele (usando setpump()) e' dopo aver settato il numbScript state (state.relais) quindi il device copia la transazione in topic da cui legge readsync 
  		si otterra uno device state che e' già scontato su state.relais  
  		
  	.....
  	
  >>> quindi il trigger di home assistant e' un listener di un event che cambia lo stato state.relais , (numbSubscr())
  
  - le entita sarebbero appunto state.relais e i servizi sono gli algo che li cambiano 
  
  
  
  ********     state.relais  o state.relais_ ?? 		*****************+
  
  
  
 _________________________________
 un modo per caricare i code e gli algo definition  e' usare un frame del browser !
 _________________________________
 
  home assistant test 
  con rif a         		***************   mng summary **************   
  si è testato che :
  	- a fronte di un change del select, che rappresenta l'istanza del home assistant sulla var dev gaspdcPref, si lanci con un automation  un topic '@Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd'
  		poi in message receive dei cmdtopic dei dev type 2 (topic topicNodeRed= '@Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd' )  lanci un interrupt che lancia il manual algo eM.state.lastUserAlgo che setta 
  		eM.state.lastUserAlgo ( che rappresenterà l'istanza del ctl esterno nel consolidate che settera il state.relais.gaspdcPref  portid 55 in consolidate()  ) 
  		
  	- che quando in consolidate aggiornando i vari  state.relais.x  in particolare il state.relais.gaspdcPref si lancia writeSync che lancia il pub sul topic associato al var dev 
  		(topic che non viene usato per fillare il deb queue in fv3/mqtt message receive in quanto inutile perchè si usa appunto lo stesso state.relais.gaspdcPrefcome come state e non serve leggere il dev mqtt queue  )
  		tale topic corrisponda al select json_attributes_topic e che quindi imposti il attribute algoSuggested
  		
  		 nb in mqtt select manca il topic perche non ha senso un topic che da mqtt imposti il selected option perche questo è impostato solo via manuale in home assistant overview !! 
  
  	- mancano i  shelly (rele mqtt) impostati da fv3 che si possono aggiungere in home assistant per monitorare come fv3 agisce sui rele. non ha senso chiamare i cmdtopic perche colliderebbe con le azioni degli algo fv3
  		se si vuole aggiungere un manual anche su tali rele bisognera fare :  (UUGG) 
  		
  	- se si vuole programmare gli algo 
  		- todo : a livello alto bisogna impostare il code degli event e il code della procedura prog_parmFact(sched) antic_parmFact(sched){ usando un frame web sul browser)
  		- poi a livello piu basico i param sched si possono settare usando il nomale interfaccia web oppure aggiungere un po di select (SSS)  in overview di home assistance che settano i sched attributes ( trgger2,...) 
  		
  		- in hs lo user non usa l'interfaccia websocket come il browser ma si usa mqtt come rele : 
			e poi come per il select NRInt creo un po di cmdrele (start_fv3-service stop_fv3-service) e al cambio stato lo si invia su un topic di comando mqtt  
				che usa i parametri settati dai select (SSS)
				che fa le stesse cose del interfaccia websocket , evento  startprogrammer ma su topic mqtt !
					- cosi come :  socket.on('startprogrammer',repeatHandler1);
						>> repeatHandler1(starthour,stophour,dminutes,triggers2) {}
								in  setanticipateflag({running:true,starthour,stophour,dminutes,triggers2},'program'); 
								aggiunge a state.program : {running:true,starthour,stophour,dminutes,triggers2}
						aggiungo allora un ctl dev di type ctl.cl=0 ( simile a un type 2)
						
							in  goonP() {// goon with message processing :
							  ctlpack.ctl.cl=0  nb ctlpack = adev.ctlpack  , adev = regTopic(topic)) = invTopic[topic] 
								invTopic settato in  numbSubscr():
									invTopic[topic]={portid,mqttInst:that,topic,topicNodeRed,cl_class,protocol,ctlpack} 
									
										cl_class =   rele/var/       >>>>>>>>  passato al termine di numbSubscr() al cb: subscred({topic,cl_class})
										
									ctlpack settato in .fact() ( chiamante di numbSubscr()) :
								 		ctlpack= {ctl:new fc(gp,ind,inorout,cfg,that),devNumb:ind,type:'mqtt',,,,};
								 		
								 		nb 
								 		.fact è factory che ritorna ctlpack  :
								 		 	console.log(' **** dev factory mqttInst.fact() for plant ',that.plantName,' relaised/resolved the devid/portid ',gp,' after subscribing on topic ',resu.topic);
            										console.log(' **** according model info: ',cfg,' \nfound  in ',infosrc,' a device of type: ',resu.cl_class,' protocol ',cfg.protocol);
            										
            									 .fact() che torna ctlpack , è chiamato in : getio(num, iotype, ind, ismqtt = false,mqttInst)  
            									 
            									 getio() è chiamato da :  doSomethingAsync(gpio,ind,ismqtt=false) 
            									 				doSomethingAsync(), in getctls() 
            									 					(getctls()  riceve due chiamate da  buildPlantDev() :  	getctls(mqttInst,gpionumb,mqtt=mqttnumb,isProb=false,mqttWebSock) e
            									 					 					getctls(mqttInst,null,mqtt=mqttprob,isProb=true) 
            									 					),
				    									 	è chiamato :
				    									 	- da fillctls() su tutti i dev (di mqtt/gpio) ind=index
				    									 	            	fillctls() fill array of resolving device that when resolved ( all or after a max time) 
				    									 	            		resolve the  SSSDD promise with the array of available devices ctl: resu[dev1ctl,,,]

				    									 	- e, se isProb=false, anche da setMqttXWebsock() che chiama doSomethingAsync(0,-1,true)   portid=0   index =-1
				    									 	
				    									 			la cfg e' in models.js :
				    									 				       mqttWebSock:        {portid:0,subtopic:'mqtt_websock_',varx:0,isprobe:false,clas:'int',protocol:'mqttxwebsock'},
				    									 				       				// must be portid=0 ! : a dummy var that creates ctl websocket topic 
				    									 				       				
				    									 			esso e' inserito in relais_ al  index >=relaisEv.length , usually index =relaisEv.length  DDTT DDTT    >>  see DDTT
 
				    									 	
				    									 		>> quindi in questo caso  doSomethingAsync(0,-1,true) chiama sul devid=0 getio(num=0, iotype='int', ind=-1, ismqtt =true,mqttInst)
				    									 		che chiama  .fact(num,ind,iotype)sul dev dummy (num=0),che , come nei device normali, :
				    									 			- torna ctlpack che oltre che settare le caratterisctiche dei dev 
					    									 			torna anche il ctl ctl=new fc(gp,ind,inorout,cfg,that)
					    									 				ctl={.......
					    									 					intx
					    									 					gpio
					    									 					cl:0/1/2/3/4  dev type !!!!!!!!!!!!!
					    									 					readSync
					    									 					writeSync}
					    									 			
					    									 			che ha le sue proprietà e le chiamate readsync e writesync (simili a type 2 o 4 )
					    									 			che pero non verranno mai chiamate essendo il dev dummy
				    									 			- run subscription : numbSubscr(cfg,that,ctlpack,subscred) 
				    									 				con cfg=mqttWebSock= {portid:0,subtopic:'mqtt_websock_',varx:0,isprobe:false,clas:'int',protocol:'mqttxwebsock'}
				    									 						{ portid, varx, isprobe, clas, protocol, subtopic } = cfg , var used to build subscription in 
				    									 						ingest (new values of dev val in topic and cmdtopic  subscription) ad pub topic when writesync
				    									 							clas = int  . nb usual values can be:    out/var/probe/int
				    									 				>>> subscriptions will be similar to  var device type 2	, but:
				    									 						 register a subscription on topic = that.topPlantPrefix + 'interface_' + subtopic + varx;
				    									 						 			ex @Casina_API@interface_mqtt_websock_0, usually not used 
				    									 											msg= .....
				    									 										e in cmdtopic, ex  @Casina_API@interface_mqtt_websock_0/NReadUser/cmd
				    									 											msg= message='{"payload":1,"sender":
				    									 															    									 											{"plant":"Casina_API","user":xxx,"token":yyyy},"url":"mqttxwebsock","event":"repeatcheckxSun",
				    									 															    									 											"data":{theeventhandlerparams=starthour,stophour,dminutes,triggers)}}' 

				    									 				returns after call cb=subscred(topic,cl_class='var')
				    									 				
				    									 					nb values of cl_class can be generally: 'rele'/'var'/'probe'
            									 						- cb from numbSubscr will just complete ctlpack with topic,cl_class,protocol and resolve mqttClass.fact  with ctlpack
            									 						- then return ctlpack from getio() and doSomethingAsync() 
            									 						
            									 					>>> so  setMqttXWebsock() launch the promise pr=doSomethingAsync(0,-1,true) that resolve in above ctlpack 
            									 					
            									 					question :il promise pr , clas='int' e portid=0, viene aggiunto ai array   {ctls:resu,// ctls=[ctl1,,,,,] ctlx: see PIRLA in mqtt
  																				devmap:resolved})
  																 che risolvono il promise  ritornato da getctls()    ????????????
  																 
            									 							nb : il resolve di SSSDD getctls() viene usato in buildPlantDev()  :
            									 									devices={	myctls:{
																						ctls:[ctl1=new fc(gp,ind,inorout,cfg)= 	
																							  {gpio=11,
																							  devNumb=0,// array index 0,1,2
																							  type=inorout,
																							  cfg,
																							  cl=0/1(clas='out')/2(a var)/3(clas='in'OR'prob'),
																							  isOn,
																							  readsync,
																							  writesync,
																							  lastwrite  // the last writeSync
																							  }
																							  ,,,],
																						  devmap:[{devNumb,devType,portnumb},,,,]
																						  }  
            									 											
            									 											
            									 											myprobs:{...}} 
            									 									
            									 									
            									 					     			e abilita().then() chiama abilita2 con devices={myctls,myprobs}
            									 					     			
            									 					     			abilita2() fills iodev.relais_ e iodev.relais_, con i ctls di myctls e myprobs
            									 					     			 i dev vengono fillati col loro index assegnando il dev name dall'array relaisEv ,
            									 					     			 	 index =0..relaisEv.length-1 (AAQZ)
            									 					     			>>  relais_ contiene anche il dummy dev con portid=0 ma di index >=relaisEv.length                DDTT
            									 					     				cosicche non viene mai processato in genere, in quanto si readsync e writeSync solo i dev AAQZ
            									 					     				tuttavia si  assegna il interrupt handler che risponderanno ai topic 
            									 			
															answer: sembra inutile . basta completare il ingest receive con
																			 else {// isCmdTopic  , news now also rele dev can have cmdtopic !!. .....
																			 
																	dopo aver aggiunto il reference al interrupt in ctl.intx    abilita2  !!!!!!!!
																	
																	
																	

										 SSSDD : getctls:function(mqttInst,gpionumb,mqttnumb,isProbe=false) returns promise with the array of available devices ctl: resu[dev1ctl,,,]
										 
										 SSSDD, cioè getcts(),  is called in    buildPlantDev() (  chiamato da  abilita(state)  ):
										 
										 	myctls_= getio.getctls(mqttInst,gpionumb,mqttnumb);// get devices choosing from describing gpio and mqtt info array : these are the visible rele/var in browser
											  // {ctls:[ctl1,,,,,],devmap:[{devNumb,devType,portnumb},,,,]}
											  // get pump/relais r/w devices from preferred  mqtt or gpio arrays
											myprobs_= getio.getctls(mqttInst,null,mqttprob,true);//   {ctls,devmap} , true = a probe/var device. invisible in browser
											    // get probs  read only devices from  mqtt, true means is a probe type (type='in')
											    // + get var, intermediate status / context to be used by other algo , connectable to red note


										 
										 
						che avendo previsto un topic topic topicNodeRed lancera un interrupt che gestirà l'aggancio ai evet handler del websochet ! 
						
							che in mqtt incoming :
								.......						
				nb invece si pensava in nodered interface di usare sempre un websocket client che mima il websocket del browser 
 ____________________________________________
 
 start without pm2 :
 	ps -ef | grep node
	kill   xxxx
	nohup yyyy &     dont work !
__________________________

amazon : Home Automation Platform (Home-Assistant,openHAB,Node-RED,ioBroker,PVoutput) 
_______________________________

backup sistema do con tessarotto :

		luigi@luigi-Vostro-3560:~$  ssh luigi@sermovox.com
		Welcome to Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-65-generic x86_64)

		 * Documentation:  https://help.ubuntu.com
		 * Management:     https://landscape.canonical.com
		 * Support:        https://ubuntu.com/advantage

		  System information as of Wed Aug 16 18:30:34 UTC 2023

		  System load:  0.09               Processes:           94
		  Usage of /:   23.8% of 24.06GB   Users logged in:     0
		  Memory usage: 34%                IP address for eth0: 46.101.180.15
		  Swap usage:   0%                 IP address for eth1: 10.135.61.82

		 * Canonical Livepatch is available for installation.
		   - Reduce system reboots and improve kernel security. Activate at:
		     https://ubuntu.com/livepatch

		199 packages can be updated.
		103 updates are security updates.


		*** System restart required ***
		Last login: Thu Dec 15 01:20:26 2022 from 95.251.38.146
		luigi@demo1:~$ 
		
	so create tar : cd deploing_demo ;  tar -cvpzf demo1_cms.tar.gz demo1_cms
	
	>> see /Documents/savings

________________________________________-

testing var send to ha  :
to ....
  mosquitto_pub -h bot.sermovox.com -t @Casina_API@ctl_var_gas-pdc_4 -m '{"payload":"ciao","sender":{"plant":"Casina_API","user":55}}' -p 1883  -u sermovox -P sime01
  
to simulate a ha cmdtopic versus a type 2 var , protocol ....... :
	mosquitto_pub -h bot.sermovox.com -t @Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd -m '{"payload":1,"sender":{"plant":"Casina_API","user":55},"url":"setMan","checked":1}' -p 1883  -u sermovox -P sime01
	

to simulate a ha cmdtopic versus a type 0 var , protocol ....... :
	mosquitto_pub -h bot.sermovox.com -t @Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd -m ' message='{"payload":1,"sender":{"plant":"Casina_API","user":xxx,"token":yyy},"url":"mqttxwebsock","event":"repeatcheckxSun","data":{theeventhandlerparams=starthour,stophour,dminutes,triggers)}}' 
' -p 1883  -u sermovox -P sime01
	

to check if is correcly send :
 	mosquitto_sub -t @Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd  -u sermovox -P sime01 -h bot.sermovox.com -p 1883

___________________________________________

  
'repeatcheckxSun'
'stopRepeat',stopRepeat);
('startprogrammer',repeatHandler1);// start anticipating algo with setting and run an execute()
function repeatHandler1(starthour,stophour,dminutes,triggers2) 


socket.on('stopprogrammer',stopprogrammer);


______________________________

ha : bisognera aggiungere uno script che genera i entity in ha e il model.js corrispondente per fv3 per i device che saranno controllati da fv3 :

pompa settore 1: ......  andra sul virtual dev x
......

_____________________________________

function a(args){
let mar=arguments[0].sender;
//mar.push(arguments[0].sender);
mar.push({type:'var',val:7});
    b.apply(this, mar);
    // b.apply(this, arguments);
}

function b(a1,a2,a3){
   alert(JSON.stringify([a1,a2,a3]));
}

a(JSON.parse('{"payload":1,"sender":[{"plant":"Casina_API","user":55},3],"url":"setMan","checked":1}'));
_________________________________
state mng  : idea strutturare gli state il level , ......
 short level , high level (will condition the param of algo that sets the low level)
  ex of high level : preferred gas/fv (is a high level copied into state.relais_)
  high level have its state : state.sysstate and its transition actions 
  _________________________________________
  
  ******   howto program logic :
  
  
  question   readwrite to modbus can be like a mqtt dev ? just is a different type of dev?
   nb a mqtt dev is built on top of a numbmqtt state so the state  is the device state.  but can we add a device command after set a var state ????????
   		>> see 	(KKPPMM)
   		
   		
   spesso si scrive sui dev come si fa in un last event : 
  	 es programming algo ha genZoneRele come last event :
  	 	....
  	 	aTT=program(state,inp,probes)
  	 	....
  	 	call await callattuators();
  	 		result=await attuators(these);
  	 			aTT=consolidate(state,'program'),
  	 			promises.push(setPump(realind,aTT[i], fn));
   		
   quindi ,riassunto come scrivere sui device: 
   - in attuators() , dopo consolidate() we write dev staff via:
   	- via setpump()   if we use a numbSubscr device that can be rele or var (var device are written 
   	
   		that call 
   			- onRelais()
   			- fn.pumpsHandler[pumpnumber](0,on_)  (if cient/browser is connected will call watchparam(pumpName) that emit : socket.emit('pump',pumpName, lightvalue);
   				the browser will handle setting the flag of device (display the new write value) 
   					browser  will call  onRelais() after set the dev flag (this is usefull only if user set the flag, otherwise fv3 will discard the double onRelais(() call !!!!)
   			
   	
   			in onRelais(pump,data,coming,fn)
   				- call writesync to dev after recovered the dev index from relaisEv ( contains the index of all numbSubscr device ( the dev that has its state represented on browser flag and on state.relais[]) 
  					fn.iodev.relais_[pump_].writeSync(valCorrection(data));
  				- updates state :
  					 api.writeScriptsToFile(fn)// upddate persistance and send status to browser
  					 
  					 
  	
  	
  	
  	
  _____________________________
  
  
  DEVICE CUSTOM AGGIUNTIVO divesro da MQTT esempio comandare con ModBUS i split !!
  
  
  
  idea : associare un dev fisico con un suo controller (es modbus) diverso da mqtt  a un dev (var o anche rele) aggiungendo :
   se il fisical dev write aggiungere un ub su dev topic,
   
   se il fisical dev read aggiungere un call al device fisico da public topic (o nedered topic ?) 
   
   cio ha senso se il dev fisico è strettamente associato al fv3 numbersubscr() dev ! 
   ...........
   
   se invece voglio inviare senza controllare dei comandi a device fisici che dipendono da un fv3 dev def basta che mandi la chiamata tipo   
   				parseFloat(await shellcmd('modbusRead',{addr:map[0],register:'temp',val:0})
   	aggiungendola dopo aver scritto sul publictopic del fv3 dev 
   	es. il split dev comanda il rele dev che e' la valvola degli split .
   		 però esso non è mqtt !!!!!! 
   		 quindi il comando lo devo aggiungere direttamente in consolidate !!!!  ????    NO
   		 >>> meglio personalizzare il writeSync di un gpio rele in 
  	
  	
  	
 ________________________________ 					 
  come leggere da un device, non registato in mqttnumb o mqttprob,  nello state direttamente in un  event di un procedure:
  
  
    - probes.giorno=parseFloat(await shellcmd('modbusRead',{addr:map[0],register:'temp',val:0}).catch(error => { // val useless
      console.error('  shellcmd catched ,error: ', error);
      retry=true;
    }));

__________________________

il havac install chiedera al utente di inserire i dati di tutti i param che saranno usati per generare :
- i dev NRInt sono i var e i rele  che vengono impostati da fv3 . si monitora con le attributi e si comanda il manualAlgo settando il select  
	
______________________________

checcare input 0/anInt   o  '0'/'anInt' :

function typeOfNaN(x) {
let xx;
  if (isNaN(x)) {
    return ' not good';
  }
    if(x==0)return 0;
    else return 1;
  }
console.log(typeOfNaN(7));


console.log(typeOfNaN('8'));


console.log(typeOfNaN('polo'));
// Expected output: "Number NaN"


or :

function typeOfNaN(x) {
let xx;
  if (!isNaN(x)) {
    if(x==0)return 0;
    else return 1;
  }
  else{
    return ' not good';
  }}
console.log(typeOfNaN(0));


console.log(typeOfNaN('0'));


console.log(typeOfNaN('polo'));

or: 

function typeOfNaN(x) {let val_;
if(!Number.isNaN(val_=Number(x)))// // val is conveted to integer
  
{if(val_==0)return 0;else return 1;
}else return 'not valid';
}
console.log(typeOfNaN(0));


console.log(typeOfNaN('0'));


console.log(typeOfNaN('polo'));
// Expected output: "Number NaN"
// Expected output: "Number NaN"

>> donot use Number.isNaN() !
____________________________________
too much listener sent on :             console.error(' stlist() listener no ERROR. now adding a listener x dev : ', dev, 'in current mqttinst.statuslist: ', mqttInst.statusList);// 05052023   dev is the devid x debug only

and setPump not called on browser !


..........
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)],
    ... 143 more items
  ],
  '110': []
}
 onRelais, find current pump  split  state different from current hw pump position thats:  null
 onRelais, find current pump  gaspdcPref  state different from current hw pump position thats:  null
  ?? attention that order in state.relays  {
  heat: true,
  pdc: true,
  g: true,
  n: false,
  s: false,
  split: true,
  gaspdcPref: true,
  acs: false
}  same as fn.state.relays  {
  heat: true,
  pdc: true,
  g: true,
  n: false,
  s: false,
  split: true,
  gaspdcPref: true,
  acs: false
}  can be different from fn.relaisEv  [ 'heat', 'pdc', 'g', 'n', 's', 'split', 'gaspdcPref', 'acs' ]
 stlist() listener no ERROR. now adding a listener x dev :  66 in current mqttinst.statuslist:  {
  '54': [],
  '55': [
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)],
    ... 139 more items
  ],
  '66': [
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)],
    ... 143 more items
  ],
  '110': []
}
 stlist() listener no ERROR. now adding a listener x dev :  55 in current mqttinst.statuslist:  {
  '54': [],
  '55': [
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)],
    ... 139 more items
  ],
  '66': [
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)], [Function (anonymous)], [Function (anonymous)],
    [Function (anonymous)],
    ... 144 more items
  ],
  '110': []
}
 onRelais, find current pump  split  state different from current hw pump position thats:  null
 onRelais, find current pump  gaspdcPref  state different from current hw pump position thats:  null
^Cluigi@raspberrypi:~/localdev/fv20 $ 


_______________________________________

todo : in  function program(state,inp__,probes)

 modificare i valori di Att   null,false,true   in     0  -1  1   -10    10        10  o -10  se non voglio far modificare il valore da intermediate !!!
 
 cio per decidere in consolidate se applicare un attivo intermediate : si se abs < 5





______________________

to download the yaml cfg see : https://developers.home-assistant.io/docs/api/rest/   using :  /api/services/<domain>/<service>

			https://www.home-assistant.io/integrations/shell_command/
			
			https://community.home-assistant.io/t/state-to-file/483167
			
shell_command:
   write_daily_rain: /bin/bash -c "echo {{ states.sensor.daily_rain.state }} > /run/weather/daily_rain"

				automation:
				 - alias: sensor_daily_rain_to_file
				   trigger:
				    - platform: state
				      entity_id: sensor.daily_rain
				    - platform: homeassistant
				      event: start
				   action:
				    - service: shell_command.write_daily_rain
				    
		
		
		
		so: 	
					
shell_command:	    		
   write_yaml: /bin/bash -c "echo {{ yaml }} > {{ filename }}"

curl \
-H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJiNmYxMDk3NDYxODI0YmZhYjkwNTc2NjQ1ZDVmODU4MyIsImlhdCI6MTY5NDQ0Mjg2MiwiZXhwIjoyMDA5ODAyODYyfQ.ppeuf-Ma1vLVQCT0Qrt07C5TXGHsHasX3ElOl1NCX3A" \
-H "Content-Type: application/json" \
-d '{"filename": "yaml_ex.txt","yaml":"atextyaml"}' \
192.168.1.212:8123/api/services/shell_command/write_yaml

cioe : curl -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJiNmYxMDk3NDYxODI0YmZhYjkwNTc2NjQ1ZDVmODU4MyIsImlhdCI6MTY5NDQ0Mjg2MiwiZXhwIjoyMDA5ODAyODYyfQ.ppeuf-Ma1vLVQCT0Qrt07C5TXGHsHasX3ElOl1NCX3A" -H "Content-Type: application/json" -d '{"filename": "yaml_ex.txt","yaml":"atextyaml"}' 192.168.1.212:8123/api/services/shell_command/write_yaml



*****



returns :
{"yaml":{"mqtt":{"switch":[{"name":"sunshine_startgenerator","qos":1,"state_topic":"£shellies/shelly1-34945475FE06/relay/0£","value_template":"\"{% if value == 'on' %} on {% else %} off {% endif %}\" ","payload_on":" \"on\"","payload_off":"\"off\"","state_on":"\"on\"","state_off":"\"off\"","command_topic":"£shellies/shelly1-34945475FE06/relay/0/command£","json_attributes_topic":"£shellies/shelly1-34945475FE06/relay/0£","json_attributes_template":"£{ \"jsonattr\": \"{{value}}\"}£"}],"select":[{"name":"sunshine_optimizing","command_topic":"£Node-Red-Register£","json_attributes_topic":"&@DefFVMng_API@var_gas-pdc_4&","json_attributes_template":"£{ \"jsonattr\": \"{{value}}\"}£","options":["0","1"]}]},"automation":{"automation":[{"alias":"fv3_optimize_sunshine_optimizing","id":"fv3_optimize_sunshine_optimizing","initial_state":true,"trigger":[{"platform":"£state£","entity_id":"£select.sunshine_optimizing£"}],"action":[{"service":"£mqtt.publish£","data":{"topic":"&@DefFVMng_API@var_gas-pdc_4/NReadUser/cmd&","payload":"£{\"payload\":{{ states.select.sunshine_optimizing.state }},\"sender\":{\"plant\":\"DefFVMng_API\",\"user\":55},\"url\":\"setMan\",\"checked\":1}£"}}]}]}},"data":{"some":["Flavio"]}}





webhooks:  see https://www.home-assistant.io/docs/automation/trigger/#webhook-trigger

curl -X POST -H "Content-Type: application/json" -d '{ "key": "value" }' https://192.168.1.212:8123/api/webhook/genyaml




			
curl \
-d "user=user1&pass=abcd" \
-X POST \
https://example.com/login
			
curl \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJiNmYxMDk3NDYxODI0YmZhYjkwNTc2NjQ1ZDVmODU4MyIsImlhdCI6MTY5NDQ0Mjg2MiwiZXhwIjoyMDA5ODAyODYyfQ.ppeuf-Ma1vLVQCT0Qrt07C5TXGHsHasX3ElOl1NCX3A" \
  -H "Content-Type: application/json" http://localhost:8123/api/		
			
curl -H "Content-Type: application/json" -d '{"filename": "yaml_ex.txt","yaml":"atextyaml"}' 192.168.1.214:8080/register
__________________________________________________

home assistant created a long lived access token , name fv3 :  eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJiNmYxMDk3NDYxODI0YmZhYjkwNTc2NjQ1ZDVmODU4MyIsImlhdCI6MTY5NDQ0Mjg2MiwiZXhwIjoyMDA5ODAyODYyfQ.ppeuf-Ma1vLVQCT0Qrt07C5TXGHsHasX3ElOl1NCX3A

____________www.anagrafenazionale.interno.it___________________________________

eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJiNmYxMDk3NDYxODI0YmZhYjkwNTc2NjQ1ZDVmODU4MyIsImlhdCI6MTY5NDQ0Mjg2MiwiZXhwIjoyMDA5ODAyODYyfQ.ppeuf-Ma1vLVQCT0Qrt07C5TXGHsHasX3ElOl1NCX3A

eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJiNmYxMDk3NDYxODI0YmZhYjkwNTc2NjQ1ZDVmODU4MyIsImlhdCI6MTY5NDQ0Mjg2MiwiZXhwIjoyMDA5ODAyODYyfQ.ppeuf-Ma1vLVQCT0Qrt07C5TXGHsHasX3ElOl1NCX3A
____________________________________________________________________________________

testing rest 
curl -X POST -H "Content-Type: application/json" -d '{ "yaml": "value" }' https://echo.zuplo.io/
{
  "url": "https://echo.zuplo.io/",
  "method": "POST",
  "query": {},
  "body": {
    "yaml": "value"
  },
  "headers": {
    "accept": "*/*",
    "accept-encoding": "gzip",
    "connection": "Keep-Alive",
    "content-length": "19",
    "content-type": "application/json",
    "host": "echo.zuplo.io",
    "true-client-ip": "79.20.9.207",
    "user-agent": "curl/7.68.0",
    "x-forwarded-proto": "https",
    "x-real-ip": "79.20.9.207"
  }



curl -X POST -H "Content-Type: application/json" -d '{ "yaml": "value" }' http://postman-echo.com/post



{
  "args": {},
  "data": {
    "yaml": "value"
  },
  "files": {},
  "form": {},
  "headers": {
    "x-forwarded-proto": "http",
    "x-forwarded-port": "80",
    "host": "postman-echo.com",
    "x-amzn-trace-id": "Root=1-6500b628-77a5d3ec7179d1922de8a8cb",
    "content-length": "19",
    "user-agent": "curl/7.68.0",
    "accept": "*/*",
    "content-type": "application/json"
  },
  "json": {
    "yaml": "value"
  },
  "url": "http://postman-echo.com/post"
}


from fv3 : for :

  
  body={ yaml: "value" };
    url='http://postman-echo.com/post';


returning a promise from echo resolving as :  {
  "args": {},
  "data": {
    "yaml": "value"
  },
  "files": {},
  "form": {},
  "headers": {
    "x-forwarded-proto": "http",
    "x-forwarded-port": "80",
    "host": "postman-echo.com",
    "x-amzn-trace-id": "Root=1-6500b57a-7cc7c36c4a83929c4fef4f63",
    "content-length": "16",
    "content-type": "application/json"
  },
  "json": {
    "yaml": "value"
  },
  "url": "http://postman-echo.com/post"
}


"{\"mqtt\":{\"switch\":[{\"name\":\"sunshine_startgenerator\",\"qos\":1,\"state_topic\":\"£shellies/shelly1-34945475FE06/relay/0£\",\"value_template\":\"\\\"{% if value == 'on' %} on {% else %} off {% endif %}\\\" \",\"payload_on\":\" \\\"on\\\"\",\"payload_off\":\"\\\"off\\\"\",\"state_on\":\"\\\"on\\\"\",\"state_off\":\"\\\"off\\\"\",\"command_topic\":\"£shellies/shelly1-34945475FE06/relay/0/command£\",\"json_attributes_topic\":\"£shellies/shelly1-34945475FE06/relay/0£\",\"json_attributes_template\":\"£{ \\\"jsonattr\\\": \\\"{{value}}\\\"}£\"}],\"select\":[{\"name\":\"sunshine_optimizing\",\"command_topic\":\"£Node-Red-Register£\",\"json_attributes_topic\":\"&@DefFVMng_API@var_gas-pdc_4&\",\"json_attributes_template\":\"£{ \\\"jsonattr\\\": \\\"{{value}}\\\"}£\",\"options\":[\"0\",\"1\"]}]},\"automation\":{\"automation\":[{\"alias\":\"fv3_optimize_sunshine_optimizing\",\"id\":\"fv3_optimize_sunshine_optimizing\",\"initial_state\":true,\"trigger\":[{\"platform\":\"£state£\",\"entity_id\":\"£select.sunshine_optimizing£\"}],\"action\":[{\"service\":\"£mqtt.publish£\",\"data\":{\"topic\":\"&@DefFVMng_API@var_gas-pdc_4/NReadUser/cmd&\",\"payload\":\"£{\\\"payload\\\":{{ states.select.sunshine_optimizing.state }},\\\"sender\\\":{\\\"plant\\\":\\\"DefFVMng_API\\\",\\\"user\\\":55},\\\"url\\\":\\\"setMan\\\",\\\"checked\\\":1}£\"}}]}]}}"
________________________________________
echo "£\"{\"data\":\"{{data.json}}\"}\"£ ££  £\"{\"data\":\"{{data.json}}\"}\"£"  | sed -e "s/££/\/n/g" | sed -e "s/£/\'/g"

____________________________________________

riassunto difficolta nel download del yaml:
- i webhook con chiamata aiax jsno no possono portare string con segni speciali 
- necesssita la codifica di " ' e \n e #
- nel ricostruire il file nei action dei automation si richiamano shell_command 
- i shell cmd se leggono il data devono essere "" e quindi non e' possibile usare cmd con parametro  ""
- non posso oncatenare cmd con &&
- non riesco a eseguire .sh nei shell_command 

>> quindi i sed non possono leggere i json data quindi il filename del yaml scaricato
__________________________________________________________


____________________________________________

 /bin/bash -c " myFVdata="£\"{\"data\":\"{{data.json}}\"}\"£ ££  £\"{\"data\":\"{{data.json}}\"}\"£"  && 
 _____________________________________________
 todo 
 inserire i ok al anticipate solo se cur temp < 1.5 gradi rispetto desidered 
 provare  a bloccare qualche pump per 1 giorno in manuale
 combiare ora legale in raspberry
 cambiare lo stato dei dev mqttnumb da false ( unkwown)  / false/ true  in integer / object   to qualify the temperature gap per tener conto della soglia TgiornoTollerance . idea aggiungere un qualify a 
 ________________________________
 
 
 
 	 	// **** MNG SUMMARY mappings of probe and pump (devices shown  on pump list) devices :
		// algo (exec procedure and its event manager) works on device using virtual index refearring to gpionumb/mqttnumb pump/var e mqttprob/pythonprob probs/var.
		// 	- gpionumb/mqttnumb
		//	 	name can be used instead of virtual index on gpionumb/mqttnumb using the corrispondence relaisEv
		//		ex state of gpionumb/mqttnumb dev ( state.relays) uses name keys according to  relaisEv  
		// ...................
 
 so virtual index are used by exec events program for ex used when call event genZoneRele (input : dataArr(=sched)) , a event of a exec procedure created with prog_parmFact(sched)
 
 genZoneRele :
 - it uses program() that works on   probs dev described in  mqttprob/pythonprob   
 
 		program()  write a proposal ( pumps + tollerance ) for virtual indexed  in lastProgramAlgo using virtual index
 - then calls callattuators() that 
 	calls consolidate , // works on virtual dev  [false, false, false, false,false,false,,,]= [heat,pdc,g,n,s,split,,,], 
 	
 - then using  map=state.app.plantconfig.virt2realMap;//
 	call setPumps(virtualindex=pumpnumber,val,))
 		setPump calls :
 			onRelais(relaisEv[pumpnumber] 	>>  so works on dev name to set state.relais[name]  
 			fn.pumpsHandler[pumpnumber](0,on_)  >> so call a socket event to browser to set a pump of index pumpnumber
 					the browser sets the pump of index ....
 					
 					nb when we manual set a pump will be called a server event :  socket.emit('pump', pump= browserpumpindex ????????   , data, 'browser_pump_Handler'); //  HYN send push button status to back to server  
 						the server will set the manual of pump .............
		
 			nb also when browser receiving the state event pumps are filling still using virtual index !!
 	
 	
  >>>   quindi il mapping dei dev output  non funziona . per ora usare solo virt2realMap =[0,1,2,3,4,5,6,7] . probabilamnte bisogna updatare il browser usando i nomi e eventualmente un locale index
  // invece e' da considerare il probmapping , see .....
 	
 	
 	
 	
 	
old comment to review :
 	
   when they wants to write values on browser the virtual index are mapped to real index:
		promises.push(setPump(realind,aTT[i], fn));
	 using:
		- old : state.devmapping ( per i prob : state.probmaping )

		- new : virt2realMap di models.js
	
	
	 who write to dev state ?   we keep real or virtual on state  or just we associate state with the dev descripion ? 
	 
	  >>>  lo stato dei dev lo teniamo in   relays con key devname ( see AASSWW) 
	  NB    relaisEv [heat,pdc,g,n,s,split,gaspcdPrefer,bloccoacs]da la corrispondenza    devname <> virtual index   cioe gli index in mqttnumb/gpionumb array
	  quindi ......
	 
	 nb seems devmapping no more used but virt2realMap  
	 
	 
	 
	 completare : // **** MNG SUMMARY mappings of probe and pump (devices shown  on pump list) devices :
	 
	 
	 
	 
	 	// **** MNG SUMMARY mappings of probe and pump (devices shown  on pump list) devices :
		// algo (exec procedure and its event manager) works on device using virtual index refearring to gpionumb/mqttnumb pump/var e mqttprob/pythonprob probs/var.
		// 	- gpionumb/mqttnumb
		//	 	name can be used instead of virtual index on gpionumb/mqttnumb using the corrispondence relaisEv
		//		ex state of gpionumb/mqttnumb dev ( state.relays) uses name keys according to  relaisEv  
		
		// some of pump/var are diplayed on browser as pump list with real index refearring to map[i] virtual index , map filled as 

	 
	 
	 
	 
	 
	 
	 stavamo guardando il mapping dei prob in : probes.notte=getPyProb(pyInd);
	 
_____________________
todo error in   if(eM.iodev.relais_[ii].gpio==0)mqtt2webS=eM.iodev.relais_[ii];// the ctl for     >>> probabilmente perche bloccato nel debug : controllare senza fermare in debug ! 

__________________________________________
riassunto pgm tollerance in browser 

in startprog() called x firare l'event "startprogrammer" :
	- crea TgiornoToll riformattando il PGMgiorno= {'8:30':0,"10:50":1022} >  {'8:30':0,"10:50":22}
		e aggiungendo triggers2.TgiornoToll[x]=0; o triggers2.TgiornoToll["10:50":]=triggers2_.TgiornoTollerance , il valore della tolleranza nel input TgiornoTollerance
		
		TgiornoToll viene poi raccolto nel event handler e filla il sched con cui chiama prog_parmFact(sched):
		{
				  programs: {
				    giorno: {sched: {"8:30": 27,"17:00": 30,},
                                         	toll: {"8:30": 0,"17:00": 0,},
                                         	TgiornoTollerance: 0},
				   notte:{},                                                 },    
				  probMapping: [   2,   4,   0,   3,   1,  5,  ],
				  mapping: [ 0, 1,2, 3,-1,  5, ],
				  ei: "S",
				}
				
	prog_parmFact(sched) setta il
	 let dataArr_=	{
			  initProg:{dataArr:sched},// std input dataArr coming from sched
			  genZoneRele:{dataArr:sched}};
			  
	che mi ritrovo nel input degli event , ex 
	
	these.on('genZoneRele', async function ( inp_, cb) {// the fsm ask state updates (we use openapi) : will set input of 'startcheck' , best to set also corresponding state ( last data gathered from fusionsolar)

                                        /*
                                           inp_={
                                              dataArr: {
                                                programs: { giorno: [Object], ei: 'W' },
                                                probMapping: [ 2, 4, 0, 3, 1, 5 ],
                                                mapping: [ 0, 1, 2, 3, -1, 5 ]
                                              },
                                              initProg: { notte: 20, giorno: 20 }
                                            } 
________________________________________

il protocollo shellyht  legge temp as string , !!!
__________________________________
controllare che, come  e quando : se cambio uno state.x.y.z   allora viene scritto in persistant as json 
____________________________
test if string is float or integer : console.log((!Number.isNaN(val_=Number(test))),but Number()  is 0  with "",undefined and null !!!
		so : test != null &&test !='' && (!Number.isNaN(val_=Number(test))    is goog to test a float , int or a number string 
test if a integer :
- Number.isInteger(Number.parseInt(test)),test); 
or better :
- (Number.isInteger(Number(val)))   but 0=Number()  is got with "",undefined and null !!!
__________________________________________________

 setManual (pump_, val, coming,checked,eM) 
   console.log(' abilita2 interrupt Iter1 : receiving   var ',pump,', msg val (0/1) : ',val_,'  checked : ',checked_,'  , actual status is :',state.relays[pump],' , queue is :',queue,', data was ',data);
	 console.log(' socket.on(manualAlgoProposal  handle set manual proposal');  
	 1695413982434,
	 mosquitto_sub -t   @Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd   -u sermovox -P sime01 -h bot.sermovox.com -p 1883
	 Subscribed successfully in plant
	 	 
	 
	 onRelais,  changing/confirm current rele hw position/value x  gaspdcPref  , index  6  ,  to new value:  1
writeSync() , using instance  1695343770933  Published on device  55  , a var msg  {"payload":1,"sender":{"plant":"Casina_API","user":55}} ,successfully to @Casina_API@ctl_var_gas-pdc_4
 ** writesync , using instance  1695343770933  for portid  55 , cl   2 , is ending writinging val:  1 , now current dev queue is :  []  returning code {"payload":1,"sender":{"plant":"Casina_API","user":55}}
 onRelais,  todo : verifying current rele  position/value changing  x  gaspdcPref  now is:  1
 stlist() : listener x dev :  55 , registered to wait for next message, in request ts # 1695343831258 , in listener position #  0  is timeout.  so cb with void message
 executing shell:    cioe ${stdout}
 std error is  ok
 getio() , shellcmd  n.  1  returned :  ok  cioe ${stderr}
 executing cmd:  python3 rs485_simul.py w 4 4188 0 >> resultrs384.txt
 mqtt income. Received message  {"payload":1,"sender":{"plant":"Casina_API","user":55}}  on topic  @Casina_API@ctl_var_gas-pdc_4
 mqtt Received message x dev  55  thats a var , coming from itself
 mqtt income. Received message  {"payload":0,"sender":{"plant":"Casina_API","user":55},"url":"setMan","checked":1}  on topic  @Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd
 mqtt Received message x dev  55  thats a var , coming from itself
  message  with cmd topic x device  55 , of type  2  , so  interrupt to update the value. after update this dev will writesync the value x confirmation
 abilita2 interrupt Iter1 : receiving   var  gaspdcPref , msg val (0/1) :  0   checked :  1   , actual status is : true  , queue is : [] , data was  {
_______________________________________________________
si ribadisce che e' meglio creare automation scegliere il rele e poi aggiungere automation che al change ( o via una sua copia template) triggery un dev noto di fv3
_________________________________________ 
spiega attuale cfg al 22092023
# "data":[1,23,2,{"power":{{ states.input_number.box1.state }}}]   ,"data1":{{ states.sensor.pippo.state }}  "data":{{ states.input_text.text1.state }},
# Loads default set of integrations. Do not remove.
default_config:

# Load frontend themes from the themes folder
frontend:
  themes: !include_dir_merge_named themes
"fv3_cmd_startAnticipate" (sostituito dal   "fv3_cmd_start" ) 
automation:
  - alias: "fv3_mnged_state_optimize"
    id: "optimize"
    initial_state: true
    trigger:
      - platform: state
        entity_id: select.NRInt
    condition:
    action:
      - service: mqtt.publish
        data:
          topic: '@Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd'
          payload: >
            {"payload":{{ states.select.NRInt.state }},"sender":{"plant":"Casina_API","user":55},"url":"setMan","checked":1}
  - alias: "fv3_cmd_startAnticipate"
    id: "anticipate"
    initial_state: true
    trigger:
      - platform: state
        entity_id: input_button.start_ensavings
    condition:
    action:
      - service: mqtt.publish
        data:
          topic: '@Casina_API@interface_mqtt_websock_0/NReadUser/cmd'
          payload: >
            {"payload":{{ states.select.NRInt.state }},"sender":{"plant":"Casina_API","user":77},"url":"mqttxwebsock","event":"repeatcheckxSun","data":{{ states.sensor.pippo.state }},"param":"{{ states('input_select.savingsservice') }}"}
  - alias: "fv3_cmd_start"
    id: "startEM"
    initial_state: true
    trigger:
      - platform: state
        entity_id: input_boolean.savingsservice
    condition:
    action:
      - if:
         - condition: state
           entity_id: input_boolean.savingsservice
           state: 'on'
           
        then:
         - service: mqtt.publish
           data:
             topic: '@Casina_API@interface_mqtt_websock_0/NReadUser/cmd'
             payload: >
               {"payload":{{ states.select.NRInt.state }},"sender":{"plant":"Casina_API","user":77},"url":"mqttxwebsock","event":"repeatcheckxSun","data":{{ states.sensor.pippo.state }},"data1":{{ states.input_text.text1.state }},"param":"{{ states('input_boolean.savingsservice') }}"}
        else:
         - service: mqtt.publish
           data:
             topic: '@Casina_API@interface_mqtt_websock_0/NReadUser/cmd'
             payload: >
                 {"payload":0,"sender":{"plant":"Casina_API","user":77},"url":"mqttxwebsock","event":"stopcheckxSun"}

  - alias: "yaml_generator"
    id: "yaml_gen"
    initial_state: true
    trigger:
      - platform: webhook
        webhook_id: "genyaml"
        allowed_methods:
          - POST
          - PUT
        local_only: false    
    condition:
    action:
      - service: shell_command.write_yaml23
        data:
          filename: pippo.txt
          shellname: "{{ trigger.json.shellname}}"
          myjson: "{{ trigger.json}}"
          yaml: "{{ trigger.json.data}}"
          shell: "{{ trigger.json.shell}}"
      - service: shell_command.write_yaml22
        data:
          filename: pippo.txt
          shellname: "{{ trigger.json.shellname}}"
          myjson: "{{ trigger.json}}"
          yaml: "{{ trigger.json.data}}"
      - service: shell_command.subst2
      - service: shell_command.write_yaml24
        data:
          filename: pippo.txt
script: !include scripts.yaml
scene: !include scenes.yaml
mqtt:
# esempio di rele dev . i state del rele sono pub su state_topic che switchano i on e off state del entity  monitorando cosi il settaggio dei rele da parte del fv3. 
# quando switchato emette un comandtopic che e' l'input del rele o meglio potrà essere, come per i var, un nodered command topic che lancia un interrupt per settare un Manual Algo request
  - switch:
      name: "RSSI"
      qos: 1
      state_topic: shellies/shelly1-34945475FE06/relay/0
#      value_template: "{% if value == 'on' %} on {% else %} off {% endif %}" only x sensor ?
      payload_on: "on"
      payload_off: "off"
      state_on: "on"
      state_off: "off"
      command_topic: shellies/shelly1-34945475FE06/relay/0/command
      json_attributes_topic: shellies/shelly1-34945475FE06/relay/0
      json_attributes_template: >
        { "jsonattr": "{{value}}"}
        
# Example configuration.yaml entry  ??
  - text:
      name: "node-red_pub"
      icon: mdi:ab-testing
      mode: "text"
      command_template: '{"payload":{{states.sun.sun.attributes.friendly_name}},"sender":{"plant":"Casina_API","user":55},"url":"setMan","checked":1}'  
#     command_template: 'pippo'  
      command_topic: "@Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd"
      state_topic: "@Casina_API@ctl_var_gas-pdc_4"
      min: 2
      max: 20
      
# Example configuration.yaml entry , x numbSubscr var dev. command_topic is just a info topic (Node-Red-Register)  published with option when selected in overview 
# when selected it will launch also automation that will fire on cmdtopic=@Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd a formatted json to lauch a interrupt to set a ManualAlgo . 
#  nb when fv3 works with some algo on this attribute it will emit a writesync() , and  also pub on json_attributes_topic a formatted value,  value.payload ='0/1' will set the algoSuggested property of the select entity
  - select:
      command_topic: Node-Red-Register
      json_attributes_topic: '@Casina_API@ctl_var_gas-pdc_4'
      json_attributes_template: >
        { "algoSuggested": "{{value_json.payload}}"}
      name: "NRInt"
      options:
        - "0"
        - "1"
input_number:
  box1:
    name: "minPower"
    initial: 30
    min: -20
    max: 35
    step: 1
    mode: box
input_button:
  start_ensavings:
    name: "Energy_Savings"
    icon: mdi:bell
# savings service on
input_boolean:
  savingsservice:
    name: use ai to savings energy
    icon: mdi:tools
# donot resolve state, so use as programmer input
input_text:
  text1:
    name: Text 1
    initial: '{"PGMgiorno" : { "8:30" : 27, "17:00" : 30 }}'
template:
  - sensor:
      - name: "pippo"
        state:  "[1,23,2,{\"FVPower\":{{ states.input_number.box1.state|int }}}]"
        icon: mdi:tools
# API
api:
shell_command:	    		
   write_yaml: /bin/bash -c "echo {{ yaml }} > {{ filename }}"
   write_yaml2: /bin/bash -c "echo '{{myjson.data}}'  >{{ filename }}"
   write_yaml22: /bin/bash -c " echo '{{myjson.data}}'  > {{ filename }}  "
   write_yaml23: /bin/bash -c "echo '#!{{shell}}'  > {{ shellname }} "
   write_yaml24: fvshell.sh
   write_yaml3: /bin/bash -c "echo '{{myjson}}'  >{{ filename }}"
   write_yaml4: /bin/bash -c " mydata='{{myjson.data}}' && echo $mydata  >{{ filename }}"  perde blanks
   subst: " cat {{ filename }} >  fv3.txt "
   subst1: cat pippo.txt | sed -e "s/£££/\\n/g" | sed -e "s/££/\'/g" | sed -e "s/£/\"/g" >{{ filename }}
   subst2:  sed -i "s/£££/\\n/g" pippo.txt&& sed -i "s/££/\'/g" pippo.txt && sed -i "s/£/\"/g" pippo.txt
   
   spiega:
   
   il nrint riceve da fv3 il update del rele associato a  anticipate attivo , lo posso anchemodificare ma non deve lanciare nessun comando topic (@Casina_API@interface_mqtt_websock_0/NReadUser/cmd')associato al anticipate var dev  al anticipate algo. 
   	>> todo 
   		quindi modifico  lo automation "fv3_mnged_state_optimize sul configuration.yaml di sopra :
   				modificando il trigger con :
   				
   				      - platform: state
        				  entity_id: select.NRInt
   				
   				
   				
   		cancello  il "fv3_cmd_startAnticipate" (sostituito dal   "fv3_cmd_start" )
   	
   - solo quando modifico il nrint e lancio il button  input_button.start_ensavings allora pubs sul cmdtopic del anticipate cmd topic '@Casina_API@interface_mqtt_websock_0/NReadUser/cmd' , il che triggera un interrupt per settare una richiesta di useralgo per il var dev anticipate 
   	dettaglio auth : 
   		usare uno user 1055 per dire al dev 55 che sono il ha associato  da cui arriva un cmdtopic (il mqtt auth tuttavia deve impedire che un client possa inviare un pub su un topic non previsto per il client autorizzato  ) 
   		>>  in sostanza il brocker deve capire che quando il client hs chiede un connection il client deve avere le auth per publicare sul client fv3 che e' associato al client che e' autorizzato a lavorare sul plant in questione
   		
   		
      value_template:  >
        {% if value_json.payload == 0 %}
          "0"
        {% elif value_json.payload == 1 %}
          "1"
        {% endif %}"
        
              value_template:  "{% if value == 'on' %} 1 {% else %} 0 {% endif %}"
              
      value_template:  |-
        {% if value_json.payload == 0 %}
          "0"
        {% elif value_json.payload == 1 %}
          "1"
        {% endif %}" 
        
        
ok :
  - select:
      command_topic: 'Node-Red-Register'
      state_topic: 'Node-Red-Register1'
      json_attributes_topic: '@Casina_API@ctl_var_gas-pdc_4'
      json_attributes_template: >
        { "algoSuggested": "{{value_json.payload}}"}
      name: "NRInt"
      options:
        - "giallo"
        - "verde"
      value_template:  '{% if value_json.payload == "giallo" %} giallo {% elif value_json.payload == "verde" %} verde {% endif %}'
      
 ok:
 
   - select:
      command_topic: 'Node-Red-Register'
      state_topic: 'Node-Red-Register1'
      json_attributes_topic: '@Casina_API@ctl_var_gas-pdc_4'
      json_attributes_template: >
        { "algoSuggested": "{{value_json.payload}}"}
      name: "NRInt"
      options:
        - "0"
        - "1"
      value_template:  '{% if value_json.payload == "0" %} 0 {% elif value_json.payload == "1" %} 1 {% endif %}'   
 _____________________________
 provato con ma non va (in configuration_ok11092023 (copy)):
   - alias: "relay2fv3"
    id: "relaytemp"
    trigger:
      - platform: state
        entity_id: select.NRInt
    condition:
    action:
      - service: mqtt.publish
        data:
          topic: 'xshellies/shellyht-1E6C54/sensor/temperature'
          payload: >
            {"payload":{{ states.select.NRInt.state }},"sender":{"plant":"Casina_API","user":69},"url":"setMan","checked":1}
 
 
 infatti riprovato il vecchio configuration_ok11092023.yaml e va !!!
  cio perche/quando si aggiunge a NRInt il : 
  	state_topic: 'Node-Red-Register' 
  	
  	il problema si è poi risolto perche si triggera in effetty lo shelly rssi !!!!!
  	
  	
  	nb to publish  select options  see : https://community.home-assistant.io/t/mqtt-select-wont-publish-the-new-selected-value/405056/2
 _________________-
 Setup is at the moment:
config.yaml

select: !include select.yaml

select.yaml

- platform: mqtt
  name: "Husmodus"
  state_topic: "custom/select/husmodus/01"
  command_topic: "custom/select/husmodus/01/set"
  options: 
    -"Normal"
    -"Borte"
    -"Ferie"
    -"Natt"
    _____________________________________
    
    evaluate also the possibilita di settare i device con le api , see https://stevessmarthomeguide.com/adding-an-mqtt-device-to-home-assistant/   https://i3engineering.com/an-example-of-setting-up-devices-in-home-assistant-using-mqtt-discovery/en
    	>>> https://community.home-assistant.io/t/solved-how-to-get-mqtt-select-in-discovery/349328
 ________________________________
 todo : fare anche il var dev nrint con switch al posto del select !
    value_template: >- 
  {% if value_json.switchType == 1 %}
    on
  {% else %}
    off
  {% endif %}
  see https://community.home-assistant.io/t/mqtt-switch-help-with-value-template/290572
  _____________________________
  
  riassunto situazione casina 10092023
  
  logica  PPKK: scegliere i dev con blueprint e poi con i relay automation faccio il relay dei device scelti o dei loro estratti template (nome fisso) verso i dev fissi di fv3 	
  il modello proposto per una nuova versione ha: 
  -  device :
  
  	- shelly x caldaia , ora rssi
  		al cambio stato alimenta il dev heat consence di fv3 : il relay automation emette un pub mqtt con devid con un: carattere in piu del attuale . es  : shellies/shelly1-34945475FE06/relay/0  >  shellies/shelly1-34945475FE06_/relay/0
  		esso non va usato qundo lancio il anticipate o il program , 
  		 recupera il modo di operare per settare eventualmente un manual con un command topic che lanci un interrupt (come i var type2) 
  		 	> ma qui ho un type 1 con gia un command per settare il dev! mntre avrei bisogno (anche ) di un set del manual che il dev type 2 settano con il cmd topic che lancia un interrupt
  		 		no non serve mandare un cmd topic sul heath , basta mandare un cmd topic sul intermediate nrint , il itermediate è fatto per questo !!!
  		 				rivedi la teoria piu sopra !
  		
  	- shelly da aggiungere per un rele acs che per praticita puo essere un rele di  on/off impianto , in || con int nero/bianco
  	
  	- shelly ht , anche lui con relay al probe di fv3
  	
  	- var dev anticipaterunning, nrint,  ma realizzato come sensor o switch perche il select non ha uno state disponibile 
  		nb      - command_topic: 'Node-Red-Register1'  si manda a un topic di info
      			- state_topic: 'Node-Red-Register' > dovrebbe essere invece il '@Casina_API@ctl_var_gas-pdc_4'   !!!
      			- per inviare il fv3 com topic (@Casina_API@ctl_var_gas-pdc_4/NReadUser/cmd) (x settare il lastusermanual proposal) si usa un button input_button.start_ensavings !
  	
  	- input_boolean.savingsservice fire il cmd x fv3 , es start/stop  algos
  		alcuni param sono estratti da pippo(template che formatta il power estratto dal  states.input_number.box1) e input_text (text 1 x temp program )  : states.sensor.pippo.state }},"data1":{{ states.input_text.text1.state
  		
	- il webhook "genyaml" permettere invece di scaricare il yaml che poi viene added dal user al yalm config as added file  
	
	nb al posto di scaricare il yaml (con webhook) posso usare i native device (configurati con blueprint?) di ha su cui fare il relay verso i corrispondenti in fv3
	
	nb il mqtt broker se uso quello di fv3 devo passargli user e password (sempre via webhook come per il file yaml ? ),
	invece se il broker è del user (es sempre dentro il container magari con anche nodered) 
	- forse devo aprire una websocket per collegare il fv3 al posto di fare il relay su broker fv3 verso il device ombra fv3 ? 
	- o metto una app nel container che intercetta il relay fatta sul broker interno e lo rigira verso fv3 usando un websocket ?
	-o banalmente collego in ws con il package fornito ws e poi chiamo quando scrivo sui device , in writesync oltre che scrivere/pub posso anche chiamare il ws verso ha e lanciare un service che setta il state di un local sensor/wswitch e il command template si arrangia a mandare il cmd topic al shelly pump , vedi service di prova, invece i sensor locali al cambio stato possono inviare un msg sul ws conection che provvede a inserire il msg sul queue del device sensor  mqtt . esso sara letto da readSync  !!
	 vedi :  https://jeroenboumans.medium.com/listening-to-the-home-assistent-websocket-api-with-python-7a074f8c81ea che copia lo state dei sensori su un file di log (noi faremo banalmente copia in mqtt dev queue !) 
	
invece la versione attuale continua ad avere i device definiti da uno scaricamento via webhook del confg_fv3.yaml
 in pratica uso direttamente configurare  device coi indirizzi reali di fv3 che scarico via config_fv3.yaml
 al posto di quello di sopra PPKK
 ___________________________________
 
    using script in mqtt service : https://www.home-assistant.io/integrations/mqtt
    Automations

Use as script in automations.

automation:
  alias: "Send me a message when I get home"
  trigger:
    platform: state
    entity_id: device_tracker.me
    to: "home"
  action:
    service: script.notify_mqtt
    data:
      target: "me"
      message: "I'm home"

script:
  notify_mqtt:
    sequence:
      - service: mqtt.publish
        data:
          payload: "{{ message }}"
          topic: home/"{{ target }}"
          retain: true
 ________________________________
 
 https://www.home-assistant.io/docs/scripts/service-calls/
 the basics

Call the service homeassistant.turn_on on the entity group.living_room. This will turn all members of group.living_room on. You can also use entity_id: all and it will turn on all possible entities.

service: homeassistant.turn_on
entity_id: group.living_room

YAML
Targeting areas and devices

Instead of targeting an entity, you can also target an area or device. Or a combination of these. This is done with the target key.

A target is a map that contains at least one of the following: area_id, device_id, entity_id. Each of these can be a list.

The following example uses a single service call to turn on the lights in the living room area, 2 additional light devices and 2 additional light entities:

service: light.turn_on
target:
  area_id: living_room
  device_id:
    - ff22a1889a6149c5ab6327a8236ae704
    - 52c050ca1a744e238ad94d170651f96b
  entity_id:
    - light.hallway
    - light.landing

YAML
Passing data to the service call

You can also specify other parameters beside the entity to target. For example, the light.turn_on service allows specifying the brightness.

service: light.turn_on
entity_id: group.living_room
data:
  brightness: 120
  rgb_color: [255, 0, 0]

YAML

A full list of the parameters for a service can be found on the documentation page of each integration, in the same way as it’s done for the light.turn_on service.
Use templates to decide which service to call

You can use templating support to dynamically choose which service to call. For example, you can call a certain service based on if a light is on.

service: >
  {% if states('sensor.temperature') | float > 15 %}
    switch.turn_on
  {% else %}
    switch.turn_off
  {% endif %}
entity_id: switch.ac

YAML
Using the Services Developer Tool
___________________________________
 82.60.170.209:8123/lovelace/0

You can use the Services Developer Tool to test data to pass in a service call. For example, you may test turning on or off a ‘group’ (See [groups] for more info)

To turn a group on or off, pass the following info:

    Domain: homeassistant
    Service: turn_on
    Service Data: { "entity_id": "group.kitchen" }

Use templates to determine the attributes

Templates can also be used for the data that you pass to the service call.

service: thermostat.set_temperature
target:
  entity_id: >
    {% if is_state('device_tracker.paulus', 'home') %}
      thermostat.upstairs
    {% else %}
      thermostat.downstairs
    {% endif %}
data:
  temperature: "{{ 22 - distance(states.device_tracker.paulus) }}"

YAML
You can use a template returning a native dictionary as well, which is useful if the attributes to be set depend on the situation.
_________________________
attenzione cambiare nrint in sensor che non ho disponibile lo state x i action degli automate .
________________________
todo 
prova cambiare preferredgasfv  alcune volte specchia in nrint (anticipo attivo 2) a volte no !
	cancellare anticipo attivo
manca il flag anticipate algo active/not active
	e ralativa sincro con il use ai to saving, quando si switcha da browser il anticipate algo
		ma questo non e' banale perche il anticipate algo flag del browser non e' uno status dei dev ma in state. che il flag si attiva da data.anticipate null/notnull !  , che non è copiato da nessun writesync e relativo mqtt pub !!!!
	
prova : - setta anticipo attivo 1 da ha con use ai to saving,
	- spegni browser,
	- switcha a 0 anticipo con use ai to saving,
	- riapro il browser e devo vedere in anticipate flag spento

____________________________________________________
092023

dev mapping 

algo works on virtual device on mqttnumb e mqttprob, each specific device has a virtual index,
now:
- virt2realMap:[0,1,2,3,4,5,6,7],// std virtual group , map only if >=0 , some bugs: so use identity only
  it should map virtual dev to mqttnumb devices , that has associated state management (state.relays?) that are represented in order in web browser
  
- virt2realProbMap:[0,1,-1,-1,-1,-1],
  that map the virtual index into the real index on mqttprob and pythonprob devices has the type3 and 4 dev type
  il meccanismo per recuperare i device prob e' quello usato negli event ,es see : these.on("initProg",//
  	recuper il plant cfg con : state.app.plantconfig.virt2realProbMap;
  	e usando le funzioni getPyProb(pyInd) e getMqttProb si recuperano i index(ind= map[ilvirtualindex del device su cui si vuole operare]) con cui accedere al ctl dei dev 
  		es : 
  		dev= these.iodev.probs_[ind])!=null){
    		curval=await dev.readSync();// 0/1
  }

news : si introdice il dev state, dummy, al virtual index 0 dei virt2realProbMap , che rappresenta un var dev , type 4 , che contiene specifiche var dello state :
	{statevar1,statevar2,,,} in json string format
	usually are only writeSync to subtopic:'var_state_' 
____________________________________

error in event , cant find triggers2 :

 handler fired by event genZoneRele , with input data:  {
  "dataArr": {
    "programs": {
      "giorno": {
        "sched": {
          "8:30": 28,
          "17:00": 30
        },
        "toll": {
          "8:30": 0,
          "17:00": 0
        },
        "TgiornoTollerance": 0
      }
    },
    "probMapping": [
      2,
      4,
      0,
      3,
      1,
      5
    ],
    "mapping": [
      0,
      1,
      2,
      3,
      -1,
      5
    ],
    "ei": "S"
  },
  "initProg": {
    "giorno": "24.12",
    "notte": 21
  }
}
program() called with programming/scheduling data inp:  {
  "programs": {
    "giorno": {
      "sched": {
        "8:30": 28,
        "17:00": 30
      },
      "toll": {
        "8:30": 0,
        "17:00": 0
      },
      "TgiornoTollerance": 0
    }
  },
  "probMapping": [
    2,
    4,
    0,
    3,
    1,
    5
  ],
  "mapping": [
    0,
    1,
    2,
    3,
    -1,
    5
  ],
  "ei": "S"
}  and current probs:  { giorno: '24.12', notte: 21 }
program() NB before call consolidate ret=optimize(ret) can have any null value!
 runEvent(): promise was started ( probably terminated)  , event  genZoneRele , ev2run is: { initProg: null, genZoneRele: 'initProg' }  con input dataCon:  {
  initProg: {
    dataArr: {
      programs: [Object],
      probMapping: [Array],
      mapping: [Array],
      ei: 'S'
    }
  },
  genZoneRele: {
    dataArr: {
      programs: [Object],
      probMapping: [Array],
      mapping: [Array],
      ei: 'S'
    },
    initProg: { giorno: '24.12', notte: 21 }
  }
} , dataInv(quali eventi sono alimentati):  { initProg: 'genZoneRele' }
Waiting for the debugger to disconnect...
/home/luigi/localdev/raspexampl/fv/fv3.js:1041
state.program.triggers2.lastT=[date.toLocaleString(),probes];//JSON.stringify(probes)]; anomalus array with different types
                             ^

TypeError: Cannot set properties of undefined (setting 'lastT')
    at program (/home/luigi/localdev/raspexampl/fv/fv3.js:1041:30)
    at WithTime.<anonymous> (/home/luigi/localdev/raspexampl/fv/fv3.js:2317:13)
    at WithTime.emit (node:events:526:28)
    at WithTime.InnerFunction (/home/luigi/localdev/raspexampl/fv/app2.js:332:14)
    at runEvent (/home/luigi/localdev/raspexampl/fv/app2.js:475:49)
    at goonstep_ (/home/luigi/localdev/raspexampl/fv/app2.js:426:9)
    at goonstep (/home/luigi/localdev/raspexampl/fv/app2.js:409:15)
    at updateData_ (/home/luigi/localdev/raspexampl/fv/app2.js:318:7)
    at WithTime.<anonymous> (/home/luigi/localdev/raspexampl/fv/fv3.js:2258:1)
    at runMicrotasks (<anonymous>)
____________________________________

 socket.io  summary 
 
x il namespace nodered si è  seguito: https://socket.io/docs/v4/namespaces/

nb :  io.on = io.of("/").on  =  io.sockets.on ,  
	cioe io=io.of("/") ? oppure io.on  registra middleware attaccato a tutti i namespace ?   

- const adminNamespace = io.of("/admin");
- mainspace: io.sockets === io.of("/")

connection crea il socket che definice i event handler :

                io.of("/").on("connection", (socket) => {
                
                	socket.on()
                	socket.emit()
                });
                io.of("/").use((socket, next) => { next() });// socket middleware , can be used to auth:
                	 io.of("/").use((socket, next) => {
                                        const token = socket.handshake.auth.token;
                                        // ...
                                      });
                io.of("/").emit("hi", "everyone!");  emit on all connected sockets
                
                ........................
                
_______________________

reference out of scope in socket.on('comnnection',,
	plantcnt=model.ejscontext(plant_),
	    eM = ccbbRef(plantcfg.name);              
________________________________________

user - plant association

dopo che il client (installer che puo avere piu plant da gestire) si è identificato puo chiedere la gestione di un plant con:
- socket.on('startuserplant', handler:

 	 se il plant e' gestibile da client/user (see plants['MarsonLuigi_API'].users ) allora si carica il controller con:
 	 	  eM = ccbbRef(plantcfg.name);
 		  aggiungendo i rif al current session/socket : eM.getcontext={getSession:session,,,,
 		  nb getSession is used in onRelais()!
 		  
 		  nb: verra aggiunto anche il ref al socket, nodered socket, home assistant socket ....

	ccbbRef=function ccbb(plantname) {// when client/plant got a request (a button) for a plant on a webpage , we fire : socket.on('startuserplant' ,that to operate/ register the fv ctl inst
	>  so we instatiate or recover  the fsm: ()  calling ccbbRef(plantname) 
	 
	> recover from : return started[name].inst;	
	> instantiate with event_manager/fsm factory : the eMClass.cfg factory: 
	
	      inst=started[name].inst = (new eMClass()).cfg(name);// create the fv ctl, customize its .on . nb function cfg() is created in this module !
	      inst.reBuildFromState=true;// that wll be overwritten by loadstate !!!
	      inst.init=false;// not redy to be used without recover state and connectto to device 
	      return inst
	      
	      nb  eMClass is got calling fsmManager = require('./app2.js') :

			      	fsmmanager(opt, function (app, opt, no_ccbb) {// ask fsm factory app to give the event factory eMClass, or connect as login to the app server
		  			// no_ccbb   needed ??
		  			
		  			eMClass = app.getEventMng();
	      				...
		  			eMClass.prototype.cfg = function (plantname) {// add a cfg static func that add fv3 custom .on on all instance 


__________________________________________________________
 res =[...state.app.plantconfig.relaisDef];// clone array
 ______________________________________________________
 
 *************  good 251102023:      restructuring sw .on('connect',handler)		XXRR
 
 		function handler(){
 		eM=
 		repeat=
 		
 		}
 
 	e interni socket.on('event',handler1)
 	
 			nb handler1 usa variabili di state a livello plant (eM/fn) poi risolto il plant il handler e' in efeftti stateless dal punto di vista plant per tutta la gestione del plant sucessiva 
 				recuperati dal user sul bank plants[]
 				>>> in altre parole si potrebbe pensare il handler1 come il risultato di un factory (closure) che mette a disposizione del handler delle variabili static settate in base ai parametri della chiamata del factory !!!!!
 
 l'handler/1 e' meglio metterlo in un require ext cosi e' chiaro quali main var vengono passati , esse sono uno state addizionale degli handler 
  es in socket.on('startuserplant' ,handler2) in base al user authenticated e al plant autorizzato che vuole gestire , viene recuperato/generato il ctl del plant 
  - quando faccio partire un repetitive algo uso un repeat che una volta creato poi rimane a disposizione nel socket per accendere spegnere gli algo del plant sulla schermata browser
  - gli algo quando girano settano state.program/anticipate che viene poi recuperato nel caso di nuova connessione socket:
  
  	- build/recover fn/eM, recover state, add mqtt devices using startfv_:
  	
  		-  {eM,repeat,repeat1} = (ccbb=ccbbRef)(plantcfg.name).inst;  GGTT
  			
		    eM.getcontext=...
		    em.socket= socket
  		-  if (eM) {
			     // startfv_(eM,user);// ** start/update singlethon 
			     recoverstatus.call(eM,plantcfg,plantcnt,plantconfig,feature).then((em_) => startfv_(em_,oncomplete_)); /
  		
  	- oncomplete(): will:
  			- start program/anticipate according state.program/anticipate if the algo in not active (lauched before in a socket connection in a app/server instance not stopped )
  				cioe' se eM/fn e' stato recoverato dal server instance bank plants, vuol dire che stava girando  e quindi anche i suoi algo come si vede dallo state
  				ma se eM è stato creato perche il server è stato stoppato o perche qualcuno ha stoppato il fn allora devo ripristinare gli algo previsti dallo state che ha registrato l'ultimo state valido del plant 
  				
  			- if fn e' recoverato e tutto va bene almeno allineare gli stati dei pumps/relais del browser con il loro corretti state state.ralays lanciando setPump su tutto il state.relays  !!!!!  **********  todo  *********
  				
  		se ad es trovo state.program allora vuol dire che esso stava girando perche precedentemnte ho girato repeatHandler1 :
  			repeatHandler1 esso avendo procurato il launcher repeat/1 membro del handler XXRR:
  				handler.repeat1= repeat1||fv3.checkFactory(eM) // checkFactory è factory/closure del repeat/repeat1!
  				
  					*** idea: invece di settare repeat qui posso tentate di recuperarlo in GGTT. praticamente quando apro un nuovo socket connection ricovero il eM e anche il repeat/1 !!
  							>>  fatto !
  				
  				nb quando chiudo la connessione socket il XXRR handler possiede (come in un closure) delle var che sono riferite da funzioni/ oggetti che sono ancora attivi e disponibili pertanto non puo essere garbage collector 
  		(ri)lancia il algo :
  			- repeat1.repeatcheckxSun(starthour,stophour,dminutes,prog_parmFact(sched))==0)
  					nb if find  (repeat/1=checkFactory).interv  vuol dire che il interval che lancia ripetutamente la func del algo e' attiva 
  						usualy we will stop it and reset !! :
  					- if (interv) clearInterval(interv);
  						>> why reset ????? if we want to reset it and restart using the new devices rebuilt with current cfg in model we can stop and start the algo from browser !!!!!
  						>> so if repeat is recovered in a socket and we want to restart the algo we stop the previuos repetition interv 
  						>> but the problem is if we exit from socket and a client reconnect we probably  find the previous repeat that is alredy working :
  							see :
  								    	repeat =started[name].repeat;
    									repeat1=started[name].repeat1;
  						>>>>> so we can store a reference on checkFactory somewhere in plants[aplant] ?????
  							probably yes!!
  			
  				setanticipateflag({running:true,starthour,stophour,dminutes,triggers2},'program');
  				
  					
  				
  				> tale funzione di repeat1 non ha rif esterni ma continua ad operare 
  							see: checkFactory.gfg_Run_()
  								esso fa rirare piu volte checkFactory.callF() 
  									che opera sulle variabili di checkFactory :
  										fn
  								 e lancia checkFactory.callFn_(execParm);
  								 	che opera sulle variabili di checkFactory : es execParm
  								 	e lancia fn.execute(procName,a,b,  ev2run, asyncPoint, processAsync, dataArr, finche non siamo fuori limiti giornata
  								 	con :  checkFactory.interv = setInterval(
  								 		>>> nbnb passando interv un rif alla procedura da ripetere , la funzione di sistema mantiene un rif a checkFactory che quindi non puo essere garbage collected !!!!!!!!!!!!!!!!!!!!!! 
  				
  				  fino a che viene arrestata con 
  					repeat1.stopRepeat() che provvede a clerare il interv !!!!!
  					setanticipateflag(false,'program','lastProgramAlgo');		
  							>> // store in state the algo launch params (ex: triggers), update state store :
  											state.program/anticipate=set_;
  											
  								**** cioe il state.program significa che l'algo program was started nd never stopped
  									quindi in oncomplete_() :
  									- se sono in un socket in cui ho lanciato il algo : il algo e' running posso resettarlo o stopparlo
  									- se non sono in un socket che lo ha lanciato : posso recuperatlo con  ccbbRef() e resettarlo (potrei anche semplicemente recuperarlo)
  									- se il server e' stato stoppato : il eM e repeat sono persi , ricostruirli !
  						mantiene rif al algo ???????
  					
  				 nel ambito della stessa connessione socket XXRR !
  				 ma se il socket viene chiuso ????  sembrache non siaa possibile avere il rif di interv a meno che non lo inserisco in setanticipateflag su qualche var !!!!!!!!!!!!!!!!!!!
____________________________________
adminNamespace.on("connection", socket => {// register emit handlers on 
  console.log(' from node-red  a socket started 
  
  ***************    todo complete event to manage () stop repeat algo,.....');

___________________________________________


se attivo 2 soket , allora ho 2 closure che lavorno sullo stesso fn , se cambio una attivazione su un browser si vedra dai 2 browser !?

__________________________________-

ipotesi stazionaria , cicli giornalieri che si ripetono 

al tempo t 
 calcolo se riempio la batteria in giornata con una stima consumi std :
 - si allora il delta devo se posso anticiparlo :risparmio energia enel( non immetto in rete energia del fv) 1 = anticipo min (ma in ogni caso limitato) per avere 100% a fine sole x tempo fino a fine sole
 	
 inoltre se posso anticipare ancora es 2 kwh , allora avro meno batteria ma avro risparmiato ciclo di batteria in % sul ciclo base (meta potwnza batteria)
 
 nb anticipo il condizionamento se t > t desidere programmata o se sono in recpero deferred con batteria vuota (avro anche risp ener enel) o no (risparmio di ciclo)
 
 - se non riesco a riempira la batteria ma non si svuota la notte:
 	converra anticipare al max per risparmiare sul ciclo
 	
 - se non riempio e si svuota la notte 
 	allora uguale a che non si svuota
 _________________________________
 
 test tollerance e ha ok manca attivare in tollerance anche pump consenso  e inserire tollerance quando start programmer da ha 
 - non occorre comandare il consenso al modo di node red (propone un manualalgo via interrupt) che funziona solo con fv3 attivato  perche e' un po complex x user 
 	tanto vale far vedere il 
   ma permettere di attivare un termostato locale quando il program algo è spento su switch nativo . si puo anche fare manual cmd sullo switch !
   
   >>> sistemare il ralay al _shelly......
   ___________________________
   https://emhass.readthedocs.io/en/latest/
   
   __________________________________________________
   todo if temp not got exit null from algo !!!
   ________________________________________
   when debugging and stop thea at restart the socket changes and has no more fn/eM instance so when push a button in browser we got error :
   ]
 stopprogrammer event fired
 stopRepeat() called . we must reset the runing intervals
.. setanticipateflag() eM is null 
.. setanticipateflag() eM is null 
 setanticipateflag() called to set running algo:  program  init param:  false  , in state. program  ,(if null init parm will also  reset state. lastProgramAlgo
anticipateFlag(), eM is null!, probably after a debugging stop point
anticipateFlag(), eM is null 
Waiting for the debugger to disconnect...
/home/luigi/localdev/raspexampl/fv/fv3.js:4522
  let state=fn.state;
               ^

TypeError: Cannot read properties of undefined (reading 'state')
    at anticipateFlag (/home/luigi/localdev/raspexampl/fv/fv3.js:4522:16)
    at setanticipateflag (/home/luigi/localdev/raspexampl/fv/fv3.js:4288:5)
    at Socket.stopprogrammer (/home/luigi/localdev/raspexampl/fv/fv3.js:4473:3)
    at Socket.emit (node:events:526:28)
    at Socket.emitUntyped (/home/luigi/localdev/raspexampl/node_modules/socket.io/dist/typed-events.js:69:22)
    at /home/luigi/localdev/raspexampl/node_modules/socket.io/dist/socket.js:614:39
    at processTicksAndRejections (node:internal/process/task_queues:78:11)

Node.js v17.5.0
luigi@luigi-Vostro-3560:~/localdev/raspexampl/fv$ 
_______________________--
  testinh ha 11102023
  - se parto pgm da browser non updato  il pgm in ha
  
  - sistemare il winter/summer in : if(triggers2&&triggers2.PGMgiorno){ 
	  triggers2.mapping="==&&state.devmapping=[0,1,2,3,-1,5]";
	  triggers2.probMapping="==&&state.probmapping=[2,4,0,3,1,5]";triggers2.ei=message.param.ei||"S";triggers2.Tgiorno=true; 
	  console.log('intWebSock() starting program  Algos');  
  - sistemare :
   mqtt income. Received message  {'id': '0', 'idx': '0', 'alias': None, 'platform': 'mqtt', 'topic': 'shellies/shelly1-34945475FE06/relay/0', 'payload': 'on', 'qos': 0, 'description': 'mqtt topic shellies/shelly1-34945475FE06/relay/0'}  on topic  shellies/_shelly1-34945475FE06/relay/0
 Inserted current message ( {'id': '0', 'idx': '0', 'alias': None, 'platform': 'mqtt', 'topic': 'shellies/shelly1-34945475FE06/relay/0', 'payload': 'on', 'qos': 0, 'description': 'mqtt topic shellies/shelly1-34945475FE06/relay/0'} ) , in current msg queue for device: 11  is:  [
  "{'id': '0', 'idx': '0', 'alias': None, 'platform': 'mqtt', 'topic': 'shellies/shelly1-34945475FE06/relay/0', 'payload': 'on', 'qos': 0, 'description': 'mqtt topic shellies/shelly1-34945475FE06/relay/0'}",
  'on',
  "{'id': '0', 'idx': '0', 'alias': None, 'platform': 'mqtt', 'topic': 'shellies/shelly1-34945475FE06/relay/0', 'payload': 'on', 'qos': 0, 'description': 'mqtt topic shellies/shelly1-34945475FE06/relay/0'}",
  "{'id': '0', 'idx': '0', 'alias': None, 'platform': 'mqtt', 'topic': 'shellies/shelly1-34945475FE06/relay/0', 'payload': 'on', 'qos': 0, 'description': 'mqtt topic shellies/shelly1-34945475FE06/relay/0'}",
  'on',
  "{'id': ....
  
  - 
  _____________________________________
  Avoid using states.sensor.temperature.state, instead use states('sensor.temperature'). It is strongly advised to use the states(), is_state(), state_attr() and is_state_attr() as much as possible, to avoid errors and error message when the entity isn’t ready yet (e.g., during Home Assistant startup).
  ___________________________________
  
  osservazioni :
# see https://www.home-assistant.io/docs/blueprint/tutorial/
blueprint:
  name: FV Optimizer consenso state
  description: FV OPtimizer state
  domain: automation
  input: 
    acs_switch:
      name: acs_switch
      description: switch acs
      selector:
        entity:
          filter:
            - domain: switch 
#  - alias: "fv3_relay_acs"
id: "optimize100"
initial_state: true
trigger:
  - platform: mqtt
    # qui bisogna calcolare il topic in funzione del device connesso quindi una funzione di ... con !input .....
    topic:  '@Casina_API@ctl_var_state_0'
    # payload: "on"
    # value_template: "{{ value_json.state }}"
    # These variables are evaluated and set when this trigger is triggered:    use : {% if myval == "ON" %}   switch.turn_on ....
    variables:
        myval:  "{{ trigger }}"
        myval2:  "{% if trigger.payload_json.payload.state.relays.acs == true %} ON {% else %} OFF {% endif %}"
    ##    myval:  "{% if value_json.payload.state.relays.acs == true %} ON {% else %} OFF {% endif %}"
condition:
action:
  - service: >
       {% if myval2 == 'ON' %}
         switch.turn_on
       {% else %}
         switch.turn_off
       {% endif %}
    target: !input acs_switch
  - service: mqtt.publish
    data:
      topic: 'poppo'
      payload: >
        {{ trigger }} and {{ myval }} and {{ myval2 }}			>>>>> trigger and myval sono ==   !!!!!
___________________________________

fn context e closure di fn , cioe il cb della connessione socket è closure(cioe lo contiene come oggetto , quindi le funzioni di fn vedono le variabili/oggetti del closure) di fn 
	nel cb girera' il fn e rimmarra a girare anche quando il socket viene chiuso
	per vedere se il socket e' aperto si testa clientDiscon !
	quando si riapre un socket la funzione di cb (nuovo closure) recupera il fn da started o ne instanzia uno nuovo recuperando anche tutti gli altri 'states' necessari a funzionare

quando al event     socket.on('startuserplant',
	- fn viene recoverato o viene instanziato, e aggiunto al bank di running ctl : started=[]
			let recInsts = ccbbRef(plantcfg.name);
    			fn=eM = recInsts.inst;
    	fn viene corredato di 'states' che contengono info sul plant gestito e oggetti che lo gestiscono :
    	 	- es 
    	 		   repeat,// active rep func x anticipate
			  repeat1,// active rep func x temperature programmer
			  clientDiscon=false;		e' settato false in closere cb , true in handler di   socket.on('disconnect',() => {// clientDiscon=true;  });		SSWW 

    	 e info sul corrente socket di connessione al browser:
    	 	- eM.getcontext (=context), es sessione corrente del browser
    	 	- eM.socket=socket;
    	 	
    	 		> eM.getcontext (=context) è usato in :
    	 		    - OnRelais()
    	 			- per controllare la sessione corrente dell'ultimo browser connession :  session 
    	 					per .....
    	 			- per controllare se il browser e' attivo e anullare la sua doppia richiesta : see: OnRelais started x mqttnumb dev , pump/devNam
    	 			
    	 				se proviene dal browser si processa solo se (context=fn.getcontext).processBrow()== true cioe se context.discFromBrow== false
   
   						infatti in setPump() :
   						 clientDiscon=fn.getcontext.getCliDiscon()=context.clientDiscon
   						 	se false (cioe il browser è connesso con il socket) :
   						 		  fn.getcontext.discFromBrow=true;// so in eM.getcontext.processBrow() return false if fn.state.discFromBrow=true
   						 		  // now reset timeoutref=fn.getcontext.blocking :
									  if(fn.getcontext.blocking)clearTimeout(fn.getcontext.blocking);// fn.state.discFromBrow : the server req  (onRelais ) is followed by a browswer req : 
									  //    so if a previous browser timeout was set , reset it and  reset the interval of browser  blocking 
									  fn.getcontext.blocking=setTimeout(()=>{ fn.getcontext.discFromBrow=false ;fn.getcontext.blocking=null},2000);
									  		naturalmente appena ricevuto il event dal server in onRelais si cancella immediatamente il flag browser blocking : discFromBrow: true > false
									  	>> questo resetta  con 2 s di ritardo il flag che blocca il processamento del setPump event  in OnRelais perche gia processato direttamente da setPump 
									  		di solito 
									  	 quindi dopo 2 s il browser puo mandare eventi che saranno processati da onRelais()
											>>> sarebbe meglio mettere un hash per escludere proprio operazione appena lanciate dal setPromp()    
   								quindi si lancia solo in tale caso (clientDiscon=false) il browser event con :
   									fn.pumpsHandler[pumpnumber](0,on_);/
   
   
   						>>>>>>>>>ok :   summary :
   						all'inizio in SSWW  si setta la variabile closure  clientDiscon che poi viene true solo  quando il socket esce SSEE
   							clientDiscon è disponibile anche in fn.getContext.getCliDiscon
   							
   						in setPump se c'è connessione socket con un browser (clientDiscon=false, :
   							- si setta getcontext.discFromBrow=true che è  flag di non doppo processamento 
   							 	e si rilancia un timeout con funzione che resetta il flag dopo 2 s 
   							 		il timeout ref viene storato in .getcontext.blocking)
   							- poi si invia l'evento di update dei pumps ( fn.pumpsHandler[pumpnumber](0,on_)): al browser via socket event

   							
   							
   							
   						in OnRelais() 
   							- recupero clientDiscon con clientDiscon=fn.getcontext.getCliDiscon()
   							
   							se vedo arrvare un evento dal browser , (see: if (fn.getcontext && fn.getcontext.processBrow))
   							- checko il flag discFromBrow(via fn.getcontext.processBrow)
   								se  discFromBrow==true  
   									- resetto timeout (getcontext.blocking)
   									  e resetto il flag fn.getcontext.discFromBrow=false
   									  ed esco senza processare due volte l'evento nascente da setPump
   
   
   						>> migliorare descrivendo meglio il setpump da non raddoppiare con un hash
   						>> capire perche il reset del  clientDiscon che avviene nel :
   						
   							 socket.on('disconnect',() => {// to do 	SSEE
								    // set a flag to avoid browser .emit call from any function that can do that
								    // eM will run also if the client dead . when a new connection come and it refears to same plant of the running eM , attact it to the closure and goon  
								    clientDiscon=true;  });
   							non viene poi resetatto d un nuova connessione !!!!
    	 	
    	 inoltre recupera info sulla cfg del plant da models x buildare i device :
    	 	- eM.status.plantcfg
    
    	 e lo state del plant che sopravvive alla distruzione del istanza (server down ) 
    	 	- fn.state
    	 	ricoverato con 
    		- recoverstatus.call(eM,plantcfg,plantcnt,plantconfig,feature)
    		
    		- .then((em_) => startfv_(em_,oncomplete_));
    		  dove viene appiccicati i device 				>>>>>>>>>><>> è da fare solo per istanza nuova e non recuperata !  >> controllare !!!!
    		  - fn.iodev
    		  e con oncomplete():
    		  - si  partono i algo correnti come registrato in . state
    		  
    dopo questo evento gli altri eventi del socket (verso browser) avranno a disposizione il plant ctl fn per operare:
    	- fn
    	
    fn similmente verra messo a disposizione anche agli altre connessioni come :
    	- verso nodered o verso mqtt parte socket emul o verso socket ha 
    	
 ___________________________
 to do studiare :
 
         /* **************
         getCliDiscon() banalmente ritorna questo onconnection handler clientDiscon (significa il browser non connesso, session expired !)!! 
          in base a clientDiscon si  settera getcontext.discFromBrow true se clientDiscon=false cioe non processo il doppio comando in onRelais
           nb getcontext.processBrow() ritorna !getcontext.discFromBrow
           inoltre  when clientdiscon it useless run function that will emit browser .emit , because no connection is available
        */
 
    context= eM.getcontext={// to make available this closure var to setPump,.....
                  // probably must nulllified when socket disconnect clientDiscon=null, instead to pass clientDiscon !
	      getSession:function(){return session;},
	      getCliDiscon:function(){return clientDiscon;}, ritorna clientDiscon
	      processBrow:function(){
		if(this.discFromBrow)return false;// discard processing the browser req
		else return true;},
	      discFromBrow:false  // flag di non doppio processamento
 e state.    
	     	"discFromBrow" : [],		??
    		"blocking" : [],

    perche il client disconnect rimane attivo dopo che riconnetto un socket cosi perdo nel browser gli update dei pumps !
    
    
    see : 
    	 // todo correct fn.state.discFromBrow >>>> fn.getcontext.discFromBrow ??? 
_______________________________________

 old staff , try to resolve a bug :
 errore rssi 16102021
 recovery yaml del 11102023 e da li com meld cancellato tutto da 11102023 meno rssi e poi :
  aggiunto pezzo pezzo staff dal 11102023 fino a comarsa errore rssi 
  
  ________________________________
  
 mosquitto_pub -h bot.sermovox.com -t  @Casina_API@ctl_var_state_0   -m '{"payload":{"state":{"relays":{"acs":false}}}}' -p 1883  -u sermovox -P sime01

  >  {'id': '0', 'idx': '0', 'alias': None, 'platform': 'mqtt', 'topic': '@Casina_API@ctl_var_state_0', 'payload': '{"payload":{"state":{"relays":{"acs":false}}}}', 'qos': 0, 'description': 'mqtt topic @Casina_API@ctl_var_state_0', 'payload_json': {'payload': {'state': {'relays': {'acs': False}}}}} and {'id': '0', 'idx': '0', 'alias': None, 'platform': 'mqtt', 'topic': '@Casina_API@ctl_var_state_0', 'payload': '{"payload":{"state":{"relays":{"acs":false}}}}', 'qos': 0, 'description': 'mqtt topic @Casina_API@ctl_var_state_0', 'payload_json': {'payload': {'state': {'relays': {'acs': False}}}}} and  thatis to test!

____________________________

remember interrupt 

in mqtt  si checca se posso agganciare un int quando un messaggio diretto a un dev di tipo 0 1,2,4 ha un cmd topic :
	 topicNodeRed = adev.topicNodeRed; isCmdTopic = topicNodeRed && topicNodeRed == topic; /
 quindi si assegna il suo handler e gli si passa i data :
 message_.url == 'setMan' && ctlpack.ctl.int1) o
  message_.url == 'mqttxwebsock' && ctlpack.ctl.intWebSoc) 
  than the def : intHand = ctlpack.ctl.int0;
 if (intHand) intHand(msg, mqttInst.status[dev], data);
 
 
 nb  lo state e' inviato tramite un dev type 4 di tipo prob indirizzato da virt2realProbMap:[0] che in casina è il prob number 3 che è
 
 
 nb intwebsok int è relativo al dev con description : 
 	 mqttWebSock:        {portid:0,subtopic:'mqtt_websock_',varx:0,isprobe:false,clas:'int',protocol:'mqttxwebsock'},// must be portid=0 ! : a dummy var that creates ctl websocket topic 
                                                                                                                        // todo >>>> must be added a user/token release process or implement a broker security by clientid
 _________________________________________
 todo add temp a program algo lanciato con cmdtopic del dev 
 
  infatti si pub :
 	topic: '@Casina_API@interface_mqtt_websock_0/NReadUser/cmd'
          payload: >
               {"payload":1,"sender":{"plant":"Casina_API","user":77},"url":"mqttxwebsock","event":"repeatcheckxSun","data":{{ states.sensor.pippo.state }},"data1":{{ states.input_text.text1.state }},"param":"{{ states('input_boolean.savingsservice') }}"}
               
       e essendo  "url":"mqttxwebsock"  e un cmdtopic lancia un interrupt ctlpack.ctl.intWebSoc  sul device descritto con   mqttWebSock.
       
       nd il int ctlpack.ctl.intWebSoc:
       	intWebSock(val=0, devqueue, message)
       lancia il handler del algo program impostando triggers2:
       
       			triggers2=message.data[3];// only "PGMgiorno" : { "8:30" : 27, "17:00" : 30 },
       			
       			repeatHandler1(xstart,xstop,xmin,triggers2); 
       			
         nb l'handler gestise un trigger2 che completo è: 		

                                                                        "triggers2" : {
                                                                          "Tgiorno" : true,
                                                                          "PGMgiorno" : { "8:30" : 27, "17:00" : 30 },
                                                                          "Tnotte" : false,
                                                                          "PGMnotte" : { "notte" : { "8:30" : 20, "17:00" : 22 } },
                                                                          "lastT" : ["21/08/2023, 09:33:23", { "notte" : 23.8, "giorno" : 24.3 }],
                                                                          "mapping" : "==&&state.devmapping=[0,1,2,3,-1,5]",
                                                                          "probMapping" : "==&&state.probmapping=[2,4,0,3,1,5]",
                                                                          "ei" : "S"
                                                                      }
  ________________________________
  
  session management :
  see the log when the socket is connected to browser:
	  console.log(`saving user and socketid ${socket.id} in session ${session.id} used by future fn ( will be associated to user plant). in case algo procedure wants to do something with session and socket if they are active`);
	  console.log('session will be duplicated on fn.getcontext and the socket is still active if fn.getcontext.discFromBrow=false ! '); 
__________________________

 attenzione che e' fn a avere la connessione con il ha via mqtt o wsocket. ha sincronizza i rele usando il  
 	- il command topic dei rele associati that is fired only when its state.relays changes o 
 	- via state (repetitive at specific event that changes some state) 
 	
 	>> gestire eventuali disallineamenti !!!
 __________________________________
 
 models.js ha home assistant state topic  
 // virt2realProbMap[ 0] is reserved to state pub var dev on mqttprob[virtualindex[0]]
 
        virt2realProbMap:[3,1000,-1,1001,-1,-1,-1],// algo works on virtual index 1 ,rindex= virt2realProbMap[1] is the index in :
                                //  mqttprob
                                //  or ( if>1000) pythonprob   
                                //  to find probs relating to :
                                //      g, virtual index 2 of gpionumb/mqttnumb pump dev
                                //              the g temp prob is got by a python shell referring to address pythonprob[virt2realProbMap[1]]
                                //      n , virtual index 3 of gpionumb/mqttnumb pump dev
                                //              the n temp prob is got by a python shell referring to address pythonprob[virt2realProbMap[3]]
                                //      s  virtual index 4 of gpionumb/mqttnumb pump dev
                                // better if < 1000 : 
                                // virtual modbus python probs used by algo.  x : g , n , s  virtual zones temp/humid device map to  mqttprob dev
                                // algo wants to find mqttprob and look at virt2realProbMap whose index are so mapped :
                                //  index of virt2realProbMap > [ha state dummy var device,g temp,g humid,n temp,n humidg, s temp,s humid]
                                // -1 for undefined
                                // virtualindex 0 is reserved to state pub var dev on mqttprob[virtualindex[0]]
 ______________________________-
 22102023 : todo :
    			- if fn e' recoverato e tutto va bene almeno allineare gli stati dei pumps/relais del browser con il loro corretti state state.ralays lanciando setPump su tutto il state.relays  !!!!!  **********  todo  *********
______________________________________
todo : 
- the listener array grows too much , try to reset listener x all cases , see:
            if (resetListener) {
                resRetList(resetListener);// say to message income to reset the listener
                see the log in logs/listenertoolonganticipateatmorning_23102023.txt
                
- check in casina , should be identity ? :
 "devmapping" : [0, 1, 2, 3, -1, 5],
 ___________________
 dev mng summary :
 un device mqtt ha topic e pubtopic :
 - A un topic che sono 
 	messaggi ricevuti dal dev , e relativi subtopic che possono esere pensati come canali addizionali , es url/event  con request e response (del request sul B)
  e un 
 -B pubtopic che sono i messaggi trasmessi da fv3 con relativi subtopic , es url con  request ( il response avviene sul A con pari urlresponse) e request
 in pratica e come avere un websocket tra fv3 verso il device e viceversa con emit(A)  e relativi .on handler (B)
 
 un custom device i canali tra fv3 e device sono rappresentati da cmdshell  (B con un solo subtopic e relativo return ) e/o da pubshell
  quindi fv3 lancia un writesync es start splits , si lancia lo shel e la sua risposta puo essere inserita 
  - nel pubtopic che da al device principale che poi lo puo rigirare nel topic 
  - rigirato come nei var dev type 2 ne topic dove trovo la risposta del device che ritorna nel readsync 
  
  
  nb un pubshell si ottiene anche col meccanismo  virt2realProbMap in models.js !
    _____________________________
    
 	 
